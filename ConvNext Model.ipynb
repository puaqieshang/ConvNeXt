{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "23c48e8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn\n",
    "import sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dbb43a70",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mqpua0001\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import wandb\n",
    "wandb.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1ebd9f0b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not using distributed mode\n",
      "Namespace(aa='rand-m9-mstd0.5-inc1', auto_resume=True, batch_size=10, clip_grad=None, color_jitter=0.4, crop_pct=None, cutmix=0.0, cutmix_minmax=None, data_path='C:/Users/qiezh/Desktop/FYP/FYPConvNext/ChestXRays/train', data_set='image_folder', device='cuda', disable_eval=False, dist_eval=True, dist_on_itp=False, dist_url='env://', distributed=False, drop_path=0, enable_wandb=True, epochs=1, eval=False, eval_data_path='C:/Users/qiezh/Desktop/FYP/FYPConvNext/ChestXRays/val', finetune='convnext_tiny_1k_224_ema.pth', head_init_scale=1.0, imagenet_default_mean_and_std=True, input_size=224, layer_decay=1.0, layer_scale_init_value=1e-06, local_rank=-1, log_dir=None, lr=0.0004, min_lr=1e-06, mixup=0.0, mixup_mode='batch', mixup_prob=1.0, mixup_switch_prob=0.5, model='convnext_tiny', model_ema=False, model_ema_decay=0.9999, model_ema_eval=False, model_ema_force_cpu=False, model_key='model|module', model_prefix='', momentum=0.9, nb_classes=4, num_workers=8, opt='adamw', opt_betas=None, opt_eps=1e-08, output_dir='C:/Users/qiezh/Desktop/FYP/FYPConvNext/ConvNextResults/ResultsWandB', pin_mem=True, project='convnext', recount=1, remode='pixel', reprob=0.25, resplit=False, resume='', save_ckpt=True, save_ckpt_freq=1, save_ckpt_num=3, seed=0, smoothing=0.1, start_epoch=0, train_interpolation='bicubic', update_freq=1, use_amp=False, wandb_ckpt=True, warmup_epochs=0, warmup_steps=-1, weight_decay=0.05, weight_decay_end=None, world_size=1)\n",
      "Transform = \n",
      "RandomResizedCropAndInterpolation(size=(224, 224), scale=(0.08, 1.0), ratio=(0.75, 1.3333), interpolation=PIL.Image.BICUBIC)\n",
      "RandomHorizontalFlip(p=0.5)\n",
      "<timm.data.auto_augment.RandAugment object at 0x0000019B1F7CED60>\n",
      "ToTensor()\n",
      "Normalize(mean=tensor([0.4850, 0.4560, 0.4060]), std=tensor([0.2290, 0.2240, 0.2250]))\n",
      "<timm.data.random_erasing.RandomErasing object at 0x0000019B1F7DD130>\n",
      "---------------------------\n",
      "Number of the class = 4\n",
      "Transform = \n",
      "Resize(size=256, interpolation=bicubic)\n",
      "CenterCrop(size=(224, 224))\n",
      "ToTensor()\n",
      "Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225))\n",
      "---------------------------\n",
      "Number of the class = 4\n",
      "Sampler_train = <torch.utils.data.distributed.DistributedSampler object at 0x0000019B1F7CE370>\n",
      "Load ckpt from convnext_tiny_1k_224_ema.pth\n",
      "Load state_dict by model_key = model\n",
      "Removing key head.weight from pretrained checkpoint\n",
      "Removing key head.bias from pretrained checkpoint\n",
      "Weights of ConvNeXt not initialized from pretrained model: ['head.weight', 'head.bias']\n",
      "Model = ConvNeXt(\n",
      "  (downsample_layers): ModuleList(\n",
      "    (0): Sequential(\n",
      "      (0): Conv2d(3, 96, kernel_size=(4, 4), stride=(4, 4))\n",
      "      (1): LayerNorm()\n",
      "    )\n",
      "    (1): Sequential(\n",
      "      (0): LayerNorm()\n",
      "      (1): Conv2d(96, 192, kernel_size=(2, 2), stride=(2, 2))\n",
      "    )\n",
      "    (2): Sequential(\n",
      "      (0): LayerNorm()\n",
      "      (1): Conv2d(192, 384, kernel_size=(2, 2), stride=(2, 2))\n",
      "    )\n",
      "    (3): Sequential(\n",
      "      (0): LayerNorm()\n",
      "      (1): Conv2d(384, 768, kernel_size=(2, 2), stride=(2, 2))\n",
      "    )\n",
      "  )\n",
      "  (stages): ModuleList(\n",
      "    (0): Sequential(\n",
      "      (0): Block(\n",
      "        (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)\n",
      "        (norm): LayerNorm()\n",
      "        (pwconv1): Linear(in_features=96, out_features=384, bias=True)\n",
      "        (act): GELU()\n",
      "        (pwconv2): Linear(in_features=384, out_features=96, bias=True)\n",
      "        (drop_path): Identity()\n",
      "      )\n",
      "      (1): Block(\n",
      "        (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)\n",
      "        (norm): LayerNorm()\n",
      "        (pwconv1): Linear(in_features=96, out_features=384, bias=True)\n",
      "        (act): GELU()\n",
      "        (pwconv2): Linear(in_features=384, out_features=96, bias=True)\n",
      "        (drop_path): Identity()\n",
      "      )\n",
      "      (2): Block(\n",
      "        (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)\n",
      "        (norm): LayerNorm()\n",
      "        (pwconv1): Linear(in_features=96, out_features=384, bias=True)\n",
      "        (act): GELU()\n",
      "        (pwconv2): Linear(in_features=384, out_features=96, bias=True)\n",
      "        (drop_path): Identity()\n",
      "      )\n",
      "    )\n",
      "    (1): Sequential(\n",
      "      (0): Block(\n",
      "        (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)\n",
      "        (norm): LayerNorm()\n",
      "        (pwconv1): Linear(in_features=192, out_features=768, bias=True)\n",
      "        (act): GELU()\n",
      "        (pwconv2): Linear(in_features=768, out_features=192, bias=True)\n",
      "        (drop_path): Identity()\n",
      "      )\n",
      "      (1): Block(\n",
      "        (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)\n",
      "        (norm): LayerNorm()\n",
      "        (pwconv1): Linear(in_features=192, out_features=768, bias=True)\n",
      "        (act): GELU()\n",
      "        (pwconv2): Linear(in_features=768, out_features=192, bias=True)\n",
      "        (drop_path): Identity()\n",
      "      )\n",
      "      (2): Block(\n",
      "        (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)\n",
      "        (norm): LayerNorm()\n",
      "        (pwconv1): Linear(in_features=192, out_features=768, bias=True)\n",
      "        (act): GELU()\n",
      "        (pwconv2): Linear(in_features=768, out_features=192, bias=True)\n",
      "        (drop_path): Identity()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Currently logged in as: qpua0001. Use `wandb login --relogin` to force relogin\n",
      "wandb: Tracking run with wandb version 0.12.16\n",
      "wandb: Run data is saved locally in C:\\Users\\qiezh\\Desktop\\FYP\\FYPConvNext\\ConvNeXt\\wandb\\run-20220521_214804-t73pba5b\n",
      "wandb: Run `wandb offline` to turn off syncing.\n",
      "wandb: Syncing run colorful-glade-6\n",
      "wandb:  View project at https://wandb.ai/qpua0001/convnext\n",
      "wandb:  View run at https://wandb.ai/qpua0001/convnext/runs/t73pba5b\n",
      "wandb: Adding directory to artifact (C:\\Users\\qiezh\\Desktop\\FYP\\FYPConvNext\\ConvNextResults\\ResultsWandB)... Done. 0.5s\n",
      "wandb: Waiting for W&B process to finish... (success).\n",
      "wandb: - 637.175 MB of 637.175 MB uploaded (0.000 MB deduped)\n",
      "wandb: \\ 637.175 MB of 637.175 MB uploaded (0.000 MB deduped)\n",
      "wandb: | 637.175 MB of 637.198 MB uploaded (0.000 MB deduped)\n",
      "wandb: / 637.175 MB of 637.198 MB uploaded (0.000 MB deduped)\n",
      "wandb: - 637.175 MB of 637.198 MB uploaded (0.000 MB deduped)\n",
      "wandb: \\ 637.198 MB of 637.198 MB uploaded (0.000 MB deduped)\n",
      "wandb: | 637.198 MB of 637.198 MB uploaded (0.000 MB deduped)\n",
      "wandb: / 637.198 MB of 637.198 MB uploaded (0.000 MB deduped)\n",
      "wandb: - 637.198 MB of 637.198 MB uploaded (0.000 MB deduped)\n",
      "wandb: \\ 637.198 MB of 637.198 MB uploaded (0.000 MB deduped)\n",
      "wandb: | 637.198 MB of 637.198 MB uploaded (0.000 MB deduped)\n",
      "wandb: / 637.198 MB of 637.198 MB uploaded (0.000 MB deduped)\n",
      "wandb: - 637.198 MB of 637.198 MB uploaded (0.000 MB deduped)\n",
      "wandb: \\ 637.198 MB of 637.198 MB uploaded (0.000 MB deduped)\n",
      "wandb:                                                                                \n",
      "wandb: Synced colorful-glade-6: https://wandb.ai/qpua0001/convnext/runs/t73pba5b\n",
      "wandb: Synced 6 W&B file(s), 0 media file(s), 3 artifact file(s) and 0 other file(s)\n",
      "wandb: Find logs at: .\\wandb\\run-20220521_214804-t73pba5b\\logs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      )\n",
      "    )\n",
      "    (2): Sequential(\n",
      "      (0): Block(\n",
      "        (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n",
      "        (norm): LayerNorm()\n",
      "        (pwconv1): Linear(in_features=384, out_features=1536, bias=True)\n",
      "        (act): GELU()\n",
      "        (pwconv2): Linear(in_features=1536, out_features=384, bias=True)\n",
      "        (drop_path): Identity()\n",
      "      )\n",
      "      (1): Block(\n",
      "        (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n",
      "        (norm): LayerNorm()\n",
      "        (pwconv1): Linear(in_features=384, out_features=1536, bias=True)\n",
      "        (act): GELU()\n",
      "        (pwconv2): Linear(in_features=1536, out_features=384, bias=True)\n",
      "        (drop_path): Identity()\n",
      "      )\n",
      "      (2): Block(\n",
      "        (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n",
      "        (norm): LayerNorm()\n",
      "        (pwconv1): Linear(in_features=384, out_features=1536, bias=True)\n",
      "        (act): GELU()\n",
      "        (pwconv2): Linear(in_features=1536, out_features=384, bias=True)\n",
      "        (drop_path): Identity()\n",
      "      )\n",
      "      (3): Block(\n",
      "        (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n",
      "        (norm): LayerNorm()\n",
      "        (pwconv1): Linear(in_features=384, out_features=1536, bias=True)\n",
      "        (act): GELU()\n",
      "        (pwconv2): Linear(in_features=1536, out_features=384, bias=True)\n",
      "        (drop_path): Identity()\n",
      "      )\n",
      "      (4): Block(\n",
      "        (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n",
      "        (norm): LayerNorm()\n",
      "        (pwconv1): Linear(in_features=384, out_features=1536, bias=True)\n",
      "        (act): GELU()\n",
      "        (pwconv2): Linear(in_features=1536, out_features=384, bias=True)\n",
      "        (drop_path): Identity()\n",
      "      )\n",
      "      (5): Block(\n",
      "        (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n",
      "        (norm): LayerNorm()\n",
      "        (pwconv1): Linear(in_features=384, out_features=1536, bias=True)\n",
      "        (act): GELU()\n",
      "        (pwconv2): Linear(in_features=1536, out_features=384, bias=True)\n",
      "        (drop_path): Identity()\n",
      "      )\n",
      "      (6): Block(\n",
      "        (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n",
      "        (norm): LayerNorm()\n",
      "        (pwconv1): Linear(in_features=384, out_features=1536, bias=True)\n",
      "        (act): GELU()\n",
      "        (pwconv2): Linear(in_features=1536, out_features=384, bias=True)\n",
      "        (drop_path): Identity()\n",
      "      )\n",
      "      (7): Block(\n",
      "        (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n",
      "        (norm): LayerNorm()\n",
      "        (pwconv1): Linear(in_features=384, out_features=1536, bias=True)\n",
      "        (act): GELU()\n",
      "        (pwconv2): Linear(in_features=1536, out_features=384, bias=True)\n",
      "        (drop_path): Identity()\n",
      "      )\n",
      "      (8): Block(\n",
      "        (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n",
      "        (norm): LayerNorm()\n",
      "        (pwconv1): Linear(in_features=384, out_features=1536, bias=True)\n",
      "        (act): GELU()\n",
      "        (pwconv2): Linear(in_features=1536, out_features=384, bias=True)\n",
      "        (drop_path): Identity()\n",
      "      )\n",
      "    )\n",
      "    (3): Sequential(\n",
      "      (0): Block(\n",
      "        (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)\n",
      "        (norm): LayerNorm()\n",
      "        (pwconv1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "        (act): GELU()\n",
      "        (pwconv2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        (drop_path): Identity()\n",
      "      )\n",
      "      (1): Block(\n",
      "        (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)\n",
      "        (norm): LayerNorm()\n",
      "        (pwconv1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "        (act): GELU()\n",
      "        (pwconv2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        (drop_path): Identity()\n",
      "      )\n",
      "      (2): Block(\n",
      "        (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)\n",
      "        (norm): LayerNorm()\n",
      "        (pwconv1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "        (act): GELU()\n",
      "        (pwconv2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        (drop_path): Identity()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "  (head): Linear(in_features=768, out_features=4, bias=True)\n",
      ")\n",
      "number of params: 27823204\n",
      "LR = 0.00040000\n",
      "Batch size = 10\n",
      "Update frequent = 1\n",
      "Number of training examples = 2270\n",
      "Number of training training per epoch = 227\n",
      "Param groups = {\n",
      "  \"decay\": {\n",
      "    \"weight_decay\": 0.05,\n",
      "    \"params\": [\n",
      "      \"downsample_layers.0.0.weight\",\n",
      "      \"downsample_layers.1.1.weight\",\n",
      "      \"downsample_layers.2.1.weight\",\n",
      "      \"downsample_layers.3.1.weight\",\n",
      "      \"stages.0.0.dwconv.weight\",\n",
      "      \"stages.0.0.pwconv1.weight\",\n",
      "      \"stages.0.0.pwconv2.weight\",\n",
      "      \"stages.0.1.dwconv.weight\",\n",
      "      \"stages.0.1.pwconv1.weight\",\n",
      "      \"stages.0.1.pwconv2.weight\",\n",
      "      \"stages.0.2.dwconv.weight\",\n",
      "      \"stages.0.2.pwconv1.weight\",\n",
      "      \"stages.0.2.pwconv2.weight\",\n",
      "      \"stages.1.0.dwconv.weight\",\n",
      "      \"stages.1.0.pwconv1.weight\",\n",
      "      \"stages.1.0.pwconv2.weight\",\n",
      "      \"stages.1.1.dwconv.weight\",\n",
      "      \"stages.1.1.pwconv1.weight\",\n",
      "      \"stages.1.1.pwconv2.weight\",\n",
      "      \"stages.1.2.dwconv.weight\",\n",
      "      \"stages.1.2.pwconv1.weight\",\n",
      "      \"stages.1.2.pwconv2.weight\",\n",
      "      \"stages.2.0.dwconv.weight\",\n",
      "      \"stages.2.0.pwconv1.weight\",\n",
      "      \"stages.2.0.pwconv2.weight\",\n",
      "      \"stages.2.1.dwconv.weight\",\n",
      "      \"stages.2.1.pwconv1.weight\",\n",
      "      \"stages.2.1.pwconv2.weight\",\n",
      "      \"stages.2.2.dwconv.weight\",\n",
      "      \"stages.2.2.pwconv1.weight\",\n",
      "      \"stages.2.2.pwconv2.weight\",\n",
      "      \"stages.2.3.dwconv.weight\",\n",
      "      \"stages.2.3.pwconv1.weight\",\n",
      "      \"stages.2.3.pwconv2.weight\",\n",
      "      \"stages.2.4.dwconv.weight\",\n",
      "      \"stages.2.4.pwconv1.weight\",\n",
      "      \"stages.2.4.pwconv2.weight\",\n",
      "      \"stages.2.5.dwconv.weight\",\n",
      "      \"stages.2.5.pwconv1.weight\",\n",
      "      \"stages.2.5.pwconv2.weight\",\n",
      "      \"stages.2.6.dwconv.weight\",\n",
      "      \"stages.2.6.pwconv1.weight\",\n",
      "      \"stages.2.6.pwconv2.weight\",\n",
      "      \"stages.2.7.dwconv.weight\",\n",
      "      \"stages.2.7.pwconv1.weight\",\n",
      "      \"stages.2.7.pwconv2.weight\",\n",
      "      \"stages.2.8.dwconv.weight\",\n",
      "      \"stages.2.8.pwconv1.weight\",\n",
      "      \"stages.2.8.pwconv2.weight\",\n",
      "      \"stages.3.0.dwconv.weight\",\n",
      "      \"stages.3.0.pwconv1.weight\",\n",
      "      \"stages.3.0.pwconv2.weight\",\n",
      "      \"stages.3.1.dwconv.weight\",\n",
      "      \"stages.3.1.pwconv1.weight\",\n",
      "      \"stages.3.1.pwconv2.weight\",\n",
      "      \"stages.3.2.dwconv.weight\",\n",
      "      \"stages.3.2.pwconv1.weight\",\n",
      "      \"stages.3.2.pwconv2.weight\",\n",
      "      \"head.weight\"\n",
      "    ],\n",
      "    \"lr_scale\": 1.0\n",
      "  },\n",
      "  \"no_decay\": {\n",
      "    \"weight_decay\": 0.0,\n",
      "    \"params\": [\n",
      "      \"downsample_layers.0.0.bias\",\n",
      "      \"downsample_layers.0.1.weight\",\n",
      "      \"downsample_layers.0.1.bias\",\n",
      "      \"downsample_layers.1.0.weight\",\n",
      "      \"downsample_layers.1.0.bias\",\n",
      "      \"downsample_layers.1.1.bias\",\n",
      "      \"downsample_layers.2.0.weight\",\n",
      "      \"downsample_layers.2.0.bias\",\n",
      "      \"downsample_layers.2.1.bias\",\n",
      "      \"downsample_layers.3.0.weight\",\n",
      "      \"downsample_layers.3.0.bias\",\n",
      "      \"downsample_layers.3.1.bias\",\n",
      "      \"stages.0.0.gamma\",\n",
      "      \"stages.0.0.dwconv.bias\",\n",
      "      \"stages.0.0.norm.weight\",\n",
      "      \"stages.0.0.norm.bias\",\n",
      "      \"stages.0.0.pwconv1.bias\",\n",
      "      \"stages.0.0.pwconv2.bias\",\n",
      "      \"stages.0.1.gamma\",\n",
      "      \"stages.0.1.dwconv.bias\",\n",
      "      \"stages.0.1.norm.weight\",\n",
      "      \"stages.0.1.norm.bias\",\n",
      "      \"stages.0.1.pwconv1.bias\",\n",
      "      \"stages.0.1.pwconv2.bias\",\n",
      "      \"stages.0.2.gamma\",\n",
      "      \"stages.0.2.dwconv.bias\",\n",
      "      \"stages.0.2.norm.weight\",\n",
      "      \"stages.0.2.norm.bias\",\n",
      "      \"stages.0.2.pwconv1.bias\",\n",
      "      \"stages.0.2.pwconv2.bias\",\n",
      "      \"stages.1.0.gamma\",\n",
      "      \"stages.1.0.dwconv.bias\",\n",
      "      \"stages.1.0.norm.weight\",\n",
      "      \"stages.1.0.norm.bias\",\n",
      "      \"stages.1.0.pwconv1.bias\",\n",
      "      \"stages.1.0.pwconv2.bias\",\n",
      "      \"stages.1.1.gamma\",\n",
      "      \"stages.1.1.dwconv.bias\",\n",
      "      \"stages.1.1.norm.weight\",\n",
      "      \"stages.1.1.norm.bias\",\n",
      "      \"stages.1.1.pwconv1.bias\",\n",
      "      \"stages.1.1.pwconv2.bias\",\n",
      "      \"stages.1.2.gamma\",\n",
      "      \"stages.1.2.dwconv.bias\",\n",
      "      \"stages.1.2.norm.weight\",\n",
      "      \"stages.1.2.norm.bias\",\n",
      "      \"stages.1.2.pwconv1.bias\",\n",
      "      \"stages.1.2.pwconv2.bias\",\n",
      "      \"stages.2.0.gamma\",\n",
      "      \"stages.2.0.dwconv.bias\",\n",
      "      \"stages.2.0.norm.weight\",\n",
      "      \"stages.2.0.norm.bias\",\n",
      "      \"stages.2.0.pwconv1.bias\",\n",
      "      \"stages.2.0.pwconv2.bias\",\n",
      "      \"stages.2.1.gamma\",\n",
      "      \"stages.2.1.dwconv.bias\",\n",
      "      \"stages.2.1.norm.weight\",\n",
      "      \"stages.2.1.norm.bias\",\n",
      "      \"stages.2.1.pwconv1.bias\",\n",
      "      \"stages.2.1.pwconv2.bias\",\n",
      "      \"stages.2.2.gamma\",\n",
      "      \"stages.2.2.dwconv.bias\",\n",
      "      \"stages.2.2.norm.weight\",\n",
      "      \"stages.2.2.norm.bias\",\n",
      "      \"stages.2.2.pwconv1.bias\",\n",
      "      \"stages.2.2.pwconv2.bias\",\n",
      "      \"stages.2.3.gamma\",\n",
      "      \"stages.2.3.dwconv.bias\",\n",
      "      \"stages.2.3.norm.weight\",\n",
      "      \"stages.2.3.norm.bias\",\n",
      "      \"stages.2.3.pwconv1.bias\",\n",
      "      \"stages.2.3.pwconv2.bias\",\n",
      "      \"stages.2.4.gamma\",\n",
      "      \"stages.2.4.dwconv.bias\",\n",
      "      \"stages.2.4.norm.weight\",\n",
      "      \"stages.2.4.norm.bias\",\n",
      "      \"stages.2.4.pwconv1.bias\",\n",
      "      \"stages.2.4.pwconv2.bias\",\n",
      "      \"stages.2.5.gamma\",\n",
      "      \"stages.2.5.dwconv.bias\",\n",
      "      \"stages.2.5.norm.weight\",\n",
      "      \"stages.2.5.norm.bias\",\n",
      "      \"stages.2.5.pwconv1.bias\",\n",
      "      \"stages.2.5.pwconv2.bias\",\n",
      "      \"stages.2.6.gamma\",\n",
      "      \"stages.2.6.dwconv.bias\",\n",
      "      \"stages.2.6.norm.weight\",\n",
      "      \"stages.2.6.norm.bias\",\n",
      "      \"stages.2.6.pwconv1.bias\",\n",
      "      \"stages.2.6.pwconv2.bias\",\n",
      "      \"stages.2.7.gamma\",\n",
      "      \"stages.2.7.dwconv.bias\",\n",
      "      \"stages.2.7.norm.weight\",\n",
      "      \"stages.2.7.norm.bias\",\n",
      "      \"stages.2.7.pwconv1.bias\",\n",
      "      \"stages.2.7.pwconv2.bias\",\n",
      "      \"stages.2.8.gamma\",\n",
      "      \"stages.2.8.dwconv.bias\",\n",
      "      \"stages.2.8.norm.weight\",\n",
      "      \"stages.2.8.norm.bias\",\n",
      "      \"stages.2.8.pwconv1.bias\",\n",
      "      \"stages.2.8.pwconv2.bias\",\n",
      "      \"stages.3.0.gamma\",\n",
      "      \"stages.3.0.dwconv.bias\",\n",
      "      \"stages.3.0.norm.weight\",\n",
      "      \"stages.3.0.norm.bias\",\n",
      "      \"stages.3.0.pwconv1.bias\",\n",
      "      \"stages.3.0.pwconv2.bias\",\n",
      "      \"stages.3.1.gamma\",\n",
      "      \"stages.3.1.dwconv.bias\",\n",
      "      \"stages.3.1.norm.weight\",\n",
      "      \"stages.3.1.norm.bias\",\n",
      "      \"stages.3.1.pwconv1.bias\",\n",
      "      \"stages.3.1.pwconv2.bias\",\n",
      "      \"stages.3.2.gamma\",\n",
      "      \"stages.3.2.dwconv.bias\",\n",
      "      \"stages.3.2.norm.weight\",\n",
      "      \"stages.3.2.norm.bias\",\n",
      "      \"stages.3.2.pwconv1.bias\",\n",
      "      \"stages.3.2.pwconv2.bias\",\n",
      "      \"norm.weight\",\n",
      "      \"norm.bias\",\n",
      "      \"head.bias\"\n",
      "    ],\n",
      "    \"lr_scale\": 1.0\n",
      "  }\n",
      "}\n",
      "Use Cosine LR scheduler\n",
      "Set warmup steps = 0\n",
      "Set warmup steps = 0\n",
      "Max WD = 0.0500000, Min WD = 0.0500000\n",
      "criterion = LabelSmoothingCrossEntropy()\n",
      "Auto resume checkpoint: C:\\Users\\qiezh\\Desktop\\FYP\\FYPConvNext\\ConvNextResults\\ResultsWandB\\checkpoint-0.pth\n",
      "Resume checkpoint C:\\Users\\qiezh\\Desktop\\FYP\\FYPConvNext\\ConvNextResults\\ResultsWandB\\checkpoint-0.pth\n",
      "With optim & sched!\n",
      "Start training for 1 epochs\n",
      "Training time 0:00:00\n"
     ]
    }
   ],
   "source": [
    "!python main.py --epochs 1 \\\n",
    "                --model convnext_tiny \\\n",
    "                --data_set image_folder \\\n",
    "                --data_path C:/Users/qiezh/Desktop/FYP/FYPConvNext/ChestXRays/train \\\n",
    "                --eval_data_path C:/Users/qiezh/Desktop/FYP/FYPConvNext/ChestXRays/val \\\n",
    "                --batch_size 10 \\\n",
    "                --nb_classes 4 \\\n",
    "                --num_workers 8 \\\n",
    "                --warmup_epochs 0 \\\n",
    "                --save_ckpt true \\\n",
    "                --output_dir C:/Users/qiezh/Desktop/FYP/FYPConvNext/ConvNextResults/ResultsWandB \\\n",
    "                --finetune convnext_tiny_1k_224_ema.pth \\\n",
    "                --cutmix 0 \\\n",
    "                --mixup 0 --lr 4e-4 \\\n",
    "                --enable_wandb true --wandb_ckpt true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "af6b667c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not using distributed mode\n",
      "Namespace(aa='rand-m9-mstd0.5-inc1', auto_resume=True, batch_size=64, clip_grad=None, color_jitter=0.4, crop_pct=None, cutmix=1.0, cutmix_minmax=None, data_path='C:/Users/qiezh/Desktop/FYP/FYPConvNext/ChestXRays', data_set='IMNET', device='cuda', disable_eval=False, dist_eval=True, dist_on_itp=False, dist_url='env://', distributed=False, drop_path=0.2, enable_wandb=False, epochs=300, eval=True, eval_data_path=None, finetune='', head_init_scale=1.0, imagenet_default_mean_and_std=True, input_size=224, layer_decay=1.0, layer_scale_init_value=1e-06, local_rank=-1, log_dir=None, lr=0.004, min_lr=1e-06, mixup=0.8, mixup_mode='batch', mixup_prob=1.0, mixup_switch_prob=0.5, model='my_model', model_ema=False, model_ema_decay=0.9999, model_ema_eval=False, model_ema_force_cpu=False, model_key='model|module', model_prefix='', momentum=0.9, nb_classes=4, num_workers=10, opt='adamw', opt_betas=None, opt_eps=1e-08, output_dir='', pin_mem=True, project='convnext', recount=1, remode='pixel', reprob=0.25, resplit=False, resume='', save_ckpt=True, save_ckpt_freq=1, save_ckpt_num=3, seed=0, smoothing=0.1, start_epoch=0, train_interpolation='bicubic', update_freq=1, use_amp=False, wandb_ckpt=False, warmup_epochs=20, warmup_steps=-1, weight_decay=0.05, weight_decay_end=None, world_size=1)\n",
      "Transform = \n",
      "RandomResizedCropAndInterpolation(size=(224, 224), scale=(0.08, 1.0), ratio=(0.75, 1.3333), interpolation=PIL.Image.BICUBIC)\n",
      "RandomHorizontalFlip(p=0.5)\n",
      "<timm.data.auto_augment.RandAugment object at 0x000001D01F448FA0>\n",
      "ToTensor()\n",
      "Normalize(mean=tensor([0.4850, 0.4560, 0.4060]), std=tensor([0.2290, 0.2240, 0.2250]))\n",
      "<timm.data.random_erasing.RandomErasing object at 0x000001D01F448B20>\n",
      "---------------------------\n",
      "reading from datapath C:/Users/qiezh/Desktop/FYP/FYPConvNext/ChestXRays\n",
      "Number of the class = 1000\n",
      "Transform = \n",
      "Resize(size=256, interpolation=bicubic)\n",
      "CenterCrop(size=(224, 224))\n",
      "ToTensor()\n",
      "Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225))\n",
      "---------------------------\n",
      "reading from datapath C:/Users/qiezh/Desktop/FYP/FYPConvNext/ChestXRays\n",
      "Number of the class = 1000\n",
      "Sampler_train = <torch.utils.data.distributed.DistributedSampler object at 0x000001D01F448070>\n",
      "Mixup is activated!\n",
      "Model = ConvNeXt_Zheng(\n",
      "  (downsample_layers): ModuleList(\n",
      "    (0): Sequential(\n",
      "      (0): Conv2d(3, 96, kernel_size=(4, 4), stride=(4, 4))\n",
      "      (1): LayerNorm()\n",
      "    )\n",
      "    (1): Sequential(\n",
      "      (0): LayerNorm()\n",
      "      (1): Conv2d(96, 192, kernel_size=(2, 2), stride=(2, 2))\n",
      "    )\n",
      "    (2): Sequential(\n",
      "      (0): LayerNorm()\n",
      "      (1): Conv2d(192, 384, kernel_size=(2, 2), stride=(2, 2))\n",
      "    )\n",
      "    (3): Sequential(\n",
      "      (0): LayerNorm()\n",
      "      (1): Conv2d(384, 768, kernel_size=(2, 2), stride=(2, 2))\n",
      "    )\n",
      "  )\n",
      "  (stages): ModuleList(\n",
      "    (0): Sequential(\n",
      "      (0): Block(\n",
      "        (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)\n",
      "        (norm): LayerNorm()\n",
      "        (pwconv1): Linear(in_features=96, out_features=384, bias=True)\n",
      "        (act): GELU()\n",
      "        (pwconv2): Linear(in_features=384, out_features=96, bias=True)\n",
      "        (drop_path): Identity()\n",
      "      )\n",
      "      (1): Block(\n",
      "        (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)\n",
      "        (norm): LayerNorm()\n",
      "        (pwconv1): Linear(in_features=96, out_features=384, bias=True)\n",
      "        (act): GELU()\n",
      "        (pwconv2): Linear(in_features=384, out_features=96, bias=True)\n",
      "        (drop_path): DropPath()\n",
      "      )\n",
      "      (2): Block(\n",
      "        (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)\n",
      "        (norm): LayerNorm()\n",
      "        (pwconv1): Linear(in_features=96, out_features=384, bias=True)\n",
      "        (act): GELU()\n",
      "        (pwconv2): Linear(in_features=384, out_features=96, bias=True)\n",
      "        (drop_path): DropPath()\n",
      "      )\n",
      "    )\n",
      "    (1): Sequential(\n",
      "      (0): Block(\n",
      "        (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)\n",
      "        (norm): LayerNorm()\n",
      "        (pwconv1): Linear(in_features=192, out_features=768, bias=True)\n",
      "        (act): GELU()\n",
      "        (pwconv2): Linear(in_features=768, out_features=192, bias=True)\n",
      "        (drop_path): DropPath()\n",
      "      )\n",
      "      (1): Block(\n",
      "        (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)\n",
      "        (norm): LayerNorm()\n",
      "        (pwconv1): Linear(in_features=192, out_features=768, bias=True)\n",
      "        (act): GELU()\n",
      "        (pwconv2): Linear(in_features=768, out_features=192, bias=True)\n",
      "        (drop_path): DropPath()\n",
      "      )\n",
      "      (2): Block(\n",
      "        (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)\n",
      "        (norm): LayerNorm()\n",
      "        (pwconv1): Linear(in_features=192, out_features=768, bias=True)\n",
      "        (act): GELU()\n",
      "        (pwconv2): Linear(in_features=768, out_features=192, bias=True)\n",
      "        (drop_path): DropPath()\n",
      "      )\n",
      "    )\n",
      "    (2): Sequential(\n",
      "      (0): Block(\n",
      "        (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n",
      "        (norm): LayerNorm()\n",
      "        (pwconv1): Linear(in_features=384, out_features=1536, bias=True)\n",
      "        (act): GELU()\n",
      "        (pwconv2): Linear(in_features=1536, out_features=384, bias=True)\n",
      "        (drop_path): DropPath()\n",
      "      )\n",
      "      (1): Block(\n",
      "        (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n",
      "        (norm): LayerNorm()\n",
      "        (pwconv1): Linear(in_features=384, out_features=1536, bias=True)\n",
      "        (act): GELU()\n",
      "        (pwconv2): Linear(in_features=1536, out_features=384, bias=True)\n",
      "        (drop_path): DropPath()\n",
      "      )\n",
      "      (2): Block(\n",
      "        (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n",
      "        (norm): LayerNorm()\n",
      "        (pwconv1): Linear(in_features=384, out_features=1536, bias=True)\n",
      "        (act): GELU()\n",
      "        (pwconv2): Linear(in_features=1536, out_features=384, bias=True)\n",
      "        (drop_path): DropPath()\n",
      "      )\n",
      "      (3): Block(\n",
      "        (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n",
      "        (norm): LayerNorm()\n",
      "        (pwconv1): Linear(in_features=384, out_features=1536, bias=True)\n",
      "        (act): GELU()\n",
      "        (pwconv2): Linear(in_features=1536, out_features=384, bias=True)\n",
      "        (drop_path): DropPath()\n",
      "      )\n",
      "      (4): Block(\n",
      "        (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n",
      "        (norm): LayerNorm()\n",
      "        (pwconv1): Linear(in_features=384, out_features=1536, bias=True)\n",
      "        (act): GELU()\n",
      "        (pwconv2): Linear(in_features=1536, out_features=384, bias=True)\n",
      "        (drop_path): DropPath()\n",
      "      )\n",
      "      (5): Block(\n",
      "        (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n",
      "        (norm): LayerNorm()\n",
      "        (pwconv1): Linear(in_features=384, out_features=1536, bias=True)\n",
      "        (act): GELU()\n",
      "        (pwconv2): Linear(in_features=1536, out_features=384, bias=True)\n",
      "        (drop_path): DropPath()\n",
      "      )\n",
      "      (6): Block(\n",
      "        (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n",
      "        (norm): LayerNorm()\n",
      "        (pwconv1): Linear(in_features=384, out_features=1536, bias=True)\n",
      "        (act): GELU()\n",
      "        (pwconv2): Linear(in_features=1536, out_features=384, bias=True)\n",
      "        (drop_path): DropPath()\n",
      "      )\n",
      "      (7): Block(\n",
      "        (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n",
      "        (norm): LayerNorm()\n",
      "        (pwconv1): Linear(in_features=384, out_features=1536, bias=True)\n",
      "        (act): GELU()\n",
      "        (pwconv2): Linear(in_features=1536, out_features=384, bias=True)\n",
      "        (drop_path): DropPath()\n",
      "      )\n",
      "      (8): Block(\n",
      "        (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n",
      "        (norm): LayerNorm()\n",
      "        (pwconv1): Linear(in_features=384, out_features=1536, bias=True)\n",
      "        (act): GELU()\n",
      "        (pwconv2): Linear(in_features=1536, out_features=384, bias=True)\n",
      "        (drop_path): DropPath()\n",
      "      )\n",
      "    )\n",
      "    (3): Sequential(\n",
      "      (0): Block(\n",
      "        (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)\n",
      "        (norm): LayerNorm()\n",
      "        (pwconv1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "        (act): GELU()\n",
      "        (pwconv2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        (drop_path): DropPath()\n",
      "      )\n",
      "      (1): Block(\n",
      "        (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)\n",
      "        (norm): LayerNorm()\n",
      "        (pwconv1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "        (act): GELU()\n",
      "        (pwconv2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        (drop_path): DropPath()\n",
      "      )\n",
      "      (2): Block(\n",
      "        (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)\n",
      "        (norm): LayerNorm()\n",
      "        (pwconv1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "        (act): GELU()\n",
      "        (pwconv2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        (drop_path): DropPath()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "  (head): Linear(in_features=768, out_features=4, bias=True)\n",
      ")\n",
      "number of params: 27823204\n",
      "LR = 0.00400000\n",
      "Batch size = 64\n",
      "Update frequent = 1\n",
      "Number of training examples = 2270\n",
      "Number of training training per epoch = 35\n",
      "Param groups = {\n",
      "  \"decay\": {\n",
      "    \"weight_decay\": 0.05,\n",
      "    \"params\": [\n",
      "      \"downsample_layers.0.0.weight\",\n",
      "      \"downsample_layers.1.1.weight\",\n",
      "      \"downsample_layers.2.1.weight\",\n",
      "      \"downsample_layers.3.1.weight\",\n",
      "      \"stages.0.0.dwconv.weight\",\n",
      "      \"stages.0.0.pwconv1.weight\",\n",
      "      \"stages.0.0.pwconv2.weight\",\n",
      "      \"stages.0.1.dwconv.weight\",\n",
      "      \"stages.0.1.pwconv1.weight\",\n",
      "      \"stages.0.1.pwconv2.weight\",\n",
      "      \"stages.0.2.dwconv.weight\",\n",
      "      \"stages.0.2.pwconv1.weight\",\n",
      "      \"stages.0.2.pwconv2.weight\",\n",
      "      \"stages.1.0.dwconv.weight\",\n",
      "      \"stages.1.0.pwconv1.weight\",\n",
      "      \"stages.1.0.pwconv2.weight\",\n",
      "      \"stages.1.1.dwconv.weight\",\n",
      "      \"stages.1.1.pwconv1.weight\",\n",
      "      \"stages.1.1.pwconv2.weight\",\n",
      "      \"stages.1.2.dwconv.weight\",\n",
      "      \"stages.1.2.pwconv1.weight\",\n",
      "      \"stages.1.2.pwconv2.weight\",\n",
      "      \"stages.2.0.dwconv.weight\",\n",
      "      \"stages.2.0.pwconv1.weight\",\n",
      "      \"stages.2.0.pwconv2.weight\",\n",
      "      \"stages.2.1.dwconv.weight\",\n",
      "      \"stages.2.1.pwconv1.weight\",\n",
      "      \"stages.2.1.pwconv2.weight\",\n",
      "      \"stages.2.2.dwconv.weight\",\n",
      "      \"stages.2.2.pwconv1.weight\",\n",
      "      \"stages.2.2.pwconv2.weight\",\n",
      "      \"stages.2.3.dwconv.weight\",\n",
      "      \"stages.2.3.pwconv1.weight\",\n",
      "      \"stages.2.3.pwconv2.weight\",\n",
      "      \"stages.2.4.dwconv.weight\",\n",
      "      \"stages.2.4.pwconv1.weight\",\n",
      "      \"stages.2.4.pwconv2.weight\",\n",
      "      \"stages.2.5.dwconv.weight\",\n",
      "      \"stages.2.5.pwconv1.weight\",\n",
      "      \"stages.2.5.pwconv2.weight\",\n",
      "      \"stages.2.6.dwconv.weight\",\n",
      "      \"stages.2.6.pwconv1.weight\",\n",
      "      \"stages.2.6.pwconv2.weight\",\n",
      "      \"stages.2.7.dwconv.weight\",\n",
      "      \"stages.2.7.pwconv1.weight\",\n",
      "      \"stages.2.7.pwconv2.weight\",\n",
      "      \"stages.2.8.dwconv.weight\",\n",
      "      \"stages.2.8.pwconv1.weight\",\n",
      "      \"stages.2.8.pwconv2.weight\",\n",
      "      \"stages.3.0.dwconv.weight\",\n",
      "      \"stages.3.0.pwconv1.weight\",\n",
      "      \"stages.3.0.pwconv2.weight\",\n",
      "      \"stages.3.1.dwconv.weight\",\n",
      "      \"stages.3.1.pwconv1.weight\",\n",
      "      \"stages.3.1.pwconv2.weight\",\n",
      "      \"stages.3.2.dwconv.weight\",\n",
      "      \"stages.3.2.pwconv1.weight\",\n",
      "      \"stages.3.2.pwconv2.weight\",\n",
      "      \"head.weight\"\n",
      "    ],\n",
      "    \"lr_scale\": 1.0\n",
      "  },\n",
      "  \"no_decay\": {\n",
      "    \"weight_decay\": 0.0,\n",
      "    \"params\": [\n",
      "      \"downsample_layers.0.0.bias\",\n",
      "      \"downsample_layers.0.1.weight\",\n",
      "      \"downsample_layers.0.1.bias\",\n",
      "      \"downsample_layers.1.0.weight\",\n",
      "      \"downsample_layers.1.0.bias\",\n",
      "      \"downsample_layers.1.1.bias\",\n",
      "      \"downsample_layers.2.0.weight\",\n",
      "      \"downsample_layers.2.0.bias\",\n",
      "      \"downsample_layers.2.1.bias\",\n",
      "      \"downsample_layers.3.0.weight\",\n",
      "      \"downsample_layers.3.0.bias\",\n",
      "      \"downsample_layers.3.1.bias\",\n",
      "      \"stages.0.0.gamma\",\n",
      "      \"stages.0.0.dwconv.bias\",\n",
      "      \"stages.0.0.norm.weight\",\n",
      "      \"stages.0.0.norm.bias\",\n",
      "      \"stages.0.0.pwconv1.bias\",\n",
      "      \"stages.0.0.pwconv2.bias\",\n",
      "      \"stages.0.1.gamma\",\n",
      "      \"stages.0.1.dwconv.bias\",\n",
      "      \"stages.0.1.norm.weight\",\n",
      "      \"stages.0.1.norm.bias\",\n",
      "      \"stages.0.1.pwconv1.bias\",\n",
      "      \"stages.0.1.pwconv2.bias\",\n",
      "      \"stages.0.2.gamma\",\n",
      "      \"stages.0.2.dwconv.bias\",\n",
      "      \"stages.0.2.norm.weight\",\n",
      "      \"stages.0.2.norm.bias\",\n",
      "      \"stages.0.2.pwconv1.bias\",\n",
      "      \"stages.0.2.pwconv2.bias\",\n",
      "      \"stages.1.0.gamma\",\n",
      "      \"stages.1.0.dwconv.bias\",\n",
      "      \"stages.1.0.norm.weight\",\n",
      "      \"stages.1.0.norm.bias\",\n",
      "      \"stages.1.0.pwconv1.bias\",\n",
      "      \"stages.1.0.pwconv2.bias\",\n",
      "      \"stages.1.1.gamma\",\n",
      "      \"stages.1.1.dwconv.bias\",\n",
      "      \"stages.1.1.norm.weight\",\n",
      "      \"stages.1.1.norm.bias\",\n",
      "      \"stages.1.1.pwconv1.bias\",\n",
      "      \"stages.1.1.pwconv2.bias\",\n",
      "      \"stages.1.2.gamma\",\n",
      "      \"stages.1.2.dwconv.bias\",\n",
      "      \"stages.1.2.norm.weight\",\n",
      "      \"stages.1.2.norm.bias\",\n",
      "      \"stages.1.2.pwconv1.bias\",\n",
      "      \"stages.1.2.pwconv2.bias\",\n",
      "      \"stages.2.0.gamma\",\n",
      "      \"stages.2.0.dwconv.bias\",\n",
      "      \"stages.2.0.norm.weight\",\n",
      "      \"stages.2.0.norm.bias\",\n",
      "      \"stages.2.0.pwconv1.bias\",\n",
      "      \"stages.2.0.pwconv2.bias\",\n",
      "      \"stages.2.1.gamma\",\n",
      "      \"stages.2.1.dwconv.bias\",\n",
      "      \"stages.2.1.norm.weight\",\n",
      "      \"stages.2.1.norm.bias\",\n",
      "      \"stages.2.1.pwconv1.bias\",\n",
      "      \"stages.2.1.pwconv2.bias\",\n",
      "      \"stages.2.2.gamma\",\n",
      "      \"stages.2.2.dwconv.bias\",\n",
      "      \"stages.2.2.norm.weight\",\n",
      "      \"stages.2.2.norm.bias\",\n",
      "      \"stages.2.2.pwconv1.bias\",\n",
      "      \"stages.2.2.pwconv2.bias\",\n",
      "      \"stages.2.3.gamma\",\n",
      "      \"stages.2.3.dwconv.bias\",\n",
      "      \"stages.2.3.norm.weight\",\n",
      "      \"stages.2.3.norm.bias\",\n",
      "      \"stages.2.3.pwconv1.bias\",\n",
      "      \"stages.2.3.pwconv2.bias\",\n",
      "      \"stages.2.4.gamma\",\n",
      "      \"stages.2.4.dwconv.bias\",\n",
      "      \"stages.2.4.norm.weight\",\n",
      "      \"stages.2.4.norm.bias\",\n",
      "      \"stages.2.4.pwconv1.bias\",\n",
      "      \"stages.2.4.pwconv2.bias\",\n",
      "      \"stages.2.5.gamma\",\n",
      "      \"stages.2.5.dwconv.bias\",\n",
      "      \"stages.2.5.norm.weight\",\n",
      "      \"stages.2.5.norm.bias\",\n",
      "      \"stages.2.5.pwconv1.bias\",\n",
      "      \"stages.2.5.pwconv2.bias\",\n",
      "      \"stages.2.6.gamma\",\n",
      "      \"stages.2.6.dwconv.bias\",\n",
      "      \"stages.2.6.norm.weight\",\n",
      "      \"stages.2.6.norm.bias\",\n",
      "      \"stages.2.6.pwconv1.bias\",\n",
      "      \"stages.2.6.pwconv2.bias\",\n",
      "      \"stages.2.7.gamma\",\n",
      "      \"stages.2.7.dwconv.bias\",\n",
      "      \"stages.2.7.norm.weight\",\n",
      "      \"stages.2.7.norm.bias\",\n",
      "      \"stages.2.7.pwconv1.bias\",\n",
      "      \"stages.2.7.pwconv2.bias\",\n",
      "      \"stages.2.8.gamma\",\n",
      "      \"stages.2.8.dwconv.bias\",\n",
      "      \"stages.2.8.norm.weight\",\n",
      "      \"stages.2.8.norm.bias\",\n",
      "      \"stages.2.8.pwconv1.bias\",\n",
      "      \"stages.2.8.pwconv2.bias\",\n",
      "      \"stages.3.0.gamma\",\n",
      "      \"stages.3.0.dwconv.bias\",\n",
      "      \"stages.3.0.norm.weight\",\n",
      "      \"stages.3.0.norm.bias\",\n",
      "      \"stages.3.0.pwconv1.bias\",\n",
      "      \"stages.3.0.pwconv2.bias\",\n",
      "      \"stages.3.1.gamma\",\n",
      "      \"stages.3.1.dwconv.bias\",\n",
      "      \"stages.3.1.norm.weight\",\n",
      "      \"stages.3.1.norm.bias\",\n",
      "      \"stages.3.1.pwconv1.bias\",\n",
      "      \"stages.3.1.pwconv2.bias\",\n",
      "      \"stages.3.2.gamma\",\n",
      "      \"stages.3.2.dwconv.bias\",\n",
      "      \"stages.3.2.norm.weight\",\n",
      "      \"stages.3.2.norm.bias\",\n",
      "      \"stages.3.2.pwconv1.bias\",\n",
      "      \"stages.3.2.pwconv2.bias\",\n",
      "      \"norm.weight\",\n",
      "      \"norm.bias\",\n",
      "      \"head.bias\"\n",
      "    ],\n",
      "    \"lr_scale\": 1.0\n",
      "  }\n",
      "}\n",
      "Use Cosine LR scheduler\n",
      "Set warmup steps = 700\n",
      "Set warmup steps = 0\n",
      "Max WD = 0.0500000, Min WD = 0.0500000\n",
      "criterion = SoftTargetCrossEntropy()\n",
      "Auto resume checkpoint: \n",
      "Eval only mode\n",
      "[0 0 0 0 0 0 0 0 0 0 0 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 3 0 0 0 0 0 0 0\n",
      " 0 0 0 3 0 1 0 0 3 0 0 3 0 0 0 0 0 0 0 0 3 0 0 0 0 0 0 0 3 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 1 0 2 0 0 1 0 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "Test:  [0/6]  eta: 0:02:57  loss: 0.3703 (0.3703)  acc1: 88.5417 (88.5417)  acc5: 100.0000 (100.0000)  time: 29.5057  data: 27.4677  max mem: 1917\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 0 3 1 0 0 0 0 3 1 3 3 1]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "[3 3 1 1 1 1 3 3 0 1 0 0 1 3 1 0 3 3 3 1 0 3 1 3 0 0 0 0 0 1 0 0 1 1 1 1 1\n",
      " 3 1 1 1 1 1 1 1 3 3 1 1 1 0 3 1 1 1 0 1 0 1 1 1 3 1 1 3 1 0 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2]\n",
      "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2]\n",
      "[2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
      "[2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
      "[2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 3\n",
      " 3 3 3 3 3 3 3 3 3 3 3 3 3 3 0 3 0 3 3 3 3 3 3 3 3 3 3 0 3 3 3 3 3 3 3 3 3\n",
      " 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3]\n",
      "[2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 3\n",
      " 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3\n",
      " 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3]\n",
      "[3 3 0 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3\n",
      " 3 3 3 3 3 3 3 3 3 3 3 3 3 3 0 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3\n",
      " 3 3 3 3 3 3]\n",
      "[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3\n",
      " 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3\n",
      " 3 3 3 3 3 3]\n",
      "Test:  [5/6]  eta: 0:00:05  loss: 0.1841 (0.3129)  acc1: 90.6250 (89.8214)  acc5: 100.0000 (100.0000)  time: 5.1487  data: 4.5780  max mem: 1917\n",
      "Test: Total time: 0:00:31 (5.2515 s / it)\n",
      "* Acc@1 89.821 Acc@5 100.000 loss 0.313\n",
      "[[129   3   1   7]\n",
      " [ 21  99   0  20]\n",
      " [  0   0 140   0]\n",
      " [  5   0   0 135]]\n",
      "(4, 4)\n",
      "Accuracy of the network on 560 test images: 89.82143%\n"
     ]
    }
   ],
   "source": [
    "!python main.py --eval true \\\n",
    "--model  my_model \\\n",
    "--nb_classes 4 \\\n",
    "--input_size 224 --drop_path 0.2 \\\n",
    "--data_path C:/Users/qiezh/Desktop/FYP/FYPConvNext/ChestXRays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a850bcc5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21dcc72a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_loader_val = torch.utils.data.DataLoader(\n",
    "            dataset_val, sampler=sampler_val,\n",
    "            batch_size=int(1.5 * args.batch_size),\n",
    "            num_workers=args.num_workers,\n",
    "            pin_memory=args.pin_mem,\n",
    "            drop_last=False\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bae926c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(data_loader, model, device, use_amp=False):\n",
    "  \n",
    "    y_pred = []\n",
    "    y_true = []\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "#     metric_logger = utils.MetricLogger(delimiter=\"  \")\n",
    "    header = 'Test:'\n",
    "\n",
    "    # switch to evaluation mode\n",
    "    model.eval()\n",
    "    for batch in metric_logger.log_every(data_loader, 10, header):\n",
    "        images = batch[0]\n",
    "        target = batch[-1]\n",
    "\n",
    "        images = images.to(device, non_blocking=True)\n",
    "        target = target.to(device, non_blocking=True)\n",
    "\n",
    "        # compute output\n",
    "        if use_amp:\n",
    "            with torch.cuda.amp.autocast():\n",
    "                output = model(images)\n",
    "                loss = criterion(output, target)\n",
    "        else:\n",
    "            output = model(images)\n",
    "            loss = criterion(output, target)\n",
    "            \n",
    "#         print(output)\n",
    "# #         print(target)\n",
    "# #         break\n",
    "        output_classes = (torch.max(torch.exp(output), 1)[1]).data.cpu().numpy()\n",
    "        print(output_classes)\n",
    "        y_pred.extend(output_classes) # Save Prediction\n",
    "\n",
    "        labels = target.data.cpu().numpy()\n",
    "        print(labels)\n",
    "        y_true.extend(labels) # Save Truth\n",
    "  \n",
    "        acc1, acc5 = accuracy(output, target, topk=(1, 5))\n",
    "\n",
    "        batch_size = images.shape[0]\n",
    "        metric_logger.update(loss=loss.item())\n",
    "        metric_logger.meters['acc1'].update(acc1.item(), n=batch_size)\n",
    "        metric_logger.meters['acc5'].update(acc5.item(), n=batch_size)\n",
    "        \n",
    "    # #confusion matrix\n",
    "    # cf_matrix = confusion_matrix(y_true, y_pred)\n",
    "    # #metric_logger.meters['acc5'] \n",
    "    \n",
    "    # gather the stats from all processes\n",
    "    metric_logger.synchronize_between_processes()\n",
    "    print('* Acc@1 {top1.global_avg:.3f} Acc@5 {top5.global_avg:.3f} loss {losses.global_avg:.3f}'\n",
    "          .format(top1=metric_logger.acc1, top5=metric_logger.acc5, losses=metric_logger.loss))\n",
    "\n",
    "    return {k: meter.global_avg for k, meter in metric_logger.meters.items()}\n",
    "    # print(metrics)\n",
    "    # metrics['confusion_matrix'] = cf_matrix\n",
    "    \n",
    "    # # print(metrics['confusion_matrix'])\n",
    "    # # print(metrics['confusion_matrix'].shape)\n",
    "    # return metrics"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
