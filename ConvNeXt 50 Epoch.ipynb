{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a94afaa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import seaborn as sn\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8f422b52",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mqpua0001\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import wandb\n",
    "wandb.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "49350b68",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not using distributed mode\n",
      "Namespace(aa='rand-m9-mstd0.5-inc1', auto_resume=True, batch_size=10, clip_grad=None, color_jitter=0.4, crop_pct=None, cutmix=0.0, cutmix_minmax=None, data_path='C:/Users/qiezh/Desktop/FYP/FYPConvNext/ChestXRays/train', data_set='image_folder', device='cuda', disable_eval=False, dist_eval=True, dist_on_itp=False, dist_url='env://', distributed=False, drop_path=0, enable_wandb=True, epochs=50, eval=False, eval_data_path='C:/Users/qiezh/Desktop/FYP/FYPConvNext/ChestXRays/val', finetune='convnext_tiny_1k_224_ema.pth', head_init_scale=1.0, imagenet_default_mean_and_std=True, input_size=224, layer_decay=1.0, layer_scale_init_value=1e-06, local_rank=-1, log_dir=None, lr=0.0004, min_lr=1e-06, mixup=0.0, mixup_mode='batch', mixup_prob=1.0, mixup_switch_prob=0.5, model='convnext_tiny', model_ema=False, model_ema_decay=0.9999, model_ema_eval=False, model_ema_force_cpu=False, model_key='model|module', model_prefix='', momentum=0.9, nb_classes=4, num_workers=8, opt='adamw', opt_betas=None, opt_eps=1e-08, output_dir='C:/Users/qiezh/Desktop/FYP/FYPConvNext/ConvNextResults/Results50epoch', pin_mem=True, project='convnext', recount=1, remode='pixel', reprob=0.25, resplit=False, resume='', save_ckpt=True, save_ckpt_freq=1, save_ckpt_num=3, seed=0, smoothing=0.1, start_epoch=0, train_interpolation='bicubic', update_freq=1, use_amp=False, wandb_ckpt=True, warmup_epochs=0, warmup_steps=-1, weight_decay=0.05, weight_decay_end=None, world_size=1)\n",
      "Transform = \n",
      "RandomResizedCropAndInterpolation(size=(224, 224), scale=(0.08, 1.0), ratio=(0.75, 1.3333), interpolation=PIL.Image.BICUBIC)\n",
      "RandomHorizontalFlip(p=0.5)\n",
      "<timm.data.auto_augment.RandAugment object at 0x000001450C7EED60>\n",
      "ToTensor()\n",
      "Normalize(mean=tensor([0.4850, 0.4560, 0.4060]), std=tensor([0.2290, 0.2240, 0.2250]))\n",
      "<timm.data.random_erasing.RandomErasing object at 0x000001450C7FD130>\n",
      "---------------------------\n",
      "Number of the class = 4\n",
      "Transform = \n",
      "Resize(size=256, interpolation=bicubic)\n",
      "CenterCrop(size=(224, 224))\n",
      "ToTensor()\n",
      "Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225))\n",
      "---------------------------\n",
      "Number of the class = 4\n",
      "Sampler_train = <torch.utils.data.distributed.DistributedSampler object at 0x000001450C7EE370>\n",
      "Load ckpt from convnext_tiny_1k_224_ema.pth\n",
      "Load state_dict by model_key = model\n",
      "Removing key head.weight from pretrained checkpoint\n",
      "Removing key head.bias from pretrained checkpoint\n",
      "Weights of ConvNeXt not initialized from pretrained model: ['head.weight', 'head.bias']\n",
      "Model = ConvNeXt(\n",
      "  (downsample_layers): ModuleList(\n",
      "    (0): Sequential(\n",
      "      (0): Conv2d(3, 96, kernel_size=(4, 4), stride=(4, 4))\n",
      "      (1): LayerNorm()\n",
      "    )\n",
      "    (1): Sequential(\n",
      "      (0): LayerNorm()\n",
      "      (1): Conv2d(96, 192, kernel_size=(2, 2), stride=(2, 2))\n",
      "    )\n",
      "    (2): Sequential(\n",
      "      (0): LayerNorm()\n",
      "      (1): Conv2d(192, 384, kernel_size=(2, 2), stride=(2, 2))\n",
      "    )\n",
      "    (3): Sequential(\n",
      "      (0): LayerNorm()\n",
      "      (1): Conv2d(384, 768, kernel_size=(2, 2), stride=(2, 2))\n",
      "    )\n",
      "  )\n",
      "  (stages): ModuleList(\n",
      "    (0): Sequential(\n",
      "      (0): Block(\n",
      "        (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)\n",
      "        (norm): LayerNorm()\n",
      "        (pwconv1): Linear(in_features=96, out_features=384, bias=True)\n",
      "        (act): GELU()\n",
      "        (pwconv2): Linear(in_features=384, out_features=96, bias=True)\n",
      "        (drop_path): Identity()\n",
      "      )\n",
      "      (1): Block(\n",
      "        (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)\n",
      "        (norm): LayerNorm()\n",
      "        (pwconv1): Linear(in_features=96, out_features=384, bias=True)\n",
      "        (act): GELU()\n",
      "        (pwconv2): Linear(in_features=384, out_features=96, bias=True)\n",
      "        (drop_path): Identity()\n",
      "      )\n",
      "      (2): Block(\n",
      "        (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)\n",
      "        (norm): LayerNorm()\n",
      "        (pwconv1): Linear(in_features=96, out_features=384, bias=True)\n",
      "        (act): GELU()\n",
      "        (pwconv2): Linear(in_features=384, out_features=96, bias=True)\n",
      "        (drop_path): Identity()\n",
      "      )\n",
      "    )\n",
      "    (1): Sequential(\n",
      "      (0): Block(\n",
      "        (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)\n",
      "        (norm): LayerNorm()\n",
      "        (pwconv1): Linear(in_features=192, out_features=768, bias=True)\n",
      "        (act): GELU()\n",
      "        (pwconv2): Linear(in_features=768, out_features=192, bias=True)\n",
      "        (drop_path): Identity()\n",
      "      )\n",
      "      (1): Block(\n",
      "        (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)\n",
      "        (norm): LayerNorm()\n",
      "        (pwconv1): Linear(in_features=192, out_features=768, bias=True)\n",
      "        (act): GELU()\n",
      "        (pwconv2): Linear(in_features=768, out_features=192, bias=True)\n",
      "        (drop_path): Identity()\n",
      "      )\n",
      "      (2): Block(\n",
      "        (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)\n",
      "        (norm): LayerNorm()\n",
      "        (pwconv1): Linear(in_features=192, out_features=768, bias=True)\n",
      "        (act): GELU()\n",
      "        (pwconv2): Linear(in_features=768, out_features=192, bias=True)\n",
      "        (drop_path): Identity()\n",
      "      )\n",
      "    )\n",
      "    (2): Sequential(\n",
      "      (0): Block(\n",
      "        (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n",
      "        (norm): LayerNorm()\n",
      "        (pwconv1): Linear(in_features=384, out_features=1536, bias=True)\n",
      "        (act): GELU()\n",
      "        (pwconv2): Linear(in_features=1536, out_features=384, bias=True)\n",
      "        (drop_path): Identity()\n",
      "      )\n",
      "      (1): Block(\n",
      "        (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n",
      "        (norm): LayerNorm()\n",
      "        (pwconv1): Linear(in_features=384, out_features=1536, bias=True)\n",
      "        (act): GELU()\n",
      "        (pwconv2): Linear(in_features=1536, out_features=384, bias=True)\n",
      "        (drop_path): Identity()\n",
      "      )\n",
      "      (2): Block(\n",
      "        (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n",
      "        (norm): LayerNorm()\n",
      "        (pwconv1): Linear(in_features=384, out_features=1536, bias=True)\n",
      "        (act): GELU()\n",
      "        (pwconv2): Linear(in_features=1536, out_features=384, bias=True)\n",
      "        (drop_path): Identity()\n",
      "      )\n",
      "      (3): Block(\n",
      "        (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n",
      "        (norm): LayerNorm()\n",
      "        (pwconv1): Linear(in_features=384, out_features=1536, bias=True)\n",
      "        (act): GELU()\n",
      "        (pwconv2): Linear(in_features=1536, out_features=384, bias=True)\n",
      "        (drop_path): Identity()\n",
      "      )\n",
      "      (4): Block(\n",
      "        (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n",
      "        (norm): LayerNorm()\n",
      "        (pwconv1): Linear(in_features=384, out_features=1536, bias=True)\n",
      "        (act): GELU()\n",
      "        (pwconv2): Linear(in_features=1536, out_features=384, bias=True)\n",
      "        (drop_path): Identity()\n",
      "      )\n",
      "      (5): Block(\n",
      "        (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n",
      "        (norm): LayerNorm()\n",
      "        (pwconv1): Linear(in_features=384, out_features=1536, bias=True)\n",
      "        (act): GELU()\n",
      "        (pwconv2): Linear(in_features=1536, out_features=384, bias=True)\n",
      "        (drop_path): Identity()\n",
      "      )\n",
      "      (6): Block(\n",
      "        (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n",
      "        (norm): LayerNorm()\n",
      "        (pwconv1): Linear(in_features=384, out_features=1536, bias=True)\n",
      "        (act): GELU()\n",
      "        (pwconv2): Linear(in_features=1536, out_features=384, bias=True)\n",
      "        (drop_path): Identity()\n",
      "      )\n",
      "      (7): Block(\n",
      "        (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n",
      "        (norm): LayerNorm()\n",
      "        (pwconv1): Linear(in_features=384, out_features=1536, bias=True)\n",
      "        (act): GELU()\n",
      "        (pwconv2): Linear(in_features=1536, out_features=384, bias=True)\n",
      "        (drop_path): Identity()\n",
      "      )\n",
      "      (8): Block(\n",
      "        (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n",
      "        (norm): LayerNorm()\n",
      "        (pwconv1): Linear(in_features=384, out_features=1536, bias=True)\n",
      "        (act): GELU()\n",
      "        (pwconv2): Linear(in_features=1536, out_features=384, bias=True)\n",
      "        (drop_path): Identity()\n",
      "      )\n",
      "    )\n",
      "    (3): Sequential(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Currently logged in as: qpua0001. Use `wandb login --relogin` to force relogin\n",
      "wandb: Tracking run with wandb version 0.12.16\n",
      "wandb: Run data is saved locally in C:\\Users\\qiezh\\Desktop\\FYP\\FYPConvNext\\ConvNeXt\\wandb\\run-20220521_222210-tzjm3gaq\n",
      "wandb: Run `wandb offline` to turn off syncing.\n",
      "wandb: Syncing run genial-cosmos-9\n",
      "wandb:  View project at https://wandb.ai/qpua0001/convnext\n",
      "wandb:  View run at https://wandb.ai/qpua0001/convnext/runs/tzjm3gaq\n",
      "C:\\Users\\qiezh\\anaconda3\\envs\\convnext\\lib\\site-packages\\torchvision\\transforms\\functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  warnings.warn(\n",
      "C:\\Users\\qiezh\\anaconda3\\envs\\convnext\\lib\\site-packages\\torchvision\\transforms\\functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  warnings.warn(\n",
      "C:\\Users\\qiezh\\anaconda3\\envs\\convnext\\lib\\site-packages\\torchvision\\transforms\\functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  warnings.warn(\n",
      "C:\\Users\\qiezh\\anaconda3\\envs\\convnext\\lib\\site-packages\\torchvision\\transforms\\functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  warnings.warn(\n",
      "C:\\Users\\qiezh\\anaconda3\\envs\\convnext\\lib\\site-packages\\torchvision\\transforms\\functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  warnings.warn(\n",
      "C:\\Users\\qiezh\\anaconda3\\envs\\convnext\\lib\\site-packages\\torchvision\\transforms\\functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  warnings.warn(\n",
      "C:\\Users\\qiezh\\anaconda3\\envs\\convnext\\lib\\site-packages\\torchvision\\transforms\\functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  warnings.warn(\n",
      "C:\\Users\\qiezh\\anaconda3\\envs\\convnext\\lib\\site-packages\\torchvision\\transforms\\functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  warnings.warn(\n",
      "C:\\Users\\qiezh\\anaconda3\\envs\\convnext\\lib\\site-packages\\torchvision\\transforms\\functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  warnings.warn(\n",
      "C:\\Users\\qiezh\\anaconda3\\envs\\convnext\\lib\\site-packages\\torchvision\\transforms\\functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  warnings.warn(\n",
      "C:\\Users\\qiezh\\anaconda3\\envs\\convnext\\lib\\site-packages\\torchvision\\transforms\\functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  warnings.warn(\n",
      "C:\\Users\\qiezh\\anaconda3\\envs\\convnext\\lib\\site-packages\\torchvision\\transforms\\functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  warnings.warn(\n",
      "C:\\Users\\qiezh\\anaconda3\\envs\\convnext\\lib\\site-packages\\torchvision\\transforms\\functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  warnings.warn(\n",
      "C:\\Users\\qiezh\\anaconda3\\envs\\convnext\\lib\\site-packages\\torchvision\\transforms\\functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  warnings.warn(\n",
      "C:\\Users\\qiezh\\anaconda3\\envs\\convnext\\lib\\site-packages\\torchvision\\transforms\\functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  warnings.warn(\n",
      "C:\\Users\\qiezh\\anaconda3\\envs\\convnext\\lib\\site-packages\\torchvision\\transforms\\functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  warnings.warn(\n",
      "C:\\Users\\qiezh\\anaconda3\\envs\\convnext\\lib\\site-packages\\torchvision\\transforms\\functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  warnings.warn(\n",
      "C:\\Users\\qiezh\\anaconda3\\envs\\convnext\\lib\\site-packages\\torchvision\\transforms\\functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  warnings.warn(\n",
      "C:\\Users\\qiezh\\anaconda3\\envs\\convnext\\lib\\site-packages\\torchvision\\transforms\\functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  warnings.warn(\n",
      "C:\\Users\\qiezh\\anaconda3\\envs\\convnext\\lib\\site-packages\\torchvision\\transforms\\functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  warnings.warn(\n",
      "C:\\Users\\qiezh\\anaconda3\\envs\\convnext\\lib\\site-packages\\torchvision\\transforms\\functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  warnings.warn(\n",
      "C:\\Users\\qiezh\\anaconda3\\envs\\convnext\\lib\\site-packages\\torchvision\\transforms\\functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  warnings.warn(\n",
      "C:\\Users\\qiezh\\anaconda3\\envs\\convnext\\lib\\site-packages\\torchvision\\transforms\\functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  warnings.warn(\n",
      "C:\\Users\\qiezh\\anaconda3\\envs\\convnext\\lib\\site-packages\\torchvision\\transforms\\functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  warnings.warn(\n",
      "C:\\Users\\qiezh\\anaconda3\\envs\\convnext\\lib\\site-packages\\torchvision\\transforms\\functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  warnings.warn(\n",
      "C:\\Users\\qiezh\\anaconda3\\envs\\convnext\\lib\\site-packages\\torchvision\\transforms\\functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  warnings.warn(\n",
      "C:\\Users\\qiezh\\anaconda3\\envs\\convnext\\lib\\site-packages\\torchvision\\transforms\\functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  warnings.warn(\n",
      "C:\\Users\\qiezh\\anaconda3\\envs\\convnext\\lib\\site-packages\\torchvision\\transforms\\functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  warnings.warn(\n",
      "C:\\Users\\qiezh\\anaconda3\\envs\\convnext\\lib\\site-packages\\torchvision\\transforms\\functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  warnings.warn(\n",
      "C:\\Users\\qiezh\\anaconda3\\envs\\convnext\\lib\\site-packages\\torchvision\\transforms\\functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  warnings.warn(\n",
      "C:\\Users\\qiezh\\anaconda3\\envs\\convnext\\lib\\site-packages\\torchvision\\transforms\\functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  warnings.warn(\n",
      "C:\\Users\\qiezh\\anaconda3\\envs\\convnext\\lib\\site-packages\\torchvision\\transforms\\functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  warnings.warn(\n",
      "C:\\Users\\qiezh\\anaconda3\\envs\\convnext\\lib\\site-packages\\torchvision\\transforms\\functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  warnings.warn(\n",
      "C:\\Users\\qiezh\\anaconda3\\envs\\convnext\\lib\\site-packages\\torchvision\\transforms\\functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  warnings.warn(\n",
      "C:\\Users\\qiezh\\anaconda3\\envs\\convnext\\lib\\site-packages\\torchvision\\transforms\\functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  warnings.warn(\n",
      "C:\\Users\\qiezh\\anaconda3\\envs\\convnext\\lib\\site-packages\\torchvision\\transforms\\functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  warnings.warn(\n",
      "C:\\Users\\qiezh\\anaconda3\\envs\\convnext\\lib\\site-packages\\torchvision\\transforms\\functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  warnings.warn(\n",
      "C:\\Users\\qiezh\\anaconda3\\envs\\convnext\\lib\\site-packages\\torchvision\\transforms\\functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  warnings.warn(\n",
      "C:\\Users\\qiezh\\anaconda3\\envs\\convnext\\lib\\site-packages\\torchvision\\transforms\\functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  warnings.warn(\n",
      "C:\\Users\\qiezh\\anaconda3\\envs\\convnext\\lib\\site-packages\\torchvision\\transforms\\functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  warnings.warn(\n",
      "C:\\Users\\qiezh\\anaconda3\\envs\\convnext\\lib\\site-packages\\torchvision\\transforms\\functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  warnings.warn(\n",
      "C:\\Users\\qiezh\\anaconda3\\envs\\convnext\\lib\\site-packages\\torchvision\\transforms\\functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  warnings.warn(\n",
      "C:\\Users\\qiezh\\anaconda3\\envs\\convnext\\lib\\site-packages\\torchvision\\transforms\\functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  warnings.warn(\n",
      "C:\\Users\\qiezh\\anaconda3\\envs\\convnext\\lib\\site-packages\\torchvision\\transforms\\functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  warnings.warn(\n",
      "C:\\Users\\qiezh\\anaconda3\\envs\\convnext\\lib\\site-packages\\torchvision\\transforms\\functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  warnings.warn(\n",
      "C:\\Users\\qiezh\\anaconda3\\envs\\convnext\\lib\\site-packages\\torchvision\\transforms\\functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  warnings.warn(\n",
      "C:\\Users\\qiezh\\anaconda3\\envs\\convnext\\lib\\site-packages\\torchvision\\transforms\\functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  warnings.warn(\n",
      "C:\\Users\\qiezh\\anaconda3\\envs\\convnext\\lib\\site-packages\\torchvision\\transforms\\functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  warnings.warn(\n",
      "C:\\Users\\qiezh\\anaconda3\\envs\\convnext\\lib\\site-packages\\torchvision\\transforms\\functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  warnings.warn(\n",
      "C:\\Users\\qiezh\\anaconda3\\envs\\convnext\\lib\\site-packages\\torchvision\\transforms\\functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  warnings.warn(\n",
      "C:\\Users\\qiezh\\anaconda3\\envs\\convnext\\lib\\site-packages\\torchvision\\transforms\\functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  warnings.warn(\n",
      "C:\\Users\\qiezh\\anaconda3\\envs\\convnext\\lib\\site-packages\\torchvision\\transforms\\functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  warnings.warn(\n",
      "C:\\Users\\qiezh\\anaconda3\\envs\\convnext\\lib\\site-packages\\torchvision\\transforms\\functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  warnings.warn(\n",
      "C:\\Users\\qiezh\\anaconda3\\envs\\convnext\\lib\\site-packages\\torchvision\\transforms\\functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  warnings.warn(\n",
      "C:\\Users\\qiezh\\anaconda3\\envs\\convnext\\lib\\site-packages\\torchvision\\transforms\\functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  warnings.warn(\n",
      "C:\\Users\\qiezh\\anaconda3\\envs\\convnext\\lib\\site-packages\\torchvision\\transforms\\functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  warnings.warn(\n",
      "C:\\Users\\qiezh\\anaconda3\\envs\\convnext\\lib\\site-packages\\torchvision\\transforms\\functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  warnings.warn(\n",
      "C:\\Users\\qiezh\\anaconda3\\envs\\convnext\\lib\\site-packages\\torchvision\\transforms\\functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  warnings.warn(\n",
      "C:\\Users\\qiezh\\anaconda3\\envs\\convnext\\lib\\site-packages\\torchvision\\transforms\\functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  warnings.warn(\n",
      "C:\\Users\\qiezh\\anaconda3\\envs\\convnext\\lib\\site-packages\\torchvision\\transforms\\functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  warnings.warn(\n",
      "C:\\Users\\qiezh\\anaconda3\\envs\\convnext\\lib\\site-packages\\torchvision\\transforms\\functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  warnings.warn(\n",
      "C:\\Users\\qiezh\\anaconda3\\envs\\convnext\\lib\\site-packages\\torchvision\\transforms\\functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  warnings.warn(\n",
      "C:\\Users\\qiezh\\anaconda3\\envs\\convnext\\lib\\site-packages\\torchvision\\transforms\\functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  warnings.warn(\n",
      "C:\\Users\\qiezh\\anaconda3\\envs\\convnext\\lib\\site-packages\\torchvision\\transforms\\functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  warnings.warn(\n",
      "C:\\Users\\qiezh\\anaconda3\\envs\\convnext\\lib\\site-packages\\torchvision\\transforms\\functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  warnings.warn(\n",
      "C:\\Users\\qiezh\\anaconda3\\envs\\convnext\\lib\\site-packages\\torchvision\\transforms\\functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  warnings.warn(\n",
      "C:\\Users\\qiezh\\anaconda3\\envs\\convnext\\lib\\site-packages\\torchvision\\transforms\\functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  warnings.warn(\n",
      "C:\\Users\\qiezh\\anaconda3\\envs\\convnext\\lib\\site-packages\\torchvision\\transforms\\functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  warnings.warn(\n",
      "C:\\Users\\qiezh\\anaconda3\\envs\\convnext\\lib\\site-packages\\torchvision\\transforms\\functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  warnings.warn(\n",
      "C:\\Users\\qiezh\\anaconda3\\envs\\convnext\\lib\\site-packages\\torchvision\\transforms\\functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  warnings.warn(\n",
      "C:\\Users\\qiezh\\anaconda3\\envs\\convnext\\lib\\site-packages\\torchvision\\transforms\\functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  warnings.warn(\n",
      "C:\\Users\\qiezh\\anaconda3\\envs\\convnext\\lib\\site-packages\\torchvision\\transforms\\functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  warnings.warn(\n",
      "C:\\Users\\qiezh\\anaconda3\\envs\\convnext\\lib\\site-packages\\torchvision\\transforms\\functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  warnings.warn(\n",
      "C:\\Users\\qiezh\\anaconda3\\envs\\convnext\\lib\\site-packages\\torchvision\\transforms\\functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  warnings.warn(\n",
      "C:\\Users\\qiezh\\anaconda3\\envs\\convnext\\lib\\site-packages\\torchvision\\transforms\\functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  warnings.warn(\n",
      "C:\\Users\\qiezh\\anaconda3\\envs\\convnext\\lib\\site-packages\\torchvision\\transforms\\functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  warnings.warn(\n",
      "C:\\Users\\qiezh\\anaconda3\\envs\\convnext\\lib\\site-packages\\torchvision\\transforms\\functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  warnings.warn(\n",
      "C:\\Users\\qiezh\\anaconda3\\envs\\convnext\\lib\\site-packages\\torchvision\\transforms\\functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  warnings.warn(\n",
      "C:\\Users\\qiezh\\anaconda3\\envs\\convnext\\lib\\site-packages\\torchvision\\transforms\\functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  warnings.warn(\n",
      "C:\\Users\\qiezh\\anaconda3\\envs\\convnext\\lib\\site-packages\\torchvision\\transforms\\functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  warnings.warn(\n",
      "C:\\Users\\qiezh\\anaconda3\\envs\\convnext\\lib\\site-packages\\torchvision\\transforms\\functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  warnings.warn(\n",
      "C:\\Users\\qiezh\\anaconda3\\envs\\convnext\\lib\\site-packages\\torchvision\\transforms\\functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  warnings.warn(\n",
      "C:\\Users\\qiezh\\anaconda3\\envs\\convnext\\lib\\site-packages\\torchvision\\transforms\\functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  warnings.warn(\n",
      "C:\\Users\\qiezh\\anaconda3\\envs\\convnext\\lib\\site-packages\\torchvision\\transforms\\functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  warnings.warn(\n",
      "C:\\Users\\qiezh\\anaconda3\\envs\\convnext\\lib\\site-packages\\torchvision\\transforms\\functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  warnings.warn(\n",
      "C:\\Users\\qiezh\\anaconda3\\envs\\convnext\\lib\\site-packages\\torchvision\\transforms\\functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  warnings.warn(\n",
      "C:\\Users\\qiezh\\anaconda3\\envs\\convnext\\lib\\site-packages\\torchvision\\transforms\\functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  warnings.warn(\n",
      "C:\\Users\\qiezh\\anaconda3\\envs\\convnext\\lib\\site-packages\\torchvision\\transforms\\functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  warnings.warn(\n",
      "C:\\Users\\qiezh\\anaconda3\\envs\\convnext\\lib\\site-packages\\torchvision\\transforms\\functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  warnings.warn(\n",
      "C:\\Users\\qiezh\\anaconda3\\envs\\convnext\\lib\\site-packages\\torchvision\\transforms\\functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  warnings.warn(\n",
      "C:\\Users\\qiezh\\anaconda3\\envs\\convnext\\lib\\site-packages\\torchvision\\transforms\\functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  warnings.warn(\n",
      "C:\\Users\\qiezh\\anaconda3\\envs\\convnext\\lib\\site-packages\\torchvision\\transforms\\functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  warnings.warn(\n",
      "C:\\Users\\qiezh\\anaconda3\\envs\\convnext\\lib\\site-packages\\torchvision\\transforms\\functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  warnings.warn(\n",
      "C:\\Users\\qiezh\\anaconda3\\envs\\convnext\\lib\\site-packages\\torchvision\\transforms\\functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  warnings.warn(\n",
      "C:\\Users\\qiezh\\anaconda3\\envs\\convnext\\lib\\site-packages\\torchvision\\transforms\\functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  warnings.warn(\n",
      "C:\\Users\\qiezh\\anaconda3\\envs\\convnext\\lib\\site-packages\\torchvision\\transforms\\functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  warnings.warn(\n",
      "C:\\Users\\qiezh\\anaconda3\\envs\\convnext\\lib\\site-packages\\torchvision\\transforms\\functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  warnings.warn(\n",
      "C:\\Users\\qiezh\\anaconda3\\envs\\convnext\\lib\\site-packages\\torchvision\\transforms\\functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  warnings.warn(\n",
      "C:\\Users\\qiezh\\anaconda3\\envs\\convnext\\lib\\site-packages\\torchvision\\transforms\\functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  warnings.warn(\n",
      "C:\\Users\\qiezh\\anaconda3\\envs\\convnext\\lib\\site-packages\\torchvision\\transforms\\functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  warnings.warn(\n",
      "C:\\Users\\qiezh\\anaconda3\\envs\\convnext\\lib\\site-packages\\torchvision\\transforms\\functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  warnings.warn(\n",
      "C:\\Users\\qiezh\\anaconda3\\envs\\convnext\\lib\\site-packages\\torchvision\\transforms\\functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  warnings.warn(\n",
      "C:\\Users\\qiezh\\anaconda3\\envs\\convnext\\lib\\site-packages\\torchvision\\transforms\\functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  warnings.warn(\n",
      "C:\\Users\\qiezh\\anaconda3\\envs\\convnext\\lib\\site-packages\\torchvision\\transforms\\functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  warnings.warn(\n",
      "C:\\Users\\qiezh\\anaconda3\\envs\\convnext\\lib\\site-packages\\torchvision\\transforms\\functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  warnings.warn(\n",
      "C:\\Users\\qiezh\\anaconda3\\envs\\convnext\\lib\\site-packages\\torchvision\\transforms\\functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  warnings.warn(\n",
      "C:\\Users\\qiezh\\anaconda3\\envs\\convnext\\lib\\site-packages\\torchvision\\transforms\\functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  warnings.warn(\n",
      "C:\\Users\\qiezh\\anaconda3\\envs\\convnext\\lib\\site-packages\\torchvision\\transforms\\functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  warnings.warn(\n",
      "C:\\Users\\qiezh\\anaconda3\\envs\\convnext\\lib\\site-packages\\torchvision\\transforms\\functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  warnings.warn(\n",
      "C:\\Users\\qiezh\\anaconda3\\envs\\convnext\\lib\\site-packages\\torchvision\\transforms\\functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  warnings.warn(\n",
      "C:\\Users\\qiezh\\anaconda3\\envs\\convnext\\lib\\site-packages\\torchvision\\transforms\\functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  warnings.warn(\n",
      "C:\\Users\\qiezh\\anaconda3\\envs\\convnext\\lib\\site-packages\\torchvision\\transforms\\functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  warnings.warn(\n",
      "C:\\Users\\qiezh\\anaconda3\\envs\\convnext\\lib\\site-packages\\torchvision\\transforms\\functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  warnings.warn(\n",
      "C:\\Users\\qiezh\\anaconda3\\envs\\convnext\\lib\\site-packages\\torchvision\\transforms\\functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  warnings.warn(\n",
      "C:\\Users\\qiezh\\anaconda3\\envs\\convnext\\lib\\site-packages\\torchvision\\transforms\\functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  warnings.warn(\n",
      "C:\\Users\\qiezh\\anaconda3\\envs\\convnext\\lib\\site-packages\\torchvision\\transforms\\functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  warnings.warn(\n",
      "C:\\Users\\qiezh\\anaconda3\\envs\\convnext\\lib\\site-packages\\torchvision\\transforms\\functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  warnings.warn(\n",
      "C:\\Users\\qiezh\\anaconda3\\envs\\convnext\\lib\\site-packages\\torchvision\\transforms\\functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  warnings.warn(\n",
      "C:\\Users\\qiezh\\anaconda3\\envs\\convnext\\lib\\site-packages\\torchvision\\transforms\\functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  warnings.warn(\n",
      "C:\\Users\\qiezh\\anaconda3\\envs\\convnext\\lib\\site-packages\\torchvision\\transforms\\functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  warnings.warn(\n",
      "C:\\Users\\qiezh\\anaconda3\\envs\\convnext\\lib\\site-packages\\torchvision\\transforms\\functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  warnings.warn(\n",
      "C:\\Users\\qiezh\\anaconda3\\envs\\convnext\\lib\\site-packages\\torchvision\\transforms\\functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  warnings.warn(\n",
      "C:\\Users\\qiezh\\anaconda3\\envs\\convnext\\lib\\site-packages\\torchvision\\transforms\\functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  warnings.warn(\n",
      "C:\\Users\\qiezh\\anaconda3\\envs\\convnext\\lib\\site-packages\\torchvision\\transforms\\functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      (0): Block(\n",
      "        (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)\n",
      "        (norm): LayerNorm()\n",
      "        (pwconv1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "        (act): GELU()\n",
      "        (pwconv2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        (drop_path): Identity()\n",
      "      )\n",
      "      (1): Block(\n",
      "        (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)\n",
      "        (norm): LayerNorm()\n",
      "        (pwconv1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "        (act): GELU()\n",
      "        (pwconv2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        (drop_path): Identity()\n",
      "      )\n",
      "      (2): Block(\n",
      "        (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)\n",
      "        (norm): LayerNorm()\n",
      "        (pwconv1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "        (act): GELU()\n",
      "        (pwconv2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        (drop_path): Identity()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "  (head): Linear(in_features=768, out_features=4, bias=True)\n",
      ")\n",
      "number of params: 27823204\n",
      "LR = 0.00040000\n",
      "Batch size = 10\n",
      "Update frequent = 1\n",
      "Number of training examples = 2270\n",
      "Number of training training per epoch = 227\n",
      "Param groups = {\n",
      "  \"decay\": {\n",
      "    \"weight_decay\": 0.05,\n",
      "    \"params\": [\n",
      "      \"downsample_layers.0.0.weight\",\n",
      "      \"downsample_layers.1.1.weight\",\n",
      "      \"downsample_layers.2.1.weight\",\n",
      "      \"downsample_layers.3.1.weight\",\n",
      "      \"stages.0.0.dwconv.weight\",\n",
      "      \"stages.0.0.pwconv1.weight\",\n",
      "      \"stages.0.0.pwconv2.weight\",\n",
      "      \"stages.0.1.dwconv.weight\",\n",
      "      \"stages.0.1.pwconv1.weight\",\n",
      "      \"stages.0.1.pwconv2.weight\",\n",
      "      \"stages.0.2.dwconv.weight\",\n",
      "      \"stages.0.2.pwconv1.weight\",\n",
      "      \"stages.0.2.pwconv2.weight\",\n",
      "      \"stages.1.0.dwconv.weight\",\n",
      "      \"stages.1.0.pwconv1.weight\",\n",
      "      \"stages.1.0.pwconv2.weight\",\n",
      "      \"stages.1.1.dwconv.weight\",\n",
      "      \"stages.1.1.pwconv1.weight\",\n",
      "      \"stages.1.1.pwconv2.weight\",\n",
      "      \"stages.1.2.dwconv.weight\",\n",
      "      \"stages.1.2.pwconv1.weight\",\n",
      "      \"stages.1.2.pwconv2.weight\",\n",
      "      \"stages.2.0.dwconv.weight\",\n",
      "      \"stages.2.0.pwconv1.weight\",\n",
      "      \"stages.2.0.pwconv2.weight\",\n",
      "      \"stages.2.1.dwconv.weight\",\n",
      "      \"stages.2.1.pwconv1.weight\",\n",
      "      \"stages.2.1.pwconv2.weight\",\n",
      "      \"stages.2.2.dwconv.weight\",\n",
      "      \"stages.2.2.pwconv1.weight\",\n",
      "      \"stages.2.2.pwconv2.weight\",\n",
      "      \"stages.2.3.dwconv.weight\",\n",
      "      \"stages.2.3.pwconv1.weight\",\n",
      "      \"stages.2.3.pwconv2.weight\",\n",
      "      \"stages.2.4.dwconv.weight\",\n",
      "      \"stages.2.4.pwconv1.weight\",\n",
      "      \"stages.2.4.pwconv2.weight\",\n",
      "      \"stages.2.5.dwconv.weight\",\n",
      "      \"stages.2.5.pwconv1.weight\",\n",
      "      \"stages.2.5.pwconv2.weight\",\n",
      "      \"stages.2.6.dwconv.weight\",\n",
      "      \"stages.2.6.pwconv1.weight\",\n",
      "      \"stages.2.6.pwconv2.weight\",\n",
      "      \"stages.2.7.dwconv.weight\",\n",
      "      \"stages.2.7.pwconv1.weight\",\n",
      "      \"stages.2.7.pwconv2.weight\",\n",
      "      \"stages.2.8.dwconv.weight\",\n",
      "      \"stages.2.8.pwconv1.weight\",\n",
      "      \"stages.2.8.pwconv2.weight\",\n",
      "      \"stages.3.0.dwconv.weight\",\n",
      "      \"stages.3.0.pwconv1.weight\",\n",
      "      \"stages.3.0.pwconv2.weight\",\n",
      "      \"stages.3.1.dwconv.weight\",\n",
      "      \"stages.3.1.pwconv1.weight\",\n",
      "      \"stages.3.1.pwconv2.weight\",\n",
      "      \"stages.3.2.dwconv.weight\",\n",
      "      \"stages.3.2.pwconv1.weight\",\n",
      "      \"stages.3.2.pwconv2.weight\",\n",
      "      \"head.weight\"\n",
      "    ],\n",
      "    \"lr_scale\": 1.0\n",
      "  },\n",
      "  \"no_decay\": {\n",
      "    \"weight_decay\": 0.0,\n",
      "    \"params\": [\n",
      "      \"downsample_layers.0.0.bias\",\n",
      "      \"downsample_layers.0.1.weight\",\n",
      "      \"downsample_layers.0.1.bias\",\n",
      "      \"downsample_layers.1.0.weight\",\n",
      "      \"downsample_layers.1.0.bias\",\n",
      "      \"downsample_layers.1.1.bias\",\n",
      "      \"downsample_layers.2.0.weight\",\n",
      "      \"downsample_layers.2.0.bias\",\n",
      "      \"downsample_layers.2.1.bias\",\n",
      "      \"downsample_layers.3.0.weight\",\n",
      "      \"downsample_layers.3.0.bias\",\n",
      "      \"downsample_layers.3.1.bias\",\n",
      "      \"stages.0.0.gamma\",\n",
      "      \"stages.0.0.dwconv.bias\",\n",
      "      \"stages.0.0.norm.weight\",\n",
      "      \"stages.0.0.norm.bias\",\n",
      "      \"stages.0.0.pwconv1.bias\",\n",
      "      \"stages.0.0.pwconv2.bias\",\n",
      "      \"stages.0.1.gamma\",\n",
      "      \"stages.0.1.dwconv.bias\",\n",
      "      \"stages.0.1.norm.weight\",\n",
      "      \"stages.0.1.norm.bias\",\n",
      "      \"stages.0.1.pwconv1.bias\",\n",
      "      \"stages.0.1.pwconv2.bias\",\n",
      "      \"stages.0.2.gamma\",\n",
      "      \"stages.0.2.dwconv.bias\",\n",
      "      \"stages.0.2.norm.weight\",\n",
      "      \"stages.0.2.norm.bias\",\n",
      "      \"stages.0.2.pwconv1.bias\",\n",
      "      \"stages.0.2.pwconv2.bias\",\n",
      "      \"stages.1.0.gamma\",\n",
      "      \"stages.1.0.dwconv.bias\",\n",
      "      \"stages.1.0.norm.weight\",\n",
      "      \"stages.1.0.norm.bias\",\n",
      "      \"stages.1.0.pwconv1.bias\",\n",
      "      \"stages.1.0.pwconv2.bias\",\n",
      "      \"stages.1.1.gamma\",\n",
      "      \"stages.1.1.dwconv.bias\",\n",
      "      \"stages.1.1.norm.weight\",\n",
      "      \"stages.1.1.norm.bias\",\n",
      "      \"stages.1.1.pwconv1.bias\",\n",
      "      \"stages.1.1.pwconv2.bias\",\n",
      "      \"stages.1.2.gamma\",\n",
      "      \"stages.1.2.dwconv.bias\",\n",
      "      \"stages.1.2.norm.weight\",\n",
      "      \"stages.1.2.norm.bias\",\n",
      "      \"stages.1.2.pwconv1.bias\",\n",
      "      \"stages.1.2.pwconv2.bias\",\n",
      "      \"stages.2.0.gamma\",\n",
      "      \"stages.2.0.dwconv.bias\",\n",
      "      \"stages.2.0.norm.weight\",\n",
      "      \"stages.2.0.norm.bias\",\n",
      "      \"stages.2.0.pwconv1.bias\",\n",
      "      \"stages.2.0.pwconv2.bias\",\n",
      "      \"stages.2.1.gamma\",\n",
      "      \"stages.2.1.dwconv.bias\",\n",
      "      \"stages.2.1.norm.weight\",\n",
      "      \"stages.2.1.norm.bias\",\n",
      "      \"stages.2.1.pwconv1.bias\",\n",
      "      \"stages.2.1.pwconv2.bias\",\n",
      "      \"stages.2.2.gamma\",\n",
      "      \"stages.2.2.dwconv.bias\",\n",
      "      \"stages.2.2.norm.weight\",\n",
      "      \"stages.2.2.norm.bias\",\n",
      "      \"stages.2.2.pwconv1.bias\",\n",
      "      \"stages.2.2.pwconv2.bias\",\n",
      "      \"stages.2.3.gamma\",\n",
      "      \"stages.2.3.dwconv.bias\",\n",
      "      \"stages.2.3.norm.weight\",\n",
      "      \"stages.2.3.norm.bias\",\n",
      "      \"stages.2.3.pwconv1.bias\",\n",
      "      \"stages.2.3.pwconv2.bias\",\n",
      "      \"stages.2.4.gamma\",\n",
      "      \"stages.2.4.dwconv.bias\",\n",
      "      \"stages.2.4.norm.weight\",\n",
      "      \"stages.2.4.norm.bias\",\n",
      "      \"stages.2.4.pwconv1.bias\",\n",
      "      \"stages.2.4.pwconv2.bias\",\n",
      "      \"stages.2.5.gamma\",\n",
      "      \"stages.2.5.dwconv.bias\",\n",
      "      \"stages.2.5.norm.weight\",\n",
      "      \"stages.2.5.norm.bias\",\n",
      "      \"stages.2.5.pwconv1.bias\",\n",
      "      \"stages.2.5.pwconv2.bias\",\n",
      "      \"stages.2.6.gamma\",\n",
      "      \"stages.2.6.dwconv.bias\",\n",
      "      \"stages.2.6.norm.weight\",\n",
      "      \"stages.2.6.norm.bias\",\n",
      "      \"stages.2.6.pwconv1.bias\",\n",
      "      \"stages.2.6.pwconv2.bias\",\n",
      "      \"stages.2.7.gamma\",\n",
      "      \"stages.2.7.dwconv.bias\",\n",
      "      \"stages.2.7.norm.weight\",\n",
      "      \"stages.2.7.norm.bias\",\n",
      "      \"stages.2.7.pwconv1.bias\",\n",
      "      \"stages.2.7.pwconv2.bias\",\n",
      "      \"stages.2.8.gamma\",\n",
      "      \"stages.2.8.dwconv.bias\",\n",
      "      \"stages.2.8.norm.weight\",\n",
      "      \"stages.2.8.norm.bias\",\n",
      "      \"stages.2.8.pwconv1.bias\",\n",
      "      \"stages.2.8.pwconv2.bias\",\n",
      "      \"stages.3.0.gamma\",\n",
      "      \"stages.3.0.dwconv.bias\",\n",
      "      \"stages.3.0.norm.weight\",\n",
      "      \"stages.3.0.norm.bias\",\n",
      "      \"stages.3.0.pwconv1.bias\",\n",
      "      \"stages.3.0.pwconv2.bias\",\n",
      "      \"stages.3.1.gamma\",\n",
      "      \"stages.3.1.dwconv.bias\",\n",
      "      \"stages.3.1.norm.weight\",\n",
      "      \"stages.3.1.norm.bias\",\n",
      "      \"stages.3.1.pwconv1.bias\",\n",
      "      \"stages.3.1.pwconv2.bias\",\n",
      "      \"stages.3.2.gamma\",\n",
      "      \"stages.3.2.dwconv.bias\",\n",
      "      \"stages.3.2.norm.weight\",\n",
      "      \"stages.3.2.norm.bias\",\n",
      "      \"stages.3.2.pwconv1.bias\",\n",
      "      \"stages.3.2.pwconv2.bias\",\n",
      "      \"norm.weight\",\n",
      "      \"norm.bias\",\n",
      "      \"head.bias\"\n",
      "    ],\n",
      "    \"lr_scale\": 1.0\n",
      "  }\n",
      "}\n",
      "Use Cosine LR scheduler\n",
      "Set warmup steps = 0\n",
      "Set warmup steps = 0\n",
      "Max WD = 0.0500000, Min WD = 0.0500000\n",
      "criterion = LabelSmoothingCrossEntropy()\n",
      "Auto resume checkpoint: \n",
      "Start training for 50 epochs\n",
      "Epoch: [0]  [  0/227]  eta: 1:27:57  lr: 0.000400  min_lr: 0.000400  loss: 1.4363 (1.4363)  class_acc: 0.2000 (0.2000)  weight_decay: 0.0500 (0.0500)  time: 23.2472  data: 21.2718  max mem: 2500\n",
      "Epoch: [0]  [ 10/227]  eta: 0:08:04  lr: 0.000400  min_lr: 0.000400  loss: 1.2305 (1.2366)  class_acc: 0.4000 (0.4636)  weight_decay: 0.0500 (0.0500)  time: 2.2334  data: 1.9339  max mem: 2500\n",
      "Epoch: [0]  [ 20/227]  eta: 0:04:15  lr: 0.000400  min_lr: 0.000400  loss: 1.1137 (1.1330)  class_acc: 0.6000 (0.5524)  weight_decay: 0.0500 (0.0500)  time: 0.1332  data: 0.0001  max mem: 2500\n",
      "Epoch: [0]  [ 30/227]  eta: 0:02:53  lr: 0.000400  min_lr: 0.000400  loss: 0.9488 (1.0595)  class_acc: 0.6000 (0.5710)  weight_decay: 0.0500 (0.0500)  time: 0.1337  data: 0.0002  max mem: 2500\n",
      "Epoch: [0]  [ 40/227]  eta: 0:02:10  lr: 0.000400  min_lr: 0.000400  loss: 0.8030 (0.9839)  class_acc: 0.7000 (0.6195)  weight_decay: 0.0500 (0.0500)  time: 0.1355  data: 0.0002  max mem: 2500\n",
      "Epoch: [0]  [ 50/227]  eta: 0:01:43  lr: 0.000400  min_lr: 0.000400  loss: 0.6829 (0.9249)  class_acc: 0.8000 (0.6549)  weight_decay: 0.0500 (0.0500)  time: 0.1350  data: 0.0002  max mem: 2500\n",
      "Epoch: [0]  [ 60/227]  eta: 0:01:25  lr: 0.000400  min_lr: 0.000400  loss: 0.7227 (0.9038)  class_acc: 0.7000 (0.6672)  weight_decay: 0.0500 (0.0500)  time: 0.1322  data: 0.0002  max mem: 2500\n",
      "Epoch: [0]  [ 70/227]  eta: 0:01:12  lr: 0.000400  min_lr: 0.000400  loss: 0.7645 (0.8809)  class_acc: 0.7000 (0.6845)  weight_decay: 0.0500 (0.0500)  time: 0.1324  data: 0.0002  max mem: 2500\n",
      "Epoch: [0]  [ 80/227]  eta: 0:01:01  lr: 0.000400  min_lr: 0.000400  loss: 0.7835 (0.8677)  class_acc: 0.8000 (0.6951)  weight_decay: 0.0500 (0.0500)  time: 0.1330  data: 0.0003  max mem: 2500\n",
      "Epoch: [0]  [ 90/227]  eta: 0:00:53  lr: 0.000400  min_lr: 0.000400  loss: 0.7311 (0.8555)  class_acc: 0.8000 (0.7011)  weight_decay: 0.0500 (0.0500)  time: 0.1328  data: 0.0003  max mem: 2500\n",
      "Epoch: [0]  [100/227]  eta: 0:00:45  lr: 0.000400  min_lr: 0.000400  loss: 0.6691 (0.8410)  class_acc: 0.8000 (0.7129)  weight_decay: 0.0500 (0.0500)  time: 0.1323  data: 0.0001  max mem: 2500\n",
      "Epoch: [0]  [110/227]  eta: 0:00:39  lr: 0.000400  min_lr: 0.000400  loss: 0.7267 (0.8376)  class_acc: 0.8000 (0.7216)  weight_decay: 0.0500 (0.0500)  time: 0.1333  data: 0.0001  max mem: 2500\n",
      "Epoch: [0]  [120/227]  eta: 0:00:34  lr: 0.000400  min_lr: 0.000400  loss: 0.7105 (0.8170)  class_acc: 0.8000 (0.7372)  weight_decay: 0.0500 (0.0500)  time: 0.1340  data: 0.0002  max mem: 2500\n",
      "Epoch: [0]  [130/227]  eta: 0:00:30  lr: 0.000400  min_lr: 0.000400  loss: 0.6402 (0.8152)  class_acc: 0.8000 (0.7405)  weight_decay: 0.0500 (0.0500)  time: 0.1336  data: 0.0003  max mem: 2500\n",
      "Epoch: [0]  [140/227]  eta: 0:00:25  lr: 0.000400  min_lr: 0.000400  loss: 0.6430 (0.8008)  class_acc: 0.8000 (0.7504)  weight_decay: 0.0500 (0.0500)  time: 0.1321  data: 0.0002  max mem: 2500\n",
      "Epoch: [0]  [150/227]  eta: 0:00:22  lr: 0.000400  min_lr: 0.000400  loss: 0.6407 (0.8017)  class_acc: 0.8000 (0.7503)  weight_decay: 0.0500 (0.0500)  time: 0.1317  data: 0.0002  max mem: 2500\n",
      "Epoch: [0]  [160/227]  eta: 0:00:18  lr: 0.000400  min_lr: 0.000400  loss: 0.6063 (0.7910)  class_acc: 0.8000 (0.7578)  weight_decay: 0.0500 (0.0500)  time: 0.1327  data: 0.0002  max mem: 2500\n",
      "Epoch: [0]  [170/227]  eta: 0:00:15  lr: 0.000400  min_lr: 0.000400  loss: 0.6057 (0.7850)  class_acc: 0.9000 (0.7620)  weight_decay: 0.0500 (0.0500)  time: 0.1329  data: 0.0002  max mem: 2500\n",
      "Epoch: [0]  [180/227]  eta: 0:00:12  lr: 0.000400  min_lr: 0.000400  loss: 0.6057 (0.7743)  class_acc: 0.9000 (0.7691)  weight_decay: 0.0500 (0.0500)  time: 0.1335  data: 0.0002  max mem: 2500\n",
      "Epoch: [0]  [190/227]  eta: 0:00:09  lr: 0.000400  min_lr: 0.000400  loss: 0.6609 (0.7759)  class_acc: 0.8000 (0.7675)  weight_decay: 0.0500 (0.0500)  time: 0.1340  data: 0.0002  max mem: 2500\n",
      "Epoch: [0]  [200/227]  eta: 0:00:06  lr: 0.000400  min_lr: 0.000400  loss: 0.6951 (0.7706)  class_acc: 0.8000 (0.7701)  weight_decay: 0.0500 (0.0500)  time: 0.1324  data: 0.0001  max mem: 2500\n",
      "Epoch: [0]  [210/227]  eta: 0:00:04  lr: 0.000400  min_lr: 0.000400  loss: 0.6331 (0.7635)  class_acc: 0.8000 (0.7754)  weight_decay: 0.0500 (0.0500)  time: 0.1317  data: 0.0000  max mem: 2500\n",
      "Epoch: [0]  [220/227]  eta: 0:00:01  lr: 0.000400  min_lr: 0.000400  loss: 0.6166 (0.7620)  class_acc: 0.9000 (0.7760)  weight_decay: 0.0500 (0.0500)  time: 0.1329  data: 0.0001  max mem: 2500\n",
      "Epoch: [0]  [226/227]  eta: 0:00:00  lr: 0.000400  min_lr: 0.000400  loss: 0.6166 (0.7586)  class_acc: 0.8000 (0.7780)  weight_decay: 0.0500 (0.0500)  time: 0.1326  data: 0.0001  max mem: 2500\n",
      "Epoch: [0] Total time: 0:00:53 (0.2373 s / it)\n",
      "Averaged stats: lr: 0.000400  min_lr: 0.000400  loss: 0.6166 (0.7586)  class_acc: 0.8000 (0.7780)  weight_decay: 0.0500 (0.0500)\n",
      "Test:  [ 0/38]  eta: 0:13:40  loss: 0.3710 (0.3710)  acc1: 86.6667 (86.6667)  acc5: 100.0000 (100.0000)  time: 21.5967  data: 21.4617  max mem: 2500\n",
      "Test:  [10/38]  eta: 0:00:56  loss: 0.4355 (0.4994)  acc1: 86.6667 (84.8485)  acc5: 100.0000 (100.0000)  time: 2.0058  data: 1.9512  max mem: 2500\n",
      "Test:  [20/38]  eta: 0:00:19  loss: 0.5682 (0.7483)  acc1: 80.0000 (73.0159)  acc5: 100.0000 (100.0000)  time: 0.0467  data: 0.0001  max mem: 2500\n",
      "Test:  [30/38]  eta: 0:00:05  loss: 0.1811 (0.5406)  acc1: 93.3333 (81.2903)  acc5: 100.0000 (100.0000)  time: 0.0469  data: 0.0001  max mem: 2500\n",
      "Test:  [37/38]  eta: 0:00:00  loss: 0.0844 (0.4623)  acc1: 100.0000 (84.1071)  acc5: 100.0000 (100.0000)  time: 0.0487  data: 0.0001  max mem: 2500\n",
      "Test: Total time: 0:00:23 (0.6286 s / it)\n",
      "* Acc@1 84.107 Acc@5 100.000 loss 0.462\n",
      "[[116   0   6  18]\n",
      " [ 34  82   0  24]\n",
      " [  0   0 136   4]\n",
      " [  2   1   0 137]]\n",
      "(4, 4)\n",
      "Accuracy of the model on the 560 test images: 84.1%\n",
      "Max accuracy: 84.11%\n",
      "Epoch: [1]  [  0/227]  eta: 1:21:53  lr: 0.000400  min_lr: 0.000400  loss: 0.5546 (0.5546)  class_acc: 0.9000 (0.9000)  weight_decay: 0.0500 (0.0500)  time: 21.6445  data: 21.4954  max mem: 2500\n",
      "Epoch: [1]  [ 10/227]  eta: 0:07:33  lr: 0.000400  min_lr: 0.000400  loss: 0.6289 (0.6311)  class_acc: 0.8000 (0.8455)  weight_decay: 0.0500 (0.0500)  time: 2.0890  data: 1.9542  max mem: 2500\n",
      "Epoch: [1]  [ 20/227]  eta: 0:03:59  lr: 0.000400  min_lr: 0.000400  loss: 0.6289 (0.6623)  class_acc: 0.8000 (0.8381)  weight_decay: 0.0500 (0.0500)  time: 0.1337  data: 0.0002  max mem: 2500\n",
      "Epoch: [1]  [ 30/227]  eta: 0:02:43  lr: 0.000399  min_lr: 0.000399  loss: 0.6958 (0.6731)  class_acc: 0.8000 (0.8387)  weight_decay: 0.0500 (0.0500)  time: 0.1339  data: 0.0001  max mem: 2500\n",
      "Epoch: [1]  [ 40/227]  eta: 0:02:03  lr: 0.000399  min_lr: 0.000399  loss: 0.6519 (0.6512)  class_acc: 0.9000 (0.8512)  weight_decay: 0.0500 (0.0500)  time: 0.1337  data: 0.0000  max mem: 2500\n",
      "Epoch: [1]  [ 50/227]  eta: 0:01:38  lr: 0.000399  min_lr: 0.000399  loss: 0.5284 (0.6351)  class_acc: 0.9000 (0.8588)  weight_decay: 0.0500 (0.0500)  time: 0.1324  data: 0.0002  max mem: 2500\n",
      "Epoch: [1]  [ 60/227]  eta: 0:01:21  lr: 0.000399  min_lr: 0.000399  loss: 0.5127 (0.6243)  class_acc: 0.9000 (0.8656)  weight_decay: 0.0500 (0.0500)  time: 0.1323  data: 0.0002  max mem: 2500\n",
      "Epoch: [1]  [ 70/227]  eta: 0:01:08  lr: 0.000399  min_lr: 0.000399  loss: 0.5884 (0.6335)  class_acc: 0.9000 (0.8592)  weight_decay: 0.0500 (0.0500)  time: 0.1340  data: 0.0002  max mem: 2500\n",
      "Epoch: [1]  [ 80/227]  eta: 0:00:58  lr: 0.000399  min_lr: 0.000399  loss: 0.6114 (0.6297)  class_acc: 0.8000 (0.8605)  weight_decay: 0.0500 (0.0500)  time: 0.1339  data: 0.0002  max mem: 2500\n",
      "Epoch: [1]  [ 90/227]  eta: 0:00:50  lr: 0.000399  min_lr: 0.000399  loss: 0.6105 (0.6304)  class_acc: 0.9000 (0.8604)  weight_decay: 0.0500 (0.0500)  time: 0.1343  data: 0.0003  max mem: 2500\n",
      "Epoch: [1]  [100/227]  eta: 0:00:44  lr: 0.000399  min_lr: 0.000399  loss: 0.6246 (0.6315)  class_acc: 0.8000 (0.8564)  weight_decay: 0.0500 (0.0500)  time: 0.1340  data: 0.0003  max mem: 2500\n",
      "Epoch: [1]  [110/227]  eta: 0:00:38  lr: 0.000399  min_lr: 0.000399  loss: 0.6246 (0.6312)  class_acc: 0.8000 (0.8568)  weight_decay: 0.0500 (0.0500)  time: 0.1327  data: 0.0002  max mem: 2500\n",
      "Epoch: [1]  [120/227]  eta: 0:00:33  lr: 0.000399  min_lr: 0.000399  loss: 0.5771 (0.6207)  class_acc: 0.9000 (0.8628)  weight_decay: 0.0500 (0.0500)  time: 0.1327  data: 0.0001  max mem: 2500\n",
      "Epoch: [1]  [130/227]  eta: 0:00:28  lr: 0.000399  min_lr: 0.000399  loss: 0.4859 (0.6156)  class_acc: 0.9000 (0.8664)  weight_decay: 0.0500 (0.0500)  time: 0.1326  data: 0.0000  max mem: 2500\n",
      "Epoch: [1]  [140/227]  eta: 0:00:24  lr: 0.000399  min_lr: 0.000399  loss: 0.5985 (0.6187)  class_acc: 0.9000 (0.8652)  weight_decay: 0.0500 (0.0500)  time: 0.1332  data: 0.0000  max mem: 2500\n",
      "Epoch: [1]  [150/227]  eta: 0:00:21  lr: 0.000399  min_lr: 0.000399  loss: 0.6934 (0.6296)  class_acc: 0.8000 (0.8583)  weight_decay: 0.0500 (0.0500)  time: 0.1331  data: 0.0000  max mem: 2500\n",
      "Epoch: [1]  [160/227]  eta: 0:00:17  lr: 0.000399  min_lr: 0.000399  loss: 0.6650 (0.6264)  class_acc: 0.8000 (0.8609)  weight_decay: 0.0500 (0.0500)  time: 0.1325  data: 0.0001  max mem: 2500\n",
      "Epoch: [1]  [170/227]  eta: 0:00:14  lr: 0.000399  min_lr: 0.000399  loss: 0.5937 (0.6260)  class_acc: 0.9000 (0.8602)  weight_decay: 0.0500 (0.0500)  time: 0.1334  data: 0.0001  max mem: 2500\n",
      "Epoch: [1]  [180/227]  eta: 0:00:11  lr: 0.000399  min_lr: 0.000399  loss: 0.5439 (0.6203)  class_acc: 0.9000 (0.8624)  weight_decay: 0.0500 (0.0500)  time: 0.1345  data: 0.0001  max mem: 2500\n",
      "Epoch: [1]  [190/227]  eta: 0:00:09  lr: 0.000399  min_lr: 0.000399  loss: 0.5872 (0.6237)  class_acc: 0.9000 (0.8613)  weight_decay: 0.0500 (0.0500)  time: 0.1332  data: 0.0002  max mem: 2500\n",
      "Epoch: [1]  [200/227]  eta: 0:00:06  lr: 0.000399  min_lr: 0.000399  loss: 0.6002 (0.6215)  class_acc: 0.9000 (0.8617)  weight_decay: 0.0500 (0.0500)  time: 0.1326  data: 0.0001  max mem: 2500\n",
      "Epoch: [1]  [210/227]  eta: 0:00:03  lr: 0.000399  min_lr: 0.000399  loss: 0.5799 (0.6223)  class_acc: 0.9000 (0.8607)  weight_decay: 0.0500 (0.0500)  time: 0.1334  data: 0.0000  max mem: 2500\n",
      "Epoch: [1]  [220/227]  eta: 0:00:01  lr: 0.000398  min_lr: 0.000398  loss: 0.5989 (0.6195)  class_acc: 0.9000 (0.8620)  weight_decay: 0.0500 (0.0500)  time: 0.1332  data: 0.0001  max mem: 2500\n",
      "Epoch: [1]  [226/227]  eta: 0:00:00  lr: 0.000398  min_lr: 0.000398  loss: 0.6195 (0.6190)  class_acc: 0.9000 (0.8626)  weight_decay: 0.0500 (0.0500)  time: 0.1342  data: 0.0001  max mem: 2500\n",
      "Epoch: [1] Total time: 0:00:52 (0.2305 s / it)\n",
      "Averaged stats: lr: 0.000398  min_lr: 0.000398  loss: 0.6195 (0.6190)  class_acc: 0.9000 (0.8626)  weight_decay: 0.0500 (0.0500)\n",
      "Test:  [ 0/38]  eta: 0:14:12  loss: 0.1642 (0.1642)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 22.4414  data: 22.3864  max mem: 2500\n",
      "Test:  [10/38]  eta: 0:00:58  loss: 0.1957 (0.1889)  acc1: 100.0000 (96.9697)  acc5: 100.0000 (100.0000)  time: 2.0866  data: 2.0352  max mem: 2500\n",
      "Test:  [20/38]  eta: 0:00:20  loss: 0.2397 (0.5563)  acc1: 86.6667 (78.0952)  acc5: 100.0000 (100.0000)  time: 0.0518  data: 0.0001  max mem: 2500\n",
      "Test:  [30/38]  eta: 0:00:06  loss: 0.2831 (0.4344)  acc1: 86.6667 (83.6559)  acc5: 100.0000 (100.0000)  time: 0.0522  data: 0.0002  max mem: 2500\n",
      "Test:  [37/38]  eta: 0:00:00  loss: 0.1555 (0.3945)  acc1: 93.3333 (85.7143)  acc5: 100.0000 (100.0000)  time: 0.0502  data: 0.0003  max mem: 2500\n",
      "Test: Total time: 0:00:24 (0.6537 s / it)\n",
      "* Acc@1 85.714 Acc@5 100.000 loss 0.394\n",
      "[[136   0   0   4]\n",
      " [ 51  77   2  10]\n",
      " [  1   1 136   2]\n",
      " [  9   0   0 131]]\n",
      "(4, 4)\n",
      "Accuracy of the model on the 560 test images: 85.7%\n",
      "Max accuracy: 85.71%\n",
      "Epoch: [2]  [  0/227]  eta: 1:21:15  lr: 0.000398  min_lr: 0.000398  loss: 0.4455 (0.4455)  class_acc: 0.9000 (0.9000)  weight_decay: 0.0500 (0.0500)  time: 21.4772  data: 21.3322  max mem: 2500\n",
      "Epoch: [2]  [ 10/227]  eta: 0:07:30  lr: 0.000398  min_lr: 0.000398  loss: 0.4533 (0.5562)  class_acc: 0.9000 (0.8818)  weight_decay: 0.0500 (0.0500)  time: 2.0747  data: 1.9395  max mem: 2500\n",
      "Epoch: [2]  [ 20/227]  eta: 0:03:58  lr: 0.000398  min_lr: 0.000398  loss: 0.5772 (0.5698)  class_acc: 0.8000 (0.8619)  weight_decay: 0.0500 (0.0500)  time: 0.1349  data: 0.0002  max mem: 2500\n",
      "Epoch: [2]  [ 30/227]  eta: 0:02:42  lr: 0.000398  min_lr: 0.000398  loss: 0.5772 (0.5753)  class_acc: 0.8000 (0.8613)  weight_decay: 0.0500 (0.0500)  time: 0.1361  data: 0.0001  max mem: 2500\n",
      "Epoch: [2]  [ 40/227]  eta: 0:02:02  lr: 0.000398  min_lr: 0.000398  loss: 0.5459 (0.5585)  class_acc: 0.9000 (0.8707)  weight_decay: 0.0500 (0.0500)  time: 0.1343  data: 0.0002  max mem: 2500\n",
      "Epoch: [2]  [ 50/227]  eta: 0:01:37  lr: 0.000398  min_lr: 0.000398  loss: 0.4616 (0.5422)  class_acc: 0.9000 (0.8882)  weight_decay: 0.0500 (0.0500)  time: 0.1322  data: 0.0002  max mem: 2500\n",
      "Epoch: [2]  [ 60/227]  eta: 0:01:20  lr: 0.000398  min_lr: 0.000398  loss: 0.4803 (0.5555)  class_acc: 0.9000 (0.8852)  weight_decay: 0.0500 (0.0500)  time: 0.1326  data: 0.0001  max mem: 2500\n",
      "Epoch: [2]  [ 70/227]  eta: 0:01:08  lr: 0.000398  min_lr: 0.000398  loss: 0.5446 (0.5558)  class_acc: 0.9000 (0.8873)  weight_decay: 0.0500 (0.0500)  time: 0.1332  data: 0.0001  max mem: 2500\n",
      "Epoch: [2]  [ 80/227]  eta: 0:00:58  lr: 0.000398  min_lr: 0.000398  loss: 0.5378 (0.5599)  class_acc: 0.9000 (0.8877)  weight_decay: 0.0500 (0.0500)  time: 0.1336  data: 0.0001  max mem: 2500\n",
      "Epoch: [2]  [ 90/227]  eta: 0:00:50  lr: 0.000398  min_lr: 0.000398  loss: 0.6177 (0.5740)  class_acc: 0.9000 (0.8802)  weight_decay: 0.0500 (0.0500)  time: 0.1349  data: 0.0001  max mem: 2500\n",
      "Epoch: [2]  [100/227]  eta: 0:00:43  lr: 0.000398  min_lr: 0.000398  loss: 0.6267 (0.5759)  class_acc: 0.9000 (0.8802)  weight_decay: 0.0500 (0.0500)  time: 0.1353  data: 0.0002  max mem: 2500\n",
      "Epoch: [2]  [110/227]  eta: 0:00:38  lr: 0.000398  min_lr: 0.000398  loss: 0.5541 (0.5751)  class_acc: 0.9000 (0.8811)  weight_decay: 0.0500 (0.0500)  time: 0.1344  data: 0.0002  max mem: 2500\n",
      "Epoch: [2]  [120/227]  eta: 0:00:33  lr: 0.000397  min_lr: 0.000397  loss: 0.5003 (0.5765)  class_acc: 0.9000 (0.8810)  weight_decay: 0.0500 (0.0500)  time: 0.1340  data: 0.0001  max mem: 2500\n",
      "Epoch: [2]  [130/227]  eta: 0:00:28  lr: 0.000397  min_lr: 0.000397  loss: 0.5119 (0.5816)  class_acc: 0.9000 (0.8786)  weight_decay: 0.0500 (0.0500)  time: 0.1330  data: 0.0002  max mem: 2500\n",
      "Epoch: [2]  [140/227]  eta: 0:00:24  lr: 0.000397  min_lr: 0.000397  loss: 0.5274 (0.5794)  class_acc: 0.9000 (0.8787)  weight_decay: 0.0500 (0.0500)  time: 0.1340  data: 0.0003  max mem: 2500\n",
      "Epoch: [2]  [150/227]  eta: 0:00:21  lr: 0.000397  min_lr: 0.000397  loss: 0.5239 (0.5871)  class_acc: 0.9000 (0.8768)  weight_decay: 0.0500 (0.0500)  time: 0.1336  data: 0.0002  max mem: 2500\n",
      "Epoch: [2]  [160/227]  eta: 0:00:17  lr: 0.000397  min_lr: 0.000397  loss: 0.5221 (0.5833)  class_acc: 0.9000 (0.8789)  weight_decay: 0.0500 (0.0500)  time: 0.1329  data: 0.0001  max mem: 2500\n",
      "Epoch: [2]  [170/227]  eta: 0:00:14  lr: 0.000397  min_lr: 0.000397  loss: 0.5185 (0.5850)  class_acc: 0.9000 (0.8784)  weight_decay: 0.0500 (0.0500)  time: 0.1352  data: 0.0001  max mem: 2500\n",
      "Epoch: [2]  [180/227]  eta: 0:00:11  lr: 0.000397  min_lr: 0.000397  loss: 0.4995 (0.5806)  class_acc: 0.9000 (0.8807)  weight_decay: 0.0500 (0.0500)  time: 0.1347  data: 0.0002  max mem: 2500\n",
      "Epoch: [2]  [190/227]  eta: 0:00:09  lr: 0.000397  min_lr: 0.000397  loss: 0.4922 (0.5832)  class_acc: 0.9000 (0.8806)  weight_decay: 0.0500 (0.0500)  time: 0.1337  data: 0.0002  max mem: 2500\n",
      "Epoch: [2]  [200/227]  eta: 0:00:06  lr: 0.000397  min_lr: 0.000397  loss: 0.5451 (0.5852)  class_acc: 0.9000 (0.8791)  weight_decay: 0.0500 (0.0500)  time: 0.1344  data: 0.0002  max mem: 2500\n",
      "Epoch: [2]  [210/227]  eta: 0:00:03  lr: 0.000397  min_lr: 0.000397  loss: 0.6208 (0.5873)  class_acc: 0.8000 (0.8768)  weight_decay: 0.0500 (0.0500)  time: 0.1342  data: 0.0002  max mem: 2500\n",
      "Epoch: [2]  [220/227]  eta: 0:00:01  lr: 0.000397  min_lr: 0.000397  loss: 0.5599 (0.5873)  class_acc: 0.9000 (0.8756)  weight_decay: 0.0500 (0.0500)  time: 0.1332  data: 0.0001  max mem: 2500\n",
      "Epoch: [2]  [226/227]  eta: 0:00:00  lr: 0.000396  min_lr: 0.000396  loss: 0.5389 (0.5860)  class_acc: 0.9000 (0.8767)  weight_decay: 0.0500 (0.0500)  time: 0.1322  data: 0.0000  max mem: 2500\n",
      "Epoch: [2] Total time: 0:00:52 (0.2303 s / it)\n",
      "Averaged stats: lr: 0.000396  min_lr: 0.000396  loss: 0.5389 (0.5860)  class_acc: 0.9000 (0.8767)  weight_decay: 0.0500 (0.0500)\n",
      "Test:  [ 0/38]  eta: 0:13:32  loss: 0.1363 (0.1363)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 21.3867  data: 21.3327  max mem: 2500\n",
      "Test:  [10/38]  eta: 0:00:55  loss: 0.1736 (0.1779)  acc1: 93.3333 (94.5455)  acc5: 100.0000 (100.0000)  time: 1.9868  data: 1.9396  max mem: 2500\n",
      "Test:  [20/38]  eta: 0:00:19  loss: 0.2038 (0.4859)  acc1: 93.3333 (78.4127)  acc5: 100.0000 (100.0000)  time: 0.0469  data: 0.0002  max mem: 2500\n",
      "Test:  [30/38]  eta: 0:00:05  loss: 0.1887 (0.3690)  acc1: 93.3333 (84.0860)  acc5: 100.0000 (100.0000)  time: 0.0476  data: 0.0001  max mem: 2500\n",
      "Test:  [37/38]  eta: 0:00:00  loss: 0.0874 (0.3317)  acc1: 100.0000 (86.0714)  acc5: 100.0000 (100.0000)  time: 0.0469  data: 0.0001  max mem: 2500\n",
      "Test: Total time: 0:00:23 (0.6234 s / it)\n",
      "* Acc@1 86.071 Acc@5 100.000 loss 0.332\n",
      "[[132   0   0   8]\n",
      " [ 49  80   0  11]\n",
      " [  0   0 140   0]\n",
      " [ 10   0   0 130]]\n",
      "(4, 4)\n",
      "Accuracy of the model on the 560 test images: 86.1%\n",
      "Max accuracy: 86.07%\n",
      "Epoch: [3]  [  0/227]  eta: 1:23:12  lr: 0.000396  min_lr: 0.000396  loss: 0.4080 (0.4080)  class_acc: 1.0000 (1.0000)  weight_decay: 0.0500 (0.0500)  time: 21.9924  data: 21.8453  max mem: 2500\n",
      "Epoch: [3]  [ 10/227]  eta: 0:07:40  lr: 0.000396  min_lr: 0.000396  loss: 0.5305 (0.5067)  class_acc: 0.9000 (0.9000)  weight_decay: 0.0500 (0.0500)  time: 2.1222  data: 1.9859  max mem: 2500\n",
      "Epoch: [3]  [ 20/227]  eta: 0:04:03  lr: 0.000396  min_lr: 0.000396  loss: 0.5349 (0.5324)  class_acc: 0.9000 (0.8857)  weight_decay: 0.0500 (0.0500)  time: 0.1357  data: 0.0001  max mem: 2500\n",
      "Epoch: [3]  [ 30/227]  eta: 0:02:46  lr: 0.000396  min_lr: 0.000396  loss: 0.6061 (0.5558)  class_acc: 0.8000 (0.8742)  weight_decay: 0.0500 (0.0500)  time: 0.1411  data: 0.0002  max mem: 2500\n",
      "Epoch: [3]  [ 40/227]  eta: 0:02:05  lr: 0.000396  min_lr: 0.000396  loss: 0.5125 (0.5326)  class_acc: 0.9000 (0.8902)  weight_decay: 0.0500 (0.0500)  time: 0.1399  data: 0.0002  max mem: 2500\n",
      "Epoch: [3]  [ 50/227]  eta: 0:01:40  lr: 0.000396  min_lr: 0.000396  loss: 0.4628 (0.5283)  class_acc: 0.9000 (0.8961)  weight_decay: 0.0500 (0.0500)  time: 0.1333  data: 0.0002  max mem: 2500\n",
      "Epoch: [3]  [ 60/227]  eta: 0:01:22  lr: 0.000396  min_lr: 0.000396  loss: 0.5822 (0.5552)  class_acc: 0.9000 (0.8836)  weight_decay: 0.0500 (0.0500)  time: 0.1332  data: 0.0003  max mem: 2500\n",
      "Epoch: [3]  [ 70/227]  eta: 0:01:09  lr: 0.000396  min_lr: 0.000396  loss: 0.6488 (0.5615)  class_acc: 0.9000 (0.8859)  weight_decay: 0.0500 (0.0500)  time: 0.1363  data: 0.0003  max mem: 2500\n",
      "Epoch: [3]  [ 80/227]  eta: 0:01:00  lr: 0.000396  min_lr: 0.000396  loss: 0.6455 (0.5774)  class_acc: 0.9000 (0.8778)  weight_decay: 0.0500 (0.0500)  time: 0.1457  data: 0.0003  max mem: 2500\n",
      "Epoch: [3]  [ 90/227]  eta: 0:00:52  lr: 0.000395  min_lr: 0.000395  loss: 0.6638 (0.5871)  class_acc: 0.8000 (0.8747)  weight_decay: 0.0500 (0.0500)  time: 0.1510  data: 0.0003  max mem: 2500\n",
      "Epoch: [3]  [100/227]  eta: 0:00:45  lr: 0.000395  min_lr: 0.000395  loss: 0.6374 (0.5966)  class_acc: 0.8000 (0.8703)  weight_decay: 0.0500 (0.0500)  time: 0.1484  data: 0.0004  max mem: 2500\n",
      "Epoch: [3]  [110/227]  eta: 0:00:39  lr: 0.000395  min_lr: 0.000395  loss: 0.5230 (0.5900)  class_acc: 0.8000 (0.8721)  weight_decay: 0.0500 (0.0500)  time: 0.1477  data: 0.0003  max mem: 2500\n",
      "Epoch: [3]  [120/227]  eta: 0:00:34  lr: 0.000395  min_lr: 0.000395  loss: 0.5050 (0.5836)  class_acc: 0.9000 (0.8785)  weight_decay: 0.0500 (0.0500)  time: 0.1422  data: 0.0002  max mem: 2500\n",
      "Epoch: [3]  [130/227]  eta: 0:00:29  lr: 0.000395  min_lr: 0.000395  loss: 0.5104 (0.5829)  class_acc: 0.9000 (0.8779)  weight_decay: 0.0500 (0.0500)  time: 0.1398  data: 0.0002  max mem: 2500\n",
      "Epoch: [3]  [140/227]  eta: 0:00:25  lr: 0.000395  min_lr: 0.000395  loss: 0.5104 (0.5773)  class_acc: 0.9000 (0.8801)  weight_decay: 0.0500 (0.0500)  time: 0.1401  data: 0.0001  max mem: 2500\n",
      "Epoch: [3]  [150/227]  eta: 0:00:21  lr: 0.000395  min_lr: 0.000395  loss: 0.5176 (0.5816)  class_acc: 0.9000 (0.8788)  weight_decay: 0.0500 (0.0500)  time: 0.1359  data: 0.0000  max mem: 2500\n",
      "Epoch: [3]  [160/227]  eta: 0:00:18  lr: 0.000395  min_lr: 0.000395  loss: 0.5830 (0.5865)  class_acc: 0.9000 (0.8776)  weight_decay: 0.0500 (0.0500)  time: 0.1367  data: 0.0001  max mem: 2500\n",
      "Epoch: [3]  [170/227]  eta: 0:00:15  lr: 0.000394  min_lr: 0.000394  loss: 0.6815 (0.5913)  class_acc: 0.8000 (0.8743)  weight_decay: 0.0500 (0.0500)  time: 0.1401  data: 0.0001  max mem: 2500\n",
      "Epoch: [3]  [180/227]  eta: 0:00:12  lr: 0.000394  min_lr: 0.000394  loss: 0.6280 (0.5913)  class_acc: 0.9000 (0.8751)  weight_decay: 0.0500 (0.0500)  time: 0.1383  data: 0.0001  max mem: 2500\n",
      "Epoch: [3]  [190/227]  eta: 0:00:09  lr: 0.000394  min_lr: 0.000394  loss: 0.5928 (0.5939)  class_acc: 0.9000 (0.8733)  weight_decay: 0.0500 (0.0500)  time: 0.1385  data: 0.0001  max mem: 2500\n",
      "Epoch: [3]  [200/227]  eta: 0:00:06  lr: 0.000394  min_lr: 0.000394  loss: 0.5512 (0.5905)  class_acc: 0.9000 (0.8756)  weight_decay: 0.0500 (0.0500)  time: 0.1406  data: 0.0000  max mem: 2500\n",
      "Epoch: [3]  [210/227]  eta: 0:00:04  lr: 0.000394  min_lr: 0.000394  loss: 0.5331 (0.5898)  class_acc: 0.9000 (0.8763)  weight_decay: 0.0500 (0.0500)  time: 0.1432  data: 0.0001  max mem: 2500\n",
      "Epoch: [3]  [220/227]  eta: 0:00:01  lr: 0.000394  min_lr: 0.000394  loss: 0.5322 (0.5864)  class_acc: 0.9000 (0.8774)  weight_decay: 0.0500 (0.0500)  time: 0.1477  data: 0.0001  max mem: 2500\n",
      "Epoch: [3]  [226/227]  eta: 0:00:00  lr: 0.000394  min_lr: 0.000394  loss: 0.5253 (0.5837)  class_acc: 0.9000 (0.8789)  weight_decay: 0.0500 (0.0500)  time: 0.1477  data: 0.0001  max mem: 2500\n",
      "Epoch: [3] Total time: 0:00:54 (0.2399 s / it)\n",
      "Averaged stats: lr: 0.000394  min_lr: 0.000394  loss: 0.5253 (0.5837)  class_acc: 0.9000 (0.8789)  weight_decay: 0.0500 (0.0500)\n",
      "Test:  [ 0/38]  eta: 0:14:29  loss: 0.1520 (0.1520)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 22.8936  data: 22.8305  max mem: 2500\n",
      "Test:  [10/38]  eta: 0:00:59  loss: 0.1601 (0.1770)  acc1: 93.3333 (95.1515)  acc5: 100.0000 (100.0000)  time: 2.1302  data: 2.0759  max mem: 2500\n",
      "Test:  [20/38]  eta: 0:00:20  loss: 0.2257 (0.4272)  acc1: 93.3333 (80.6349)  acc5: 100.0000 (100.0000)  time: 0.0506  data: 0.0003  max mem: 2500\n",
      "Test:  [30/38]  eta: 0:00:06  loss: 0.2694 (0.3682)  acc1: 86.6667 (84.0860)  acc5: 100.0000 (100.0000)  time: 0.0493  data: 0.0002  max mem: 2500\n",
      "Test:  [37/38]  eta: 0:00:00  loss: 0.2027 (0.3315)  acc1: 93.3333 (86.4286)  acc5: 100.0000 (100.0000)  time: 0.0477  data: 0.0001  max mem: 2500\n",
      "Test: Total time: 0:00:25 (0.6656 s / it)\n",
      "* Acc@1 86.429 Acc@5 100.000 loss 0.331\n",
      "[[133   0   0   7]\n",
      " [ 34  88   0  18]\n",
      " [  0  13 126   1]\n",
      " [  3   0   0 137]]\n",
      "(4, 4)\n",
      "Accuracy of the model on the 560 test images: 86.4%\n",
      "Max accuracy: 86.43%\n",
      "Epoch: [4]  [  0/227]  eta: 1:26:34  lr: 0.000394  min_lr: 0.000394  loss: 0.3632 (0.3632)  class_acc: 1.0000 (1.0000)  weight_decay: 0.0500 (0.0500)  time: 22.8844  data: 22.7313  max mem: 2500\n",
      "Epoch: [4]  [ 10/227]  eta: 0:08:00  lr: 0.000394  min_lr: 0.000394  loss: 0.5339 (0.5255)  class_acc: 0.9000 (0.8909)  weight_decay: 0.0500 (0.0500)  time: 2.2145  data: 2.0667  max mem: 2500\n",
      "Epoch: [4]  [ 20/227]  eta: 0:04:14  lr: 0.000393  min_lr: 0.000393  loss: 0.5339 (0.5666)  class_acc: 0.9000 (0.8810)  weight_decay: 0.0500 (0.0500)  time: 0.1448  data: 0.0002  max mem: 2500\n",
      "Epoch: [4]  [ 30/227]  eta: 0:02:52  lr: 0.000393  min_lr: 0.000393  loss: 0.6114 (0.5861)  class_acc: 0.9000 (0.8806)  weight_decay: 0.0500 (0.0500)  time: 0.1373  data: 0.0001  max mem: 2500\n",
      "Epoch: [4]  [ 40/227]  eta: 0:02:09  lr: 0.000393  min_lr: 0.000393  loss: 0.5197 (0.5620)  class_acc: 0.9000 (0.8951)  weight_decay: 0.0500 (0.0500)  time: 0.1336  data: 0.0000  max mem: 2500\n",
      "Epoch: [4]  [ 50/227]  eta: 0:01:43  lr: 0.000393  min_lr: 0.000393  loss: 0.3930 (0.5266)  class_acc: 1.0000 (0.9137)  weight_decay: 0.0500 (0.0500)  time: 0.1339  data: 0.0001  max mem: 2500\n",
      "Epoch: [4]  [ 60/227]  eta: 0:01:25  lr: 0.000393  min_lr: 0.000393  loss: 0.3967 (0.5355)  class_acc: 1.0000 (0.9082)  weight_decay: 0.0500 (0.0500)  time: 0.1351  data: 0.0002  max mem: 2500\n",
      "Epoch: [4]  [ 70/227]  eta: 0:01:11  lr: 0.000393  min_lr: 0.000393  loss: 0.5487 (0.5404)  class_acc: 0.9000 (0.9042)  weight_decay: 0.0500 (0.0500)  time: 0.1359  data: 0.0003  max mem: 2500\n",
      "Epoch: [4]  [ 80/227]  eta: 0:01:01  lr: 0.000393  min_lr: 0.000393  loss: 0.5240 (0.5438)  class_acc: 0.9000 (0.9012)  weight_decay: 0.0500 (0.0500)  time: 0.1338  data: 0.0002  max mem: 2500\n",
      "Epoch: [4]  [ 90/227]  eta: 0:00:52  lr: 0.000392  min_lr: 0.000392  loss: 0.5166 (0.5536)  class_acc: 0.9000 (0.8912)  weight_decay: 0.0500 (0.0500)  time: 0.1336  data: 0.0003  max mem: 2500\n",
      "Epoch: [4]  [100/227]  eta: 0:00:45  lr: 0.000392  min_lr: 0.000392  loss: 0.5216 (0.5568)  class_acc: 0.9000 (0.8901)  weight_decay: 0.0500 (0.0500)  time: 0.1341  data: 0.0004  max mem: 2500\n",
      "Epoch: [4]  [110/227]  eta: 0:00:39  lr: 0.000392  min_lr: 0.000392  loss: 0.4785 (0.5501)  class_acc: 0.9000 (0.8955)  weight_decay: 0.0500 (0.0500)  time: 0.1340  data: 0.0002  max mem: 2500\n",
      "Epoch: [4]  [120/227]  eta: 0:00:34  lr: 0.000392  min_lr: 0.000392  loss: 0.4778 (0.5433)  class_acc: 1.0000 (0.8992)  weight_decay: 0.0500 (0.0500)  time: 0.1333  data: 0.0002  max mem: 2500\n",
      "Epoch: [4]  [130/227]  eta: 0:00:29  lr: 0.000392  min_lr: 0.000392  loss: 0.5171 (0.5467)  class_acc: 0.9000 (0.8954)  weight_decay: 0.0500 (0.0500)  time: 0.1331  data: 0.0003  max mem: 2500\n",
      "Epoch: [4]  [140/227]  eta: 0:00:25  lr: 0.000392  min_lr: 0.000392  loss: 0.5679 (0.5498)  class_acc: 0.9000 (0.8950)  weight_decay: 0.0500 (0.0500)  time: 0.1331  data: 0.0002  max mem: 2500\n",
      "Epoch: [4]  [150/227]  eta: 0:00:22  lr: 0.000392  min_lr: 0.000392  loss: 0.5741 (0.5594)  class_acc: 0.9000 (0.8907)  weight_decay: 0.0500 (0.0500)  time: 0.1335  data: 0.0002  max mem: 2500\n",
      "Epoch: [4]  [160/227]  eta: 0:00:18  lr: 0.000391  min_lr: 0.000391  loss: 0.5262 (0.5548)  class_acc: 0.9000 (0.8938)  weight_decay: 0.0500 (0.0500)  time: 0.1342  data: 0.0001  max mem: 2500\n",
      "Epoch: [4]  [170/227]  eta: 0:00:15  lr: 0.000391  min_lr: 0.000391  loss: 0.5034 (0.5595)  class_acc: 0.9000 (0.8912)  weight_decay: 0.0500 (0.0500)  time: 0.1339  data: 0.0001  max mem: 2500\n",
      "Epoch: [4]  [180/227]  eta: 0:00:12  lr: 0.000391  min_lr: 0.000391  loss: 0.4981 (0.5568)  class_acc: 0.9000 (0.8917)  weight_decay: 0.0500 (0.0500)  time: 0.1333  data: 0.0003  max mem: 2500\n",
      "Epoch: [4]  [190/227]  eta: 0:00:09  lr: 0.000391  min_lr: 0.000391  loss: 0.4524 (0.5562)  class_acc: 0.9000 (0.8921)  weight_decay: 0.0500 (0.0500)  time: 0.1330  data: 0.0002  max mem: 2500\n",
      "Epoch: [4]  [200/227]  eta: 0:00:06  lr: 0.000391  min_lr: 0.000391  loss: 0.4488 (0.5529)  class_acc: 0.9000 (0.8940)  weight_decay: 0.0500 (0.0500)  time: 0.1333  data: 0.0001  max mem: 2500\n",
      "Epoch: [4]  [210/227]  eta: 0:00:04  lr: 0.000391  min_lr: 0.000391  loss: 0.4870 (0.5515)  class_acc: 0.9000 (0.8948)  weight_decay: 0.0500 (0.0500)  time: 0.1335  data: 0.0001  max mem: 2500\n",
      "Epoch: [4]  [220/227]  eta: 0:00:01  lr: 0.000390  min_lr: 0.000390  loss: 0.5382 (0.5514)  class_acc: 0.9000 (0.8950)  weight_decay: 0.0500 (0.0500)  time: 0.1350  data: 0.0001  max mem: 2500\n",
      "Epoch: [4]  [226/227]  eta: 0:00:00  lr: 0.000390  min_lr: 0.000390  loss: 0.5196 (0.5507)  class_acc: 0.9000 (0.8947)  weight_decay: 0.0500 (0.0500)  time: 0.1350  data: 0.0001  max mem: 2500\n",
      "Epoch: [4] Total time: 0:00:53 (0.2374 s / it)\n",
      "Averaged stats: lr: 0.000390  min_lr: 0.000390  loss: 0.5196 (0.5507)  class_acc: 0.9000 (0.8947)  weight_decay: 0.0500 (0.0500)\n",
      "Test:  [ 0/38]  eta: 0:13:38  loss: 0.1267 (0.1267)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 21.5479  data: 21.4949  max mem: 2500\n",
      "Test:  [10/38]  eta: 0:00:56  loss: 0.1386 (0.1644)  acc1: 100.0000 (98.1818)  acc5: 100.0000 (100.0000)  time: 2.0032  data: 1.9542  max mem: 2500\n",
      "Test:  [20/38]  eta: 0:00:19  loss: 0.2047 (0.4190)  acc1: 93.3333 (84.1270)  acc5: 100.0000 (100.0000)  time: 0.0479  data: 0.0001  max mem: 2500\n",
      "Test:  [30/38]  eta: 0:00:05  loss: 0.1534 (0.3322)  acc1: 100.0000 (88.3871)  acc5: 100.0000 (100.0000)  time: 0.0467  data: 0.0002  max mem: 2500\n",
      "Test:  [37/38]  eta: 0:00:00  loss: 0.1179 (0.3124)  acc1: 100.0000 (89.8214)  acc5: 100.0000 (100.0000)  time: 0.0453  data: 0.0002  max mem: 2500\n",
      "Test: Total time: 0:00:23 (0.6270 s / it)\n",
      "* Acc@1 89.821 Acc@5 100.000 loss 0.312\n",
      "[[137   0   2   1]\n",
      " [ 42  93   3   2]\n",
      " [  0   0 140   0]\n",
      " [  6   0   1 133]]\n",
      "(4, 4)\n",
      "Accuracy of the model on the 560 test images: 89.8%\n",
      "Max accuracy: 89.82%\n",
      "Epoch: [5]  [  0/227]  eta: 1:23:10  lr: 0.000390  min_lr: 0.000390  loss: 0.4375 (0.4375)  class_acc: 1.0000 (1.0000)  weight_decay: 0.0500 (0.0500)  time: 21.9860  data: 21.8279  max mem: 2500\n",
      "Epoch: [5]  [ 10/227]  eta: 0:07:40  lr: 0.000390  min_lr: 0.000390  loss: 0.5065 (0.5391)  class_acc: 0.9000 (0.9000)  weight_decay: 0.0500 (0.0500)  time: 2.1208  data: 1.9845  max mem: 2500\n",
      "Epoch: [5]  [ 20/227]  eta: 0:04:03  lr: 0.000390  min_lr: 0.000390  loss: 0.4757 (0.5054)  class_acc: 0.9000 (0.9238)  weight_decay: 0.0500 (0.0500)  time: 0.1339  data: 0.0001  max mem: 2500\n",
      "Epoch: [5]  [ 30/227]  eta: 0:02:45  lr: 0.000390  min_lr: 0.000390  loss: 0.5061 (0.5318)  class_acc: 0.9000 (0.9065)  weight_decay: 0.0500 (0.0500)  time: 0.1328  data: 0.0001  max mem: 2500\n",
      "Epoch: [5]  [ 40/227]  eta: 0:02:04  lr: 0.000390  min_lr: 0.000390  loss: 0.5391 (0.5262)  class_acc: 0.9000 (0.9098)  weight_decay: 0.0500 (0.0500)  time: 0.1330  data: 0.0002  max mem: 2500\n",
      "Epoch: [5]  [ 50/227]  eta: 0:01:39  lr: 0.000389  min_lr: 0.000389  loss: 0.4330 (0.5116)  class_acc: 0.9000 (0.9176)  weight_decay: 0.0500 (0.0500)  time: 0.1329  data: 0.0001  max mem: 2500\n",
      "Epoch: [5]  [ 60/227]  eta: 0:01:22  lr: 0.000389  min_lr: 0.000389  loss: 0.4184 (0.5217)  class_acc: 0.9000 (0.9180)  weight_decay: 0.0500 (0.0500)  time: 0.1332  data: 0.0003  max mem: 2500\n",
      "Epoch: [5]  [ 70/227]  eta: 0:01:09  lr: 0.000389  min_lr: 0.000389  loss: 0.5658 (0.5245)  class_acc: 0.9000 (0.9141)  weight_decay: 0.0500 (0.0500)  time: 0.1341  data: 0.0002  max mem: 2500\n",
      "Epoch: [5]  [ 80/227]  eta: 0:00:59  lr: 0.000389  min_lr: 0.000389  loss: 0.5716 (0.5298)  class_acc: 0.9000 (0.9111)  weight_decay: 0.0500 (0.0500)  time: 0.1334  data: 0.0001  max mem: 2500\n",
      "Epoch: [5]  [ 90/227]  eta: 0:00:51  lr: 0.000389  min_lr: 0.000389  loss: 0.5321 (0.5290)  class_acc: 0.9000 (0.9110)  weight_decay: 0.0500 (0.0500)  time: 0.1330  data: 0.0003  max mem: 2500\n",
      "Epoch: [5]  [100/227]  eta: 0:00:44  lr: 0.000388  min_lr: 0.000388  loss: 0.5321 (0.5356)  class_acc: 0.9000 (0.9059)  weight_decay: 0.0500 (0.0500)  time: 0.1333  data: 0.0002  max mem: 2500\n",
      "Epoch: [5]  [110/227]  eta: 0:00:38  lr: 0.000388  min_lr: 0.000388  loss: 0.4987 (0.5272)  class_acc: 0.9000 (0.9099)  weight_decay: 0.0500 (0.0500)  time: 0.1337  data: 0.0001  max mem: 2500\n",
      "Epoch: [5]  [120/227]  eta: 0:00:33  lr: 0.000388  min_lr: 0.000388  loss: 0.4475 (0.5262)  class_acc: 0.9000 (0.9107)  weight_decay: 0.0500 (0.0500)  time: 0.1342  data: 0.0002  max mem: 2500\n",
      "Epoch: [5]  [130/227]  eta: 0:00:29  lr: 0.000388  min_lr: 0.000388  loss: 0.5271 (0.5340)  class_acc: 0.9000 (0.9076)  weight_decay: 0.0500 (0.0500)  time: 0.1340  data: 0.0001  max mem: 2500\n",
      "Epoch: [5]  [140/227]  eta: 0:00:25  lr: 0.000388  min_lr: 0.000388  loss: 0.5358 (0.5338)  class_acc: 0.9000 (0.9078)  weight_decay: 0.0500 (0.0500)  time: 0.1329  data: 0.0001  max mem: 2500\n",
      "Epoch: [5]  [150/227]  eta: 0:00:21  lr: 0.000388  min_lr: 0.000388  loss: 0.5202 (0.5403)  class_acc: 0.9000 (0.9046)  weight_decay: 0.0500 (0.0500)  time: 0.1345  data: 0.0002  max mem: 2500\n",
      "Epoch: [5]  [160/227]  eta: 0:00:18  lr: 0.000387  min_lr: 0.000387  loss: 0.5742 (0.5424)  class_acc: 0.9000 (0.9025)  weight_decay: 0.0500 (0.0500)  time: 0.1344  data: 0.0003  max mem: 2500\n",
      "Epoch: [5]  [170/227]  eta: 0:00:14  lr: 0.000387  min_lr: 0.000387  loss: 0.5762 (0.5487)  class_acc: 0.9000 (0.8977)  weight_decay: 0.0500 (0.0500)  time: 0.1331  data: 0.0002  max mem: 2500\n",
      "Epoch: [5]  [180/227]  eta: 0:00:11  lr: 0.000387  min_lr: 0.000387  loss: 0.4832 (0.5431)  class_acc: 0.9000 (0.9006)  weight_decay: 0.0500 (0.0500)  time: 0.1329  data: 0.0001  max mem: 2500\n",
      "Epoch: [5]  [190/227]  eta: 0:00:09  lr: 0.000387  min_lr: 0.000387  loss: 0.4403 (0.5458)  class_acc: 0.9000 (0.8984)  weight_decay: 0.0500 (0.0500)  time: 0.1343  data: 0.0003  max mem: 2500\n",
      "Epoch: [5]  [200/227]  eta: 0:00:06  lr: 0.000387  min_lr: 0.000387  loss: 0.5589 (0.5463)  class_acc: 0.9000 (0.8975)  weight_decay: 0.0500 (0.0500)  time: 0.1344  data: 0.0003  max mem: 2500\n",
      "Epoch: [5]  [210/227]  eta: 0:00:04  lr: 0.000386  min_lr: 0.000386  loss: 0.5575 (0.5490)  class_acc: 0.9000 (0.8967)  weight_decay: 0.0500 (0.0500)  time: 0.1329  data: 0.0002  max mem: 2500\n",
      "Epoch: [5]  [220/227]  eta: 0:00:01  lr: 0.000386  min_lr: 0.000386  loss: 0.5042 (0.5486)  class_acc: 0.9000 (0.8973)  weight_decay: 0.0500 (0.0500)  time: 0.1331  data: 0.0002  max mem: 2500\n",
      "Epoch: [5]  [226/227]  eta: 0:00:00  lr: 0.000386  min_lr: 0.000386  loss: 0.3976 (0.5450)  class_acc: 1.0000 (0.8996)  weight_decay: 0.0500 (0.0500)  time: 0.1326  data: 0.0001  max mem: 2500\n",
      "Epoch: [5] Total time: 0:00:52 (0.2321 s / it)\n",
      "Averaged stats: lr: 0.000386  min_lr: 0.000386  loss: 0.3976 (0.5450)  class_acc: 1.0000 (0.8996)  weight_decay: 0.0500 (0.0500)\n",
      "Test:  [ 0/38]  eta: 0:13:44  loss: 0.2015 (0.2015)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 21.6943  data: 21.6382  max mem: 2500\n",
      "Test:  [10/38]  eta: 0:00:56  loss: 0.2298 (0.2492)  acc1: 93.3333 (93.3333)  acc5: 100.0000 (100.0000)  time: 2.0147  data: 1.9674  max mem: 2500\n",
      "Test:  [20/38]  eta: 0:00:19  loss: 0.2846 (0.4032)  acc1: 93.3333 (82.8571)  acc5: 100.0000 (100.0000)  time: 0.0467  data: 0.0002  max mem: 2500\n",
      "Test:  [30/38]  eta: 0:00:05  loss: 0.0881 (0.3035)  acc1: 100.0000 (87.9570)  acc5: 100.0000 (100.0000)  time: 0.0467  data: 0.0001  max mem: 2500\n",
      "Test:  [37/38]  eta: 0:00:00  loss: 0.0645 (0.2641)  acc1: 100.0000 (89.8214)  acc5: 100.0000 (100.0000)  time: 0.0451  data: 0.0001  max mem: 2500\n",
      "Test: Total time: 0:00:23 (0.6292 s / it)\n",
      "* Acc@1 89.821 Acc@5 100.000 loss 0.264\n",
      "[[129   0   0  11]\n",
      " [ 18  97   1  24]\n",
      " [  0   0 140   0]\n",
      " [  2   1   0 137]]\n",
      "(4, 4)\n",
      "Accuracy of the model on the 560 test images: 89.8%\n",
      "Max accuracy: 89.82%\n",
      "Epoch: [6]  [  0/227]  eta: 1:21:08  lr: 0.000386  min_lr: 0.000386  loss: 0.3639 (0.3639)  class_acc: 1.0000 (1.0000)  weight_decay: 0.0500 (0.0500)  time: 21.4458  data: 21.3027  max mem: 2500\n",
      "Epoch: [6]  [ 10/227]  eta: 0:07:29  lr: 0.000386  min_lr: 0.000386  loss: 0.4827 (0.5257)  class_acc: 0.9000 (0.9182)  weight_decay: 0.0500 (0.0500)  time: 2.0711  data: 1.9366  max mem: 2500\n",
      "Epoch: [6]  [ 20/227]  eta: 0:03:57  lr: 0.000386  min_lr: 0.000386  loss: 0.4539 (0.5213)  class_acc: 0.9000 (0.9143)  weight_decay: 0.0500 (0.0500)  time: 0.1346  data: 0.0001  max mem: 2500\n",
      "Epoch: [6]  [ 30/227]  eta: 0:02:41  lr: 0.000385  min_lr: 0.000385  loss: 0.4920 (0.5425)  class_acc: 0.9000 (0.9032)  weight_decay: 0.0500 (0.0500)  time: 0.1350  data: 0.0002  max mem: 2500\n",
      "Epoch: [6]  [ 40/227]  eta: 0:02:02  lr: 0.000385  min_lr: 0.000385  loss: 0.5374 (0.5396)  class_acc: 0.9000 (0.9073)  weight_decay: 0.0500 (0.0500)  time: 0.1380  data: 0.0002  max mem: 2500\n",
      "Epoch: [6]  [ 50/227]  eta: 0:01:38  lr: 0.000385  min_lr: 0.000385  loss: 0.4446 (0.5150)  class_acc: 1.0000 (0.9216)  weight_decay: 0.0500 (0.0500)  time: 0.1428  data: 0.0001  max mem: 2500\n",
      "Epoch: [6]  [ 60/227]  eta: 0:01:21  lr: 0.000385  min_lr: 0.000385  loss: 0.4050 (0.5098)  class_acc: 1.0000 (0.9246)  weight_decay: 0.0500 (0.0500)  time: 0.1462  data: 0.0001  max mem: 2500\n",
      "Epoch: [6]  [ 70/227]  eta: 0:01:09  lr: 0.000385  min_lr: 0.000385  loss: 0.4665 (0.5361)  class_acc: 0.9000 (0.9113)  weight_decay: 0.0500 (0.0500)  time: 0.1446  data: 0.0002  max mem: 2500\n",
      "Epoch: [6]  [ 80/227]  eta: 0:00:59  lr: 0.000384  min_lr: 0.000384  loss: 0.5309 (0.5462)  class_acc: 0.9000 (0.9062)  weight_decay: 0.0500 (0.0500)  time: 0.1424  data: 0.0001  max mem: 2500\n",
      "Epoch: [6]  [ 90/227]  eta: 0:00:51  lr: 0.000384  min_lr: 0.000384  loss: 0.5248 (0.5456)  class_acc: 0.9000 (0.9044)  weight_decay: 0.0500 (0.0500)  time: 0.1396  data: 0.0002  max mem: 2500\n",
      "Epoch: [6]  [100/227]  eta: 0:00:44  lr: 0.000384  min_lr: 0.000384  loss: 0.5351 (0.5445)  class_acc: 0.9000 (0.9050)  weight_decay: 0.0500 (0.0500)  time: 0.1341  data: 0.0003  max mem: 2500\n",
      "Epoch: [6]  [110/227]  eta: 0:00:38  lr: 0.000384  min_lr: 0.000384  loss: 0.5322 (0.5405)  class_acc: 0.9000 (0.9063)  weight_decay: 0.0500 (0.0500)  time: 0.1380  data: 0.0002  max mem: 2500\n",
      "Epoch: [6]  [120/227]  eta: 0:00:33  lr: 0.000383  min_lr: 0.000383  loss: 0.4434 (0.5441)  class_acc: 0.9000 (0.9041)  weight_decay: 0.0500 (0.0500)  time: 0.1406  data: 0.0001  max mem: 2500\n",
      "Epoch: [6]  [130/227]  eta: 0:00:29  lr: 0.000383  min_lr: 0.000383  loss: 0.5344 (0.5444)  class_acc: 0.9000 (0.9031)  weight_decay: 0.0500 (0.0500)  time: 0.1383  data: 0.0002  max mem: 2500\n",
      "Epoch: [6]  [140/227]  eta: 0:00:25  lr: 0.000383  min_lr: 0.000383  loss: 0.5344 (0.5465)  class_acc: 0.9000 (0.9014)  weight_decay: 0.0500 (0.0500)  time: 0.1412  data: 0.0003  max mem: 2500\n",
      "Epoch: [6]  [150/227]  eta: 0:00:21  lr: 0.000383  min_lr: 0.000383  loss: 0.5021 (0.5510)  class_acc: 0.9000 (0.9000)  weight_decay: 0.0500 (0.0500)  time: 0.1427  data: 0.0003  max mem: 2500\n",
      "Epoch: [6]  [160/227]  eta: 0:00:18  lr: 0.000383  min_lr: 0.000383  loss: 0.5623 (0.5536)  class_acc: 0.9000 (0.8988)  weight_decay: 0.0500 (0.0500)  time: 0.1407  data: 0.0002  max mem: 2500\n",
      "Epoch: [6]  [170/227]  eta: 0:00:15  lr: 0.000382  min_lr: 0.000382  loss: 0.5993 (0.5545)  class_acc: 0.9000 (0.8977)  weight_decay: 0.0500 (0.0500)  time: 0.1466  data: 0.0001  max mem: 2500\n",
      "Epoch: [6]  [180/227]  eta: 0:00:12  lr: 0.000382  min_lr: 0.000382  loss: 0.5053 (0.5499)  class_acc: 0.9000 (0.8989)  weight_decay: 0.0500 (0.0500)  time: 0.1476  data: 0.0002  max mem: 2500\n",
      "Epoch: [6]  [190/227]  eta: 0:00:09  lr: 0.000382  min_lr: 0.000382  loss: 0.4579 (0.5492)  class_acc: 0.9000 (0.8995)  weight_decay: 0.0500 (0.0500)  time: 0.1424  data: 0.0003  max mem: 2500\n",
      "Epoch: [6]  [200/227]  eta: 0:00:06  lr: 0.000382  min_lr: 0.000382  loss: 0.4687 (0.5476)  class_acc: 0.9000 (0.9010)  weight_decay: 0.0500 (0.0500)  time: 0.1386  data: 0.0002  max mem: 2500\n",
      "Epoch: [6]  [210/227]  eta: 0:00:04  lr: 0.000381  min_lr: 0.000381  loss: 0.4654 (0.5480)  class_acc: 0.9000 (0.9014)  weight_decay: 0.0500 (0.0500)  time: 0.1346  data: 0.0002  max mem: 2500\n",
      "Epoch: [6]  [220/227]  eta: 0:00:01  lr: 0.000381  min_lr: 0.000381  loss: 0.4654 (0.5462)  class_acc: 0.9000 (0.9023)  weight_decay: 0.0500 (0.0500)  time: 0.1342  data: 0.0001  max mem: 2500\n",
      "Epoch: [6]  [226/227]  eta: 0:00:00  lr: 0.000381  min_lr: 0.000381  loss: 0.4692 (0.5442)  class_acc: 0.9000 (0.9031)  weight_decay: 0.0500 (0.0500)  time: 0.1341  data: 0.0001  max mem: 2500\n",
      "Epoch: [6] Total time: 0:00:53 (0.2359 s / it)\n",
      "Averaged stats: lr: 0.000381  min_lr: 0.000381  loss: 0.4692 (0.5442)  class_acc: 0.9000 (0.9031)  weight_decay: 0.0500 (0.0500)\n",
      "Test:  [ 0/38]  eta: 0:13:53  loss: 0.1126 (0.1126)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 21.9357  data: 21.8776  max mem: 2500\n",
      "Test:  [10/38]  eta: 0:00:57  loss: 0.1532 (0.1503)  acc1: 100.0000 (96.9697)  acc5: 100.0000 (100.0000)  time: 2.0367  data: 1.9891  max mem: 2500\n",
      "Test:  [20/38]  eta: 0:00:19  loss: 0.1960 (0.4706)  acc1: 93.3333 (82.5397)  acc5: 100.0000 (100.0000)  time: 0.0467  data: 0.0001  max mem: 2500\n",
      "Test:  [30/38]  eta: 0:00:06  loss: 0.1130 (0.3528)  acc1: 100.0000 (87.7419)  acc5: 100.0000 (100.0000)  time: 0.0466  data: 0.0002  max mem: 2500\n",
      "Test:  [37/38]  eta: 0:00:00  loss: 0.0876 (0.3117)  acc1: 100.0000 (89.6429)  acc5: 100.0000 (100.0000)  time: 0.0450  data: 0.0001  max mem: 2500\n",
      "Test: Total time: 0:00:24 (0.6352 s / it)\n",
      "* Acc@1 89.643 Acc@5 100.000 loss 0.312\n",
      "[[136   0   1   3]\n",
      " [ 43  89   0   8]\n",
      " [  0   0 140   0]\n",
      " [  3   0   0 137]]\n",
      "(4, 4)\n",
      "Accuracy of the model on the 560 test images: 89.6%\n",
      "Max accuracy: 89.82%\n",
      "Epoch: [7]  [  0/227]  eta: 1:20:55  lr: 0.000381  min_lr: 0.000381  loss: 0.3575 (0.3575)  class_acc: 1.0000 (1.0000)  weight_decay: 0.0500 (0.0500)  time: 21.3892  data: 21.2361  max mem: 2500\n",
      "Epoch: [7]  [ 10/227]  eta: 0:07:28  lr: 0.000381  min_lr: 0.000381  loss: 0.3994 (0.4162)  class_acc: 1.0000 (0.9636)  weight_decay: 0.0500 (0.0500)  time: 2.0655  data: 1.9306  max mem: 2500\n",
      "Epoch: [7]  [ 20/227]  eta: 0:03:57  lr: 0.000381  min_lr: 0.000381  loss: 0.3994 (0.4393)  class_acc: 1.0000 (0.9524)  weight_decay: 0.0500 (0.0500)  time: 0.1338  data: 0.0001  max mem: 2500\n",
      "Epoch: [7]  [ 30/227]  eta: 0:02:41  lr: 0.000380  min_lr: 0.000380  loss: 0.4209 (0.5070)  class_acc: 0.9000 (0.9194)  weight_decay: 0.0500 (0.0500)  time: 0.1328  data: 0.0002  max mem: 2500\n",
      "Epoch: [7]  [ 40/227]  eta: 0:02:01  lr: 0.000380  min_lr: 0.000380  loss: 0.4296 (0.4992)  class_acc: 0.9000 (0.9244)  weight_decay: 0.0500 (0.0500)  time: 0.1315  data: 0.0002  max mem: 2500\n",
      "Epoch: [7]  [ 50/227]  eta: 0:01:37  lr: 0.000380  min_lr: 0.000380  loss: 0.4093 (0.4879)  class_acc: 0.9000 (0.9294)  weight_decay: 0.0500 (0.0500)  time: 0.1331  data: 0.0002  max mem: 2500\n",
      "Epoch: [7]  [ 60/227]  eta: 0:01:20  lr: 0.000380  min_lr: 0.000380  loss: 0.4537 (0.4940)  class_acc: 0.9000 (0.9262)  weight_decay: 0.0500 (0.0500)  time: 0.1334  data: 0.0003  max mem: 2500\n",
      "Epoch: [7]  [ 70/227]  eta: 0:01:07  lr: 0.000379  min_lr: 0.000379  loss: 0.5089 (0.4993)  class_acc: 0.9000 (0.9225)  weight_decay: 0.0500 (0.0500)  time: 0.1330  data: 0.0002  max mem: 2500\n",
      "Epoch: [7]  [ 80/227]  eta: 0:00:58  lr: 0.000379  min_lr: 0.000379  loss: 0.5012 (0.4970)  class_acc: 0.9000 (0.9222)  weight_decay: 0.0500 (0.0500)  time: 0.1329  data: 0.0001  max mem: 2500\n",
      "Epoch: [7]  [ 90/227]  eta: 0:00:50  lr: 0.000379  min_lr: 0.000379  loss: 0.4790 (0.4998)  class_acc: 0.9000 (0.9220)  weight_decay: 0.0500 (0.0500)  time: 0.1325  data: 0.0001  max mem: 2500\n",
      "Epoch: [7]  [100/227]  eta: 0:00:43  lr: 0.000379  min_lr: 0.000379  loss: 0.4790 (0.5003)  class_acc: 0.9000 (0.9228)  weight_decay: 0.0500 (0.0500)  time: 0.1331  data: 0.0001  max mem: 2500\n",
      "Epoch: [7]  [110/227]  eta: 0:00:37  lr: 0.000378  min_lr: 0.000378  loss: 0.5025 (0.5018)  class_acc: 0.9000 (0.9207)  weight_decay: 0.0500 (0.0500)  time: 0.1342  data: 0.0001  max mem: 2500\n",
      "Epoch: [7]  [120/227]  eta: 0:00:33  lr: 0.000378  min_lr: 0.000378  loss: 0.4495 (0.5020)  class_acc: 0.9000 (0.9207)  weight_decay: 0.0500 (0.0500)  time: 0.1336  data: 0.0000  max mem: 2500\n",
      "Epoch: [7]  [130/227]  eta: 0:00:28  lr: 0.000378  min_lr: 0.000378  loss: 0.4570 (0.5016)  class_acc: 0.9000 (0.9214)  weight_decay: 0.0500 (0.0500)  time: 0.1358  data: 0.0003  max mem: 2500\n",
      "Epoch: [7]  [140/227]  eta: 0:00:24  lr: 0.000378  min_lr: 0.000378  loss: 0.4678 (0.5011)  class_acc: 0.9000 (0.9213)  weight_decay: 0.0500 (0.0500)  time: 0.1370  data: 0.0003  max mem: 2500\n",
      "Epoch: [7]  [150/227]  eta: 0:00:21  lr: 0.000377  min_lr: 0.000377  loss: 0.4731 (0.5054)  class_acc: 0.9000 (0.9185)  weight_decay: 0.0500 (0.0500)  time: 0.1338  data: 0.0001  max mem: 2500\n",
      "Epoch: [7]  [160/227]  eta: 0:00:17  lr: 0.000377  min_lr: 0.000377  loss: 0.4814 (0.5020)  class_acc: 0.9000 (0.9199)  weight_decay: 0.0500 (0.0500)  time: 0.1332  data: 0.0001  max mem: 2500\n",
      "Epoch: [7]  [170/227]  eta: 0:00:14  lr: 0.000377  min_lr: 0.000377  loss: 0.4665 (0.5029)  class_acc: 1.0000 (0.9205)  weight_decay: 0.0500 (0.0500)  time: 0.1336  data: 0.0001  max mem: 2500\n",
      "Epoch: [7]  [180/227]  eta: 0:00:11  lr: 0.000377  min_lr: 0.000377  loss: 0.4865 (0.5018)  class_acc: 0.9000 (0.9204)  weight_decay: 0.0500 (0.0500)  time: 0.1345  data: 0.0002  max mem: 2500\n",
      "Epoch: [7]  [190/227]  eta: 0:00:09  lr: 0.000376  min_lr: 0.000376  loss: 0.4681 (0.5068)  class_acc: 0.9000 (0.9173)  weight_decay: 0.0500 (0.0500)  time: 0.1343  data: 0.0002  max mem: 2500\n",
      "Epoch: [7]  [200/227]  eta: 0:00:06  lr: 0.000376  min_lr: 0.000376  loss: 0.4605 (0.5047)  class_acc: 0.9000 (0.9189)  weight_decay: 0.0500 (0.0500)  time: 0.1345  data: 0.0002  max mem: 2500\n",
      "Epoch: [7]  [210/227]  eta: 0:00:03  lr: 0.000376  min_lr: 0.000376  loss: 0.4605 (0.5062)  class_acc: 0.9000 (0.9171)  weight_decay: 0.0500 (0.0500)  time: 0.1346  data: 0.0003  max mem: 2500\n",
      "Epoch: [7]  [220/227]  eta: 0:00:01  lr: 0.000376  min_lr: 0.000376  loss: 0.4635 (0.5068)  class_acc: 0.9000 (0.9167)  weight_decay: 0.0500 (0.0500)  time: 0.1336  data: 0.0002  max mem: 2500\n",
      "Epoch: [7]  [226/227]  eta: 0:00:00  lr: 0.000375  min_lr: 0.000375  loss: 0.4635 (0.5067)  class_acc: 0.9000 (0.9163)  weight_decay: 0.0500 (0.0500)  time: 0.1328  data: 0.0001  max mem: 2500\n",
      "Epoch: [7] Total time: 0:00:52 (0.2297 s / it)\n",
      "Averaged stats: lr: 0.000375  min_lr: 0.000375  loss: 0.4635 (0.5067)  class_acc: 0.9000 (0.9163)  weight_decay: 0.0500 (0.0500)\n",
      "Test:  [ 0/38]  eta: 0:13:27  loss: 0.1125 (0.1125)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 21.2380  data: 21.1840  max mem: 2500\n",
      "Test:  [10/38]  eta: 0:00:55  loss: 0.1780 (0.1791)  acc1: 93.3333 (96.3636)  acc5: 100.0000 (100.0000)  time: 1.9733  data: 1.9260  max mem: 2500\n",
      "Test:  [20/38]  eta: 0:00:19  loss: 0.2104 (0.4181)  acc1: 93.3333 (84.4444)  acc5: 100.0000 (100.0000)  time: 0.0467  data: 0.0002  max mem: 2500\n",
      "Test:  [30/38]  eta: 0:00:05  loss: 0.0815 (0.3096)  acc1: 100.0000 (89.2473)  acc5: 100.0000 (100.0000)  time: 0.0466  data: 0.0001  max mem: 2500\n",
      "Test:  [37/38]  eta: 0:00:00  loss: 0.0709 (0.2699)  acc1: 100.0000 (90.8929)  acc5: 100.0000 (100.0000)  time: 0.0452  data: 0.0000  max mem: 2500\n",
      "Test: Total time: 0:00:23 (0.6174 s / it)\n",
      "* Acc@1 90.893 Acc@5 100.000 loss 0.270\n",
      "[[135   0   1   4]\n",
      " [ 34  96   1   9]\n",
      " [  0   0 140   0]\n",
      " [  2   0   0 138]]\n",
      "(4, 4)\n",
      "Accuracy of the model on the 560 test images: 90.9%\n",
      "Max accuracy: 90.89%\n",
      "Epoch: [8]  [  0/227]  eta: 1:20:44  lr: 0.000375  min_lr: 0.000375  loss: 0.4640 (0.4640)  class_acc: 0.9000 (0.9000)  weight_decay: 0.0500 (0.0500)  time: 21.3403  data: 21.1943  max mem: 2500\n",
      "Epoch: [8]  [ 10/227]  eta: 0:07:27  lr: 0.000375  min_lr: 0.000375  loss: 0.5416 (0.5479)  class_acc: 0.9000 (0.8818)  weight_decay: 0.0500 (0.0500)  time: 2.0618  data: 1.9268  max mem: 2500\n",
      "Epoch: [8]  [ 20/227]  eta: 0:03:56  lr: 0.000375  min_lr: 0.000375  loss: 0.5416 (0.5271)  class_acc: 0.9000 (0.9095)  weight_decay: 0.0500 (0.0500)  time: 0.1341  data: 0.0001  max mem: 2500\n",
      "Epoch: [8]  [ 30/227]  eta: 0:02:41  lr: 0.000375  min_lr: 0.000375  loss: 0.5614 (0.5666)  class_acc: 0.9000 (0.8806)  weight_decay: 0.0500 (0.0500)  time: 0.1347  data: 0.0001  max mem: 2500\n",
      "Epoch: [8]  [ 40/227]  eta: 0:02:01  lr: 0.000374  min_lr: 0.000374  loss: 0.5778 (0.5541)  class_acc: 0.9000 (0.8878)  weight_decay: 0.0500 (0.0500)  time: 0.1351  data: 0.0002  max mem: 2500\n",
      "Epoch: [8]  [ 50/227]  eta: 0:01:37  lr: 0.000374  min_lr: 0.000374  loss: 0.4694 (0.5347)  class_acc: 0.9000 (0.9000)  weight_decay: 0.0500 (0.0500)  time: 0.1337  data: 0.0002  max mem: 2500\n",
      "Epoch: [8]  [ 60/227]  eta: 0:01:20  lr: 0.000374  min_lr: 0.000374  loss: 0.4231 (0.5277)  class_acc: 0.9000 (0.9033)  weight_decay: 0.0500 (0.0500)  time: 0.1325  data: 0.0001  max mem: 2500\n",
      "Epoch: [8]  [ 70/227]  eta: 0:01:07  lr: 0.000373  min_lr: 0.000373  loss: 0.4605 (0.5243)  class_acc: 0.9000 (0.9056)  weight_decay: 0.0500 (0.0500)  time: 0.1337  data: 0.0001  max mem: 2500\n",
      "Epoch: [8]  [ 80/227]  eta: 0:00:58  lr: 0.000373  min_lr: 0.000373  loss: 0.4621 (0.5187)  class_acc: 1.0000 (0.9123)  weight_decay: 0.0500 (0.0500)  time: 0.1348  data: 0.0000  max mem: 2500\n",
      "Epoch: [8]  [ 90/227]  eta: 0:00:50  lr: 0.000373  min_lr: 0.000373  loss: 0.4359 (0.5154)  class_acc: 1.0000 (0.9154)  weight_decay: 0.0500 (0.0500)  time: 0.1341  data: 0.0002  max mem: 2500\n",
      "Epoch: [8]  [100/227]  eta: 0:00:43  lr: 0.000373  min_lr: 0.000373  loss: 0.4207 (0.5058)  class_acc: 1.0000 (0.9218)  weight_decay: 0.0500 (0.0500)  time: 0.1337  data: 0.0003  max mem: 2500\n",
      "Epoch: [8]  [110/227]  eta: 0:00:38  lr: 0.000372  min_lr: 0.000372  loss: 0.3885 (0.4993)  class_acc: 1.0000 (0.9261)  weight_decay: 0.0500 (0.0500)  time: 0.1341  data: 0.0002  max mem: 2500\n",
      "Epoch: [8]  [120/227]  eta: 0:00:33  lr: 0.000372  min_lr: 0.000372  loss: 0.3818 (0.4951)  class_acc: 1.0000 (0.9273)  weight_decay: 0.0500 (0.0500)  time: 0.1333  data: 0.0001  max mem: 2500\n",
      "Epoch: [8]  [130/227]  eta: 0:00:28  lr: 0.000372  min_lr: 0.000372  loss: 0.4101 (0.4990)  class_acc: 0.9000 (0.9282)  weight_decay: 0.0500 (0.0500)  time: 0.1331  data: 0.0002  max mem: 2500\n",
      "Epoch: [8]  [140/227]  eta: 0:00:24  lr: 0.000371  min_lr: 0.000371  loss: 0.4399 (0.4986)  class_acc: 0.9000 (0.9277)  weight_decay: 0.0500 (0.0500)  time: 0.1333  data: 0.0002  max mem: 2500\n",
      "Epoch: [8]  [150/227]  eta: 0:00:21  lr: 0.000371  min_lr: 0.000371  loss: 0.4622 (0.5032)  class_acc: 0.9000 (0.9258)  weight_decay: 0.0500 (0.0500)  time: 0.1325  data: 0.0001  max mem: 2500\n",
      "Epoch: [8]  [160/227]  eta: 0:00:17  lr: 0.000371  min_lr: 0.000371  loss: 0.4482 (0.5039)  class_acc: 0.9000 (0.9261)  weight_decay: 0.0500 (0.0500)  time: 0.1322  data: 0.0001  max mem: 2500\n",
      "Epoch: [8]  [170/227]  eta: 0:00:14  lr: 0.000371  min_lr: 0.000371  loss: 0.5388 (0.5077)  class_acc: 0.9000 (0.9234)  weight_decay: 0.0500 (0.0500)  time: 0.1320  data: 0.0001  max mem: 2500\n",
      "Epoch: [8]  [180/227]  eta: 0:00:11  lr: 0.000370  min_lr: 0.000370  loss: 0.4921 (0.5051)  class_acc: 0.9000 (0.9249)  weight_decay: 0.0500 (0.0500)  time: 0.1326  data: 0.0002  max mem: 2500\n",
      "Epoch: [8]  [190/227]  eta: 0:00:09  lr: 0.000370  min_lr: 0.000370  loss: 0.4400 (0.5060)  class_acc: 1.0000 (0.9251)  weight_decay: 0.0500 (0.0500)  time: 0.1336  data: 0.0002  max mem: 2500\n",
      "Epoch: [8]  [200/227]  eta: 0:00:06  lr: 0.000370  min_lr: 0.000370  loss: 0.4559 (0.5048)  class_acc: 0.9000 (0.9254)  weight_decay: 0.0500 (0.0500)  time: 0.1335  data: 0.0001  max mem: 2500\n",
      "Epoch: [8]  [210/227]  eta: 0:00:03  lr: 0.000369  min_lr: 0.000369  loss: 0.4893 (0.5067)  class_acc: 0.9000 (0.9237)  weight_decay: 0.0500 (0.0500)  time: 0.1333  data: 0.0002  max mem: 2500\n",
      "Epoch: [8]  [220/227]  eta: 0:00:01  lr: 0.000369  min_lr: 0.000369  loss: 0.4857 (0.5076)  class_acc: 0.9000 (0.9226)  weight_decay: 0.0500 (0.0500)  time: 0.1340  data: 0.0002  max mem: 2500\n",
      "Epoch: [8]  [226/227]  eta: 0:00:00  lr: 0.000369  min_lr: 0.000369  loss: 0.4356 (0.5067)  class_acc: 0.9000 (0.9233)  weight_decay: 0.0500 (0.0500)  time: 0.1336  data: 0.0002  max mem: 2500\n",
      "Epoch: [8] Total time: 0:00:52 (0.2293 s / it)\n",
      "Averaged stats: lr: 0.000369  min_lr: 0.000369  loss: 0.4356 (0.5067)  class_acc: 0.9000 (0.9233)  weight_decay: 0.0500 (0.0500)\n",
      "Test:  [ 0/38]  eta: 0:13:30  loss: 0.1062 (0.1062)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 21.3223  data: 21.2663  max mem: 2500\n",
      "Test:  [10/38]  eta: 0:00:55  loss: 0.1812 (0.1868)  acc1: 93.3333 (95.1515)  acc5: 100.0000 (100.0000)  time: 1.9810  data: 1.9334  max mem: 2500\n",
      "Test:  [20/38]  eta: 0:00:19  loss: 0.2503 (0.5091)  acc1: 93.3333 (82.2222)  acc5: 100.0000 (100.0000)  time: 0.0469  data: 0.0001  max mem: 2500\n",
      "Test:  [30/38]  eta: 0:00:05  loss: 0.0982 (0.3738)  acc1: 100.0000 (87.7419)  acc5: 100.0000 (100.0000)  time: 0.0466  data: 0.0001  max mem: 2500\n",
      "Test:  [37/38]  eta: 0:00:00  loss: 0.0840 (0.3263)  acc1: 100.0000 (89.4643)  acc5: 100.0000 (100.0000)  time: 0.0450  data: 0.0002  max mem: 2500\n",
      "Test: Total time: 0:00:23 (0.6190 s / it)\n",
      "* Acc@1 89.464 Acc@5 100.000 loss 0.326\n",
      "[[132   1   1   6]\n",
      " [ 37  93   2   8]\n",
      " [  0   1 139   0]\n",
      " [  2   1   0 137]]\n",
      "(4, 4)\n",
      "Accuracy of the model on the 560 test images: 89.5%\n",
      "Max accuracy: 90.89%\n",
      "Epoch: [9]  [  0/227]  eta: 1:20:51  lr: 0.000369  min_lr: 0.000369  loss: 0.5381 (0.5381)  class_acc: 0.9000 (0.9000)  weight_decay: 0.0500 (0.0500)  time: 21.3722  data: 21.2241  max mem: 2500\n",
      "Epoch: [9]  [ 10/227]  eta: 0:07:27  lr: 0.000369  min_lr: 0.000369  loss: 0.4334 (0.4718)  class_acc: 0.9000 (0.9273)  weight_decay: 0.0500 (0.0500)  time: 2.0645  data: 1.9296  max mem: 2500\n",
      "Epoch: [9]  [ 20/227]  eta: 0:03:57  lr: 0.000368  min_lr: 0.000368  loss: 0.4106 (0.4841)  class_acc: 1.0000 (0.9381)  weight_decay: 0.0500 (0.0500)  time: 0.1343  data: 0.0001  max mem: 2500\n",
      "Epoch: [9]  [ 30/227]  eta: 0:02:41  lr: 0.000368  min_lr: 0.000368  loss: 0.4224 (0.5006)  class_acc: 1.0000 (0.9323)  weight_decay: 0.0500 (0.0500)  time: 0.1341  data: 0.0001  max mem: 2500\n",
      "Epoch: [9]  [ 40/227]  eta: 0:02:01  lr: 0.000368  min_lr: 0.000368  loss: 0.4659 (0.5055)  class_acc: 0.9000 (0.9244)  weight_decay: 0.0500 (0.0500)  time: 0.1337  data: 0.0002  max mem: 2500\n",
      "Epoch: [9]  [ 50/227]  eta: 0:01:37  lr: 0.000367  min_lr: 0.000367  loss: 0.4425 (0.5019)  class_acc: 0.9000 (0.9294)  weight_decay: 0.0500 (0.0500)  time: 0.1341  data: 0.0003  max mem: 2500\n",
      "Epoch: [9]  [ 60/227]  eta: 0:01:20  lr: 0.000367  min_lr: 0.000367  loss: 0.4189 (0.5020)  class_acc: 1.0000 (0.9262)  weight_decay: 0.0500 (0.0500)  time: 0.1351  data: 0.0002  max mem: 2500\n",
      "Epoch: [9]  [ 70/227]  eta: 0:01:08  lr: 0.000367  min_lr: 0.000367  loss: 0.4189 (0.5022)  class_acc: 0.9000 (0.9254)  weight_decay: 0.0500 (0.0500)  time: 0.1353  data: 0.0001  max mem: 2500\n",
      "Epoch: [9]  [ 80/227]  eta: 0:00:58  lr: 0.000367  min_lr: 0.000367  loss: 0.4634 (0.4988)  class_acc: 0.9000 (0.9247)  weight_decay: 0.0500 (0.0500)  time: 0.1332  data: 0.0002  max mem: 2500\n",
      "Epoch: [9]  [ 90/227]  eta: 0:00:50  lr: 0.000366  min_lr: 0.000366  loss: 0.4763 (0.4988)  class_acc: 0.9000 (0.9231)  weight_decay: 0.0500 (0.0500)  time: 0.1329  data: 0.0003  max mem: 2500\n",
      "Epoch: [9]  [100/227]  eta: 0:00:43  lr: 0.000366  min_lr: 0.000366  loss: 0.4763 (0.4997)  class_acc: 0.9000 (0.9228)  weight_decay: 0.0500 (0.0500)  time: 0.1340  data: 0.0002  max mem: 2500\n",
      "Epoch: [9]  [110/227]  eta: 0:00:38  lr: 0.000366  min_lr: 0.000366  loss: 0.4176 (0.4944)  class_acc: 1.0000 (0.9261)  weight_decay: 0.0500 (0.0500)  time: 0.1330  data: 0.0001  max mem: 2500\n",
      "Epoch: [9]  [120/227]  eta: 0:00:33  lr: 0.000365  min_lr: 0.000365  loss: 0.4018 (0.4933)  class_acc: 1.0000 (0.9273)  weight_decay: 0.0500 (0.0500)  time: 0.1323  data: 0.0001  max mem: 2500\n",
      "Epoch: [9]  [130/227]  eta: 0:00:28  lr: 0.000365  min_lr: 0.000365  loss: 0.5426 (0.5043)  class_acc: 0.9000 (0.9214)  weight_decay: 0.0500 (0.0500)  time: 0.1329  data: 0.0000  max mem: 2500\n",
      "Epoch: [9]  [140/227]  eta: 0:00:24  lr: 0.000365  min_lr: 0.000365  loss: 0.5555 (0.5042)  class_acc: 0.9000 (0.9220)  weight_decay: 0.0500 (0.0500)  time: 0.1337  data: 0.0001  max mem: 2500\n",
      "Epoch: [9]  [150/227]  eta: 0:00:21  lr: 0.000364  min_lr: 0.000364  loss: 0.4786 (0.5107)  class_acc: 0.9000 (0.9172)  weight_decay: 0.0500 (0.0500)  time: 0.1334  data: 0.0001  max mem: 2500\n",
      "Epoch: [9]  [160/227]  eta: 0:00:17  lr: 0.000364  min_lr: 0.000364  loss: 0.4786 (0.5106)  class_acc: 0.9000 (0.9174)  weight_decay: 0.0500 (0.0500)  time: 0.1330  data: 0.0002  max mem: 2500\n",
      "Epoch: [9]  [170/227]  eta: 0:00:14  lr: 0.000364  min_lr: 0.000364  loss: 0.4770 (0.5127)  class_acc: 0.9000 (0.9170)  weight_decay: 0.0500 (0.0500)  time: 0.1328  data: 0.0002  max mem: 2500\n",
      "Epoch: [9]  [180/227]  eta: 0:00:11  lr: 0.000363  min_lr: 0.000363  loss: 0.4482 (0.5092)  class_acc: 0.9000 (0.9193)  weight_decay: 0.0500 (0.0500)  time: 0.1333  data: 0.0003  max mem: 2500\n",
      "Epoch: [9]  [190/227]  eta: 0:00:09  lr: 0.000363  min_lr: 0.000363  loss: 0.4430 (0.5106)  class_acc: 0.9000 (0.9188)  weight_decay: 0.0500 (0.0500)  time: 0.1348  data: 0.0003  max mem: 2500\n",
      "Epoch: [9]  [200/227]  eta: 0:00:06  lr: 0.000363  min_lr: 0.000363  loss: 0.4728 (0.5080)  class_acc: 0.9000 (0.9209)  weight_decay: 0.0500 (0.0500)  time: 0.1339  data: 0.0001  max mem: 2500\n",
      "Epoch: [9]  [210/227]  eta: 0:00:03  lr: 0.000362  min_lr: 0.000362  loss: 0.4796 (0.5098)  class_acc: 0.9000 (0.9209)  weight_decay: 0.0500 (0.0500)  time: 0.1324  data: 0.0001  max mem: 2500\n",
      "Epoch: [9]  [220/227]  eta: 0:00:01  lr: 0.000362  min_lr: 0.000362  loss: 0.4374 (0.5064)  class_acc: 1.0000 (0.9226)  weight_decay: 0.0500 (0.0500)  time: 0.1324  data: 0.0001  max mem: 2500\n",
      "Epoch: [9]  [226/227]  eta: 0:00:00  lr: 0.000362  min_lr: 0.000362  loss: 0.4178 (0.5055)  class_acc: 0.9000 (0.9216)  weight_decay: 0.0500 (0.0500)  time: 0.1323  data: 0.0002  max mem: 2500\n",
      "Epoch: [9] Total time: 0:00:52 (0.2294 s / it)\n",
      "Averaged stats: lr: 0.000362  min_lr: 0.000362  loss: 0.4178 (0.5055)  class_acc: 0.9000 (0.9216)  weight_decay: 0.0500 (0.0500)\n",
      "Test:  [ 0/38]  eta: 0:13:17  loss: 0.0850 (0.0850)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 20.9860  data: 20.9270  max mem: 2500\n",
      "Test:  [10/38]  eta: 0:00:54  loss: 0.1621 (0.1639)  acc1: 100.0000 (96.9697)  acc5: 100.0000 (100.0000)  time: 1.9504  data: 1.9026  max mem: 2500\n",
      "Test:  [20/38]  eta: 0:00:18  loss: 0.2011 (0.4629)  acc1: 93.3333 (81.5873)  acc5: 100.0000 (100.0000)  time: 0.0467  data: 0.0002  max mem: 2500\n",
      "Test:  [30/38]  eta: 0:00:05  loss: 0.1171 (0.3441)  acc1: 93.3333 (87.0968)  acc5: 100.0000 (100.0000)  time: 0.0465  data: 0.0002  max mem: 2500\n",
      "Test:  [37/38]  eta: 0:00:00  loss: 0.0766 (0.2997)  acc1: 100.0000 (89.1071)  acc5: 100.0000 (100.0000)  time: 0.0449  data: 0.0002  max mem: 2500\n",
      "Test: Total time: 0:00:23 (0.6103 s / it)\n",
      "* Acc@1 89.107 Acc@5 100.000 loss 0.300\n",
      "[[136   0   1   3]\n",
      " [ 41  86   1  12]\n",
      " [  0   0 140   0]\n",
      " [  2   0   1 137]]\n",
      "(4, 4)\n",
      "Accuracy of the model on the 560 test images: 89.1%\n",
      "Max accuracy: 90.89%\n",
      "Epoch: [10]  [  0/227]  eta: 1:20:08  lr: 0.000362  min_lr: 0.000362  loss: 0.5595 (0.5595)  class_acc: 0.9000 (0.9000)  weight_decay: 0.0500 (0.0500)  time: 21.1831  data: 21.0350  max mem: 2500\n",
      "Epoch: [10]  [ 10/227]  eta: 0:07:23  lr: 0.000362  min_lr: 0.000362  loss: 0.4571 (0.5231)  class_acc: 0.9000 (0.9091)  weight_decay: 0.0500 (0.0500)  time: 2.0456  data: 1.9124  max mem: 2500\n",
      "Epoch: [10]  [ 20/227]  eta: 0:03:55  lr: 0.000361  min_lr: 0.000361  loss: 0.4607 (0.5287)  class_acc: 0.9000 (0.8952)  weight_decay: 0.0500 (0.0500)  time: 0.1333  data: 0.0001  max mem: 2500\n",
      "Epoch: [10]  [ 30/227]  eta: 0:02:40  lr: 0.000361  min_lr: 0.000361  loss: 0.5377 (0.5468)  class_acc: 0.9000 (0.8935)  weight_decay: 0.0500 (0.0500)  time: 0.1341  data: 0.0001  max mem: 2500\n",
      "Epoch: [10]  [ 40/227]  eta: 0:02:00  lr: 0.000361  min_lr: 0.000361  loss: 0.4531 (0.5241)  class_acc: 0.9000 (0.9098)  weight_decay: 0.0500 (0.0500)  time: 0.1329  data: 0.0000  max mem: 2500\n",
      "Epoch: [10]  [ 50/227]  eta: 0:01:36  lr: 0.000360  min_lr: 0.000360  loss: 0.4293 (0.5094)  class_acc: 1.0000 (0.9176)  weight_decay: 0.0500 (0.0500)  time: 0.1327  data: 0.0000  max mem: 2500\n",
      "Epoch: [10]  [ 60/227]  eta: 0:01:19  lr: 0.000360  min_lr: 0.000360  loss: 0.4283 (0.5079)  class_acc: 0.9000 (0.9213)  weight_decay: 0.0500 (0.0500)  time: 0.1325  data: 0.0001  max mem: 2500\n",
      "Epoch: [10]  [ 70/227]  eta: 0:01:07  lr: 0.000360  min_lr: 0.000360  loss: 0.4744 (0.5030)  class_acc: 0.9000 (0.9239)  weight_decay: 0.0500 (0.0500)  time: 0.1323  data: 0.0001  max mem: 2500\n",
      "Epoch: [10]  [ 80/227]  eta: 0:00:57  lr: 0.000359  min_lr: 0.000359  loss: 0.5038 (0.5066)  class_acc: 0.9000 (0.9185)  weight_decay: 0.0500 (0.0500)  time: 0.1328  data: 0.0001  max mem: 2500\n",
      "Epoch: [10]  [ 90/227]  eta: 0:00:49  lr: 0.000359  min_lr: 0.000359  loss: 0.5162 (0.5070)  class_acc: 0.9000 (0.9187)  weight_decay: 0.0500 (0.0500)  time: 0.1325  data: 0.0001  max mem: 2500\n",
      "Epoch: [10]  [100/227]  eta: 0:00:43  lr: 0.000359  min_lr: 0.000359  loss: 0.5601 (0.5180)  class_acc: 0.9000 (0.9109)  weight_decay: 0.0500 (0.0500)  time: 0.1327  data: 0.0000  max mem: 2500\n",
      "Epoch: [10]  [110/227]  eta: 0:00:37  lr: 0.000358  min_lr: 0.000358  loss: 0.5062 (0.5138)  class_acc: 0.9000 (0.9144)  weight_decay: 0.0500 (0.0500)  time: 0.1330  data: 0.0001  max mem: 2500\n",
      "Epoch: [10]  [120/227]  eta: 0:00:32  lr: 0.000358  min_lr: 0.000358  loss: 0.4208 (0.5077)  class_acc: 1.0000 (0.9182)  weight_decay: 0.0500 (0.0500)  time: 0.1334  data: 0.0001  max mem: 2500\n",
      "Epoch: [10]  [130/227]  eta: 0:00:28  lr: 0.000358  min_lr: 0.000358  loss: 0.4523 (0.5086)  class_acc: 0.9000 (0.9168)  weight_decay: 0.0500 (0.0500)  time: 0.1333  data: 0.0001  max mem: 2500\n",
      "Epoch: [10]  [140/227]  eta: 0:00:24  lr: 0.000357  min_lr: 0.000357  loss: 0.4306 (0.5044)  class_acc: 0.9000 (0.9191)  weight_decay: 0.0500 (0.0500)  time: 0.1324  data: 0.0002  max mem: 2500\n",
      "Epoch: [10]  [150/227]  eta: 0:00:20  lr: 0.000357  min_lr: 0.000357  loss: 0.3802 (0.5040)  class_acc: 1.0000 (0.9199)  weight_decay: 0.0500 (0.0500)  time: 0.1333  data: 0.0001  max mem: 2500\n",
      "Epoch: [10]  [160/227]  eta: 0:00:17  lr: 0.000357  min_lr: 0.000357  loss: 0.4341 (0.5081)  class_acc: 0.9000 (0.9186)  weight_decay: 0.0500 (0.0500)  time: 0.1328  data: 0.0001  max mem: 2500\n",
      "Epoch: [10]  [170/227]  eta: 0:00:14  lr: 0.000356  min_lr: 0.000356  loss: 0.5097 (0.5091)  class_acc: 0.9000 (0.9187)  weight_decay: 0.0500 (0.0500)  time: 0.1317  data: 0.0001  max mem: 2500\n",
      "Epoch: [10]  [180/227]  eta: 0:00:11  lr: 0.000356  min_lr: 0.000356  loss: 0.4890 (0.5068)  class_acc: 0.9000 (0.9199)  weight_decay: 0.0500 (0.0500)  time: 0.1323  data: 0.0002  max mem: 2500\n",
      "Epoch: [10]  [190/227]  eta: 0:00:08  lr: 0.000356  min_lr: 0.000356  loss: 0.4890 (0.5100)  class_acc: 0.9000 (0.9188)  weight_decay: 0.0500 (0.0500)  time: 0.1340  data: 0.0001  max mem: 2500\n",
      "Epoch: [10]  [200/227]  eta: 0:00:06  lr: 0.000355  min_lr: 0.000355  loss: 0.5033 (0.5100)  class_acc: 0.9000 (0.9194)  weight_decay: 0.0500 (0.0500)  time: 0.1338  data: 0.0001  max mem: 2500\n",
      "Epoch: [10]  [210/227]  eta: 0:00:03  lr: 0.000355  min_lr: 0.000355  loss: 0.4770 (0.5130)  class_acc: 0.9000 (0.9180)  weight_decay: 0.0500 (0.0500)  time: 0.1321  data: 0.0002  max mem: 2500\n",
      "Epoch: [10]  [220/227]  eta: 0:00:01  lr: 0.000354  min_lr: 0.000354  loss: 0.4562 (0.5104)  class_acc: 0.9000 (0.9186)  weight_decay: 0.0500 (0.0500)  time: 0.1331  data: 0.0002  max mem: 2500\n",
      "Epoch: [10]  [226/227]  eta: 0:00:00  lr: 0.000354  min_lr: 0.000354  loss: 0.4562 (0.5102)  class_acc: 0.9000 (0.9189)  weight_decay: 0.0500 (0.0500)  time: 0.1334  data: 0.0001  max mem: 2500\n",
      "Epoch: [10] Total time: 0:00:51 (0.2280 s / it)\n",
      "Averaged stats: lr: 0.000354  min_lr: 0.000354  loss: 0.4562 (0.5102)  class_acc: 0.9000 (0.9189)  weight_decay: 0.0500 (0.0500)\n",
      "Test:  [ 0/38]  eta: 0:13:31  loss: 0.0938 (0.0938)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 21.3652  data: 21.3112  max mem: 2500\n",
      "Test:  [10/38]  eta: 0:00:55  loss: 0.1124 (0.1152)  acc1: 100.0000 (99.3939)  acc5: 100.0000 (100.0000)  time: 1.9847  data: 1.9375  max mem: 2500\n",
      "Test:  [20/38]  eta: 0:00:19  loss: 0.1648 (0.3701)  acc1: 100.0000 (86.9841)  acc5: 100.0000 (100.0000)  time: 0.0467  data: 0.0001  max mem: 2500\n",
      "Test:  [30/38]  eta: 0:00:05  loss: 0.1535 (0.2837)  acc1: 93.3333 (90.7527)  acc5: 100.0000 (100.0000)  time: 0.0466  data: 0.0000  max mem: 2500\n",
      "Test:  [37/38]  eta: 0:00:00  loss: 0.0903 (0.2554)  acc1: 100.0000 (92.1429)  acc5: 100.0000 (100.0000)  time: 0.0451  data: 0.0001  max mem: 2500\n",
      "Test: Total time: 0:00:23 (0.6209 s / it)\n",
      "* Acc@1 92.143 Acc@5 100.000 loss 0.255\n",
      "[[140   0   0   0]\n",
      " [ 35 100   0   5]\n",
      " [  1   0 139   0]\n",
      " [  3   0   0 137]]\n",
      "(4, 4)\n",
      "Accuracy of the model on the 560 test images: 92.1%\n",
      "Max accuracy: 92.14%\n",
      "Epoch: [11]  [  0/227]  eta: 1:19:12  lr: 0.000354  min_lr: 0.000354  loss: 0.3566 (0.3566)  class_acc: 1.0000 (1.0000)  weight_decay: 0.0500 (0.0500)  time: 20.9376  data: 20.7896  max mem: 2500\n",
      "Epoch: [11]  [ 10/227]  eta: 0:07:19  lr: 0.000354  min_lr: 0.000354  loss: 0.4087 (0.4950)  class_acc: 1.0000 (0.9364)  weight_decay: 0.0500 (0.0500)  time: 2.0239  data: 1.8901  max mem: 2500\n",
      "Epoch: [11]  [ 20/227]  eta: 0:03:52  lr: 0.000354  min_lr: 0.000354  loss: 0.4087 (0.4846)  class_acc: 1.0000 (0.9333)  weight_decay: 0.0500 (0.0500)  time: 0.1332  data: 0.0001  max mem: 2500\n",
      "Epoch: [11]  [ 30/227]  eta: 0:02:38  lr: 0.000353  min_lr: 0.000353  loss: 0.4286 (0.5045)  class_acc: 1.0000 (0.9258)  weight_decay: 0.0500 (0.0500)  time: 0.1337  data: 0.0002  max mem: 2500\n",
      "Epoch: [11]  [ 40/227]  eta: 0:01:59  lr: 0.000353  min_lr: 0.000353  loss: 0.4018 (0.4767)  class_acc: 1.0000 (0.9415)  weight_decay: 0.0500 (0.0500)  time: 0.1347  data: 0.0003  max mem: 2500\n",
      "Epoch: [11]  [ 50/227]  eta: 0:01:35  lr: 0.000352  min_lr: 0.000352  loss: 0.3903 (0.4649)  class_acc: 1.0000 (0.9490)  weight_decay: 0.0500 (0.0500)  time: 0.1349  data: 0.0001  max mem: 2500\n",
      "Epoch: [11]  [ 60/227]  eta: 0:01:19  lr: 0.000352  min_lr: 0.000352  loss: 0.3903 (0.4667)  class_acc: 1.0000 (0.9459)  weight_decay: 0.0500 (0.0500)  time: 0.1349  data: 0.0002  max mem: 2500\n",
      "Epoch: [11]  [ 70/227]  eta: 0:01:07  lr: 0.000352  min_lr: 0.000352  loss: 0.4060 (0.4699)  class_acc: 0.9000 (0.9437)  weight_decay: 0.0500 (0.0500)  time: 0.1351  data: 0.0001  max mem: 2500\n",
      "Epoch: [11]  [ 80/227]  eta: 0:00:57  lr: 0.000351  min_lr: 0.000351  loss: 0.4789 (0.4705)  class_acc: 0.9000 (0.9420)  weight_decay: 0.0500 (0.0500)  time: 0.1346  data: 0.0001  max mem: 2500\n",
      "Epoch: [11]  [ 90/227]  eta: 0:00:49  lr: 0.000351  min_lr: 0.000351  loss: 0.4789 (0.4768)  class_acc: 0.9000 (0.9374)  weight_decay: 0.0500 (0.0500)  time: 0.1354  data: 0.0002  max mem: 2500\n",
      "Epoch: [11]  [100/227]  eta: 0:00:43  lr: 0.000351  min_lr: 0.000351  loss: 0.4873 (0.4783)  class_acc: 0.9000 (0.9347)  weight_decay: 0.0500 (0.0500)  time: 0.1350  data: 0.0003  max mem: 2500\n",
      "Epoch: [11]  [110/227]  eta: 0:00:37  lr: 0.000350  min_lr: 0.000350  loss: 0.4784 (0.4820)  class_acc: 0.9000 (0.9324)  weight_decay: 0.0500 (0.0500)  time: 0.1336  data: 0.0002  max mem: 2500\n",
      "Epoch: [11]  [120/227]  eta: 0:00:32  lr: 0.000350  min_lr: 0.000350  loss: 0.5051 (0.4831)  class_acc: 0.9000 (0.9314)  weight_decay: 0.0500 (0.0500)  time: 0.1349  data: 0.0002  max mem: 2500\n",
      "Epoch: [11]  [130/227]  eta: 0:00:28  lr: 0.000350  min_lr: 0.000350  loss: 0.4657 (0.4846)  class_acc: 0.9000 (0.9313)  weight_decay: 0.0500 (0.0500)  time: 0.1365  data: 0.0001  max mem: 2500\n",
      "Epoch: [11]  [140/227]  eta: 0:00:24  lr: 0.000349  min_lr: 0.000349  loss: 0.4393 (0.4853)  class_acc: 0.9000 (0.9312)  weight_decay: 0.0500 (0.0500)  time: 0.1347  data: 0.0000  max mem: 2500\n",
      "Epoch: [11]  [150/227]  eta: 0:00:20  lr: 0.000349  min_lr: 0.000349  loss: 0.4753 (0.4896)  class_acc: 0.9000 (0.9305)  weight_decay: 0.0500 (0.0500)  time: 0.1329  data: 0.0001  max mem: 2500\n",
      "Epoch: [11]  [160/227]  eta: 0:00:17  lr: 0.000348  min_lr: 0.000348  loss: 0.4753 (0.4924)  class_acc: 0.9000 (0.9292)  weight_decay: 0.0500 (0.0500)  time: 0.1335  data: 0.0001  max mem: 2500\n",
      "Epoch: [11]  [170/227]  eta: 0:00:14  lr: 0.000348  min_lr: 0.000348  loss: 0.4687 (0.4935)  class_acc: 0.9000 (0.9304)  weight_decay: 0.0500 (0.0500)  time: 0.1334  data: 0.0000  max mem: 2500\n",
      "Epoch: [11]  [180/227]  eta: 0:00:11  lr: 0.000348  min_lr: 0.000348  loss: 0.3954 (0.4885)  class_acc: 1.0000 (0.9320)  weight_decay: 0.0500 (0.0500)  time: 0.1334  data: 0.0001  max mem: 2500\n",
      "Epoch: [11]  [190/227]  eta: 0:00:09  lr: 0.000347  min_lr: 0.000347  loss: 0.3751 (0.4877)  class_acc: 1.0000 (0.9319)  weight_decay: 0.0500 (0.0500)  time: 0.1358  data: 0.0001  max mem: 2500\n",
      "Epoch: [11]  [200/227]  eta: 0:00:06  lr: 0.000347  min_lr: 0.000347  loss: 0.3987 (0.4865)  class_acc: 1.0000 (0.9318)  weight_decay: 0.0500 (0.0500)  time: 0.1364  data: 0.0001  max mem: 2500\n",
      "Epoch: [11]  [210/227]  eta: 0:00:03  lr: 0.000347  min_lr: 0.000347  loss: 0.4264 (0.4852)  class_acc: 0.9000 (0.9332)  weight_decay: 0.0500 (0.0500)  time: 0.1348  data: 0.0001  max mem: 2500\n",
      "Epoch: [11]  [220/227]  eta: 0:00:01  lr: 0.000346  min_lr: 0.000346  loss: 0.3906 (0.4850)  class_acc: 1.0000 (0.9335)  weight_decay: 0.0500 (0.0500)  time: 0.1330  data: 0.0001  max mem: 2500\n",
      "Epoch: [11]  [226/227]  eta: 0:00:00  lr: 0.000346  min_lr: 0.000346  loss: 0.4281 (0.4842)  class_acc: 0.9000 (0.9339)  weight_decay: 0.0500 (0.0500)  time: 0.1339  data: 0.0001  max mem: 2500\n",
      "Epoch: [11] Total time: 0:00:51 (0.2284 s / it)\n",
      "Averaged stats: lr: 0.000346  min_lr: 0.000346  loss: 0.4281 (0.4842)  class_acc: 0.9000 (0.9339)  weight_decay: 0.0500 (0.0500)\n",
      "Test:  [ 0/38]  eta: 0:13:06  loss: 0.1118 (0.1118)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 20.7082  data: 20.6502  max mem: 2500\n",
      "Test:  [10/38]  eta: 0:00:53  loss: 0.1350 (0.1405)  acc1: 100.0000 (96.9697)  acc5: 100.0000 (100.0000)  time: 1.9249  data: 1.8776  max mem: 2500\n",
      "Test:  [20/38]  eta: 0:00:18  loss: 0.1771 (0.3078)  acc1: 93.3333 (89.5238)  acc5: 100.0000 (100.0000)  time: 0.0466  data: 0.0002  max mem: 2500\n",
      "Test:  [30/38]  eta: 0:00:05  loss: 0.1119 (0.2500)  acc1: 100.0000 (92.6882)  acc5: 100.0000 (100.0000)  time: 0.0464  data: 0.0001  max mem: 2500\n",
      "Test:  [37/38]  eta: 0:00:00  loss: 0.1093 (0.2262)  acc1: 100.0000 (93.9286)  acc5: 100.0000 (100.0000)  time: 0.0448  data: 0.0001  max mem: 2500\n",
      "Test: Total time: 0:00:22 (0.6041 s / it)\n",
      "* Acc@1 93.929 Acc@5 100.000 loss 0.226\n",
      "[[135   3   0   2]\n",
      " [ 21 112   0   7]\n",
      " [  0   0 140   0]\n",
      " [  1   0   0 139]]\n",
      "(4, 4)\n",
      "Accuracy of the model on the 560 test images: 93.9%\n",
      "Max accuracy: 93.93%\n",
      "Epoch: [12]  [  0/227]  eta: 1:18:22  lr: 0.000346  min_lr: 0.000346  loss: 0.3918 (0.3918)  class_acc: 1.0000 (1.0000)  weight_decay: 0.0500 (0.0500)  time: 20.7161  data: 20.5731  max mem: 2500\n",
      "Epoch: [12]  [ 10/227]  eta: 0:07:14  lr: 0.000346  min_lr: 0.000346  loss: 0.3918 (0.4480)  class_acc: 1.0000 (0.9545)  weight_decay: 0.0500 (0.0500)  time: 2.0040  data: 1.8705  max mem: 2500\n",
      "Epoch: [12]  [ 20/227]  eta: 0:03:50  lr: 0.000345  min_lr: 0.000345  loss: 0.4224 (0.4931)  class_acc: 1.0000 (0.9333)  weight_decay: 0.0500 (0.0500)  time: 0.1327  data: 0.0002  max mem: 2500\n",
      "Epoch: [12]  [ 30/227]  eta: 0:02:37  lr: 0.000345  min_lr: 0.000345  loss: 0.4891 (0.5147)  class_acc: 0.9000 (0.9194)  weight_decay: 0.0500 (0.0500)  time: 0.1342  data: 0.0001  max mem: 2500\n",
      "Epoch: [12]  [ 40/227]  eta: 0:01:59  lr: 0.000344  min_lr: 0.000344  loss: 0.4316 (0.4934)  class_acc: 0.9000 (0.9268)  weight_decay: 0.0500 (0.0500)  time: 0.1361  data: 0.0000  max mem: 2500\n",
      "Epoch: [12]  [ 50/227]  eta: 0:01:35  lr: 0.000344  min_lr: 0.000344  loss: 0.4171 (0.4775)  class_acc: 1.0000 (0.9373)  weight_decay: 0.0500 (0.0500)  time: 0.1354  data: 0.0001  max mem: 2500\n",
      "Epoch: [12]  [ 60/227]  eta: 0:01:18  lr: 0.000344  min_lr: 0.000344  loss: 0.4040 (0.4751)  class_acc: 1.0000 (0.9377)  weight_decay: 0.0500 (0.0500)  time: 0.1351  data: 0.0002  max mem: 2500\n",
      "Epoch: [12]  [ 70/227]  eta: 0:01:06  lr: 0.000343  min_lr: 0.000343  loss: 0.4243 (0.4882)  class_acc: 0.9000 (0.9352)  weight_decay: 0.0500 (0.0500)  time: 0.1358  data: 0.0002  max mem: 2500\n",
      "Epoch: [12]  [ 80/227]  eta: 0:00:57  lr: 0.000343  min_lr: 0.000343  loss: 0.4703 (0.4871)  class_acc: 0.9000 (0.9346)  weight_decay: 0.0500 (0.0500)  time: 0.1348  data: 0.0003  max mem: 2500\n",
      "Epoch: [12]  [ 90/227]  eta: 0:00:49  lr: 0.000342  min_lr: 0.000342  loss: 0.4817 (0.4960)  class_acc: 0.9000 (0.9286)  weight_decay: 0.0500 (0.0500)  time: 0.1335  data: 0.0003  max mem: 2500\n",
      "Epoch: [12]  [100/227]  eta: 0:00:42  lr: 0.000342  min_lr: 0.000342  loss: 0.5480 (0.5003)  class_acc: 0.9000 (0.9257)  weight_decay: 0.0500 (0.0500)  time: 0.1334  data: 0.0002  max mem: 2500\n",
      "Epoch: [12]  [110/227]  eta: 0:00:37  lr: 0.000342  min_lr: 0.000342  loss: 0.5094 (0.5021)  class_acc: 0.9000 (0.9234)  weight_decay: 0.0500 (0.0500)  time: 0.1330  data: 0.0002  max mem: 2500\n",
      "Epoch: [12]  [120/227]  eta: 0:00:32  lr: 0.000341  min_lr: 0.000341  loss: 0.4546 (0.5004)  class_acc: 0.9000 (0.9256)  weight_decay: 0.0500 (0.0500)  time: 0.1338  data: 0.0002  max mem: 2500\n",
      "Epoch: [12]  [130/227]  eta: 0:00:28  lr: 0.000341  min_lr: 0.000341  loss: 0.4554 (0.5102)  class_acc: 0.9000 (0.9229)  weight_decay: 0.0500 (0.0500)  time: 0.1351  data: 0.0001  max mem: 2500\n",
      "Epoch: [12]  [140/227]  eta: 0:00:24  lr: 0.000341  min_lr: 0.000341  loss: 0.5035 (0.5091)  class_acc: 0.9000 (0.9227)  weight_decay: 0.0500 (0.0500)  time: 0.1353  data: 0.0002  max mem: 2500\n",
      "Epoch: [12]  [150/227]  eta: 0:00:20  lr: 0.000340  min_lr: 0.000340  loss: 0.5700 (0.5170)  class_acc: 0.9000 (0.9172)  weight_decay: 0.0500 (0.0500)  time: 0.1346  data: 0.0001  max mem: 2500\n",
      "Epoch: [12]  [160/227]  eta: 0:00:17  lr: 0.000340  min_lr: 0.000340  loss: 0.5462 (0.5149)  class_acc: 0.9000 (0.9193)  weight_decay: 0.0500 (0.0500)  time: 0.1345  data: 0.0002  max mem: 2500\n",
      "Epoch: [12]  [170/227]  eta: 0:00:14  lr: 0.000339  min_lr: 0.000339  loss: 0.4308 (0.5150)  class_acc: 1.0000 (0.9187)  weight_decay: 0.0500 (0.0500)  time: 0.1351  data: 0.0002  max mem: 2500\n",
      "Epoch: [12]  [180/227]  eta: 0:00:11  lr: 0.000339  min_lr: 0.000339  loss: 0.4509 (0.5124)  class_acc: 0.9000 (0.9193)  weight_decay: 0.0500 (0.0500)  time: 0.1337  data: 0.0001  max mem: 2500\n",
      "Epoch: [12]  [190/227]  eta: 0:00:08  lr: 0.000339  min_lr: 0.000339  loss: 0.4389 (0.5122)  class_acc: 0.9000 (0.9199)  weight_decay: 0.0500 (0.0500)  time: 0.1348  data: 0.0001  max mem: 2500\n",
      "Epoch: [12]  [200/227]  eta: 0:00:06  lr: 0.000338  min_lr: 0.000338  loss: 0.3998 (0.5094)  class_acc: 1.0000 (0.9214)  weight_decay: 0.0500 (0.0500)  time: 0.1355  data: 0.0001  max mem: 2500\n",
      "Epoch: [12]  [210/227]  eta: 0:00:03  lr: 0.000338  min_lr: 0.000338  loss: 0.4613 (0.5100)  class_acc: 0.9000 (0.9209)  weight_decay: 0.0500 (0.0500)  time: 0.1336  data: 0.0001  max mem: 2500\n",
      "Epoch: [12]  [220/227]  eta: 0:00:01  lr: 0.000337  min_lr: 0.000337  loss: 0.5127 (0.5098)  class_acc: 0.9000 (0.9208)  weight_decay: 0.0500 (0.0500)  time: 0.1335  data: 0.0001  max mem: 2500\n",
      "Epoch: [12]  [226/227]  eta: 0:00:00  lr: 0.000337  min_lr: 0.000337  loss: 0.4788 (0.5101)  class_acc: 0.9000 (0.9216)  weight_decay: 0.0500 (0.0500)  time: 0.1334  data: 0.0001  max mem: 2500\n",
      "Epoch: [12] Total time: 0:00:51 (0.2273 s / it)\n",
      "Averaged stats: lr: 0.000337  min_lr: 0.000337  loss: 0.4788 (0.5101)  class_acc: 0.9000 (0.9216)  weight_decay: 0.0500 (0.0500)\n",
      "Test:  [ 0/38]  eta: 0:13:03  loss: 0.1529 (0.1529)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 20.6181  data: 20.5611  max mem: 2500\n",
      "Test:  [10/38]  eta: 0:00:53  loss: 0.2574 (0.2222)  acc1: 93.3333 (95.7576)  acc5: 100.0000 (100.0000)  time: 1.9169  data: 1.8695  max mem: 2500\n",
      "Test:  [20/38]  eta: 0:00:18  loss: 0.2757 (0.3950)  acc1: 93.3333 (86.6667)  acc5: 100.0000 (100.0000)  time: 0.0468  data: 0.0003  max mem: 2500\n",
      "Test:  [30/38]  eta: 0:00:05  loss: 0.0964 (0.2982)  acc1: 100.0000 (90.9677)  acc5: 100.0000 (100.0000)  time: 0.0465  data: 0.0001  max mem: 2500\n",
      "Test:  [37/38]  eta: 0:00:00  loss: 0.0931 (0.2600)  acc1: 100.0000 (92.5000)  acc5: 100.0000 (100.0000)  time: 0.0450  data: 0.0001  max mem: 2500\n",
      "Test: Total time: 0:00:22 (0.6008 s / it)\n",
      "* Acc@1 92.500 Acc@5 100.000 loss 0.260\n",
      "[[133   0   0   7]\n",
      " [ 18 105   0  17]\n",
      " [  0   0 140   0]\n",
      " [  0   0   0 140]]\n",
      "(4, 4)\n",
      "Accuracy of the model on the 560 test images: 92.5%\n",
      "Max accuracy: 93.93%\n",
      "Epoch: [13]  [  0/227]  eta: 1:18:33  lr: 0.000337  min_lr: 0.000337  loss: 0.5547 (0.5547)  class_acc: 0.9000 (0.9000)  weight_decay: 0.0500 (0.0500)  time: 20.7627  data: 20.6217  max mem: 2500\n",
      "Epoch: [13]  [ 10/227]  eta: 0:07:16  lr: 0.000337  min_lr: 0.000337  loss: 0.4263 (0.4287)  class_acc: 1.0000 (0.9818)  weight_decay: 0.0500 (0.0500)  time: 2.0092  data: 1.8748  max mem: 2500\n",
      "Epoch: [13]  [ 20/227]  eta: 0:03:51  lr: 0.000336  min_lr: 0.000336  loss: 0.4285 (0.4549)  class_acc: 1.0000 (0.9571)  weight_decay: 0.0500 (0.0500)  time: 0.1342  data: 0.0002  max mem: 2500\n",
      "Epoch: [13]  [ 30/227]  eta: 0:02:37  lr: 0.000336  min_lr: 0.000336  loss: 0.4453 (0.4680)  class_acc: 0.9000 (0.9516)  weight_decay: 0.0500 (0.0500)  time: 0.1353  data: 0.0003  max mem: 2500\n",
      "Epoch: [13]  [ 40/227]  eta: 0:01:59  lr: 0.000335  min_lr: 0.000335  loss: 0.4538 (0.4811)  class_acc: 0.9000 (0.9390)  weight_decay: 0.0500 (0.0500)  time: 0.1355  data: 0.0002  max mem: 2500\n",
      "Epoch: [13]  [ 50/227]  eta: 0:01:35  lr: 0.000335  min_lr: 0.000335  loss: 0.4346 (0.4804)  class_acc: 0.9000 (0.9392)  weight_decay: 0.0500 (0.0500)  time: 0.1342  data: 0.0001  max mem: 2500\n",
      "Epoch: [13]  [ 60/227]  eta: 0:01:18  lr: 0.000335  min_lr: 0.000335  loss: 0.3965 (0.4757)  class_acc: 1.0000 (0.9426)  weight_decay: 0.0500 (0.0500)  time: 0.1345  data: 0.0001  max mem: 2500\n",
      "Epoch: [13]  [ 70/227]  eta: 0:01:06  lr: 0.000334  min_lr: 0.000334  loss: 0.4342 (0.4794)  class_acc: 0.9000 (0.9394)  weight_decay: 0.0500 (0.0500)  time: 0.1346  data: 0.0001  max mem: 2500\n",
      "Epoch: [13]  [ 80/227]  eta: 0:00:57  lr: 0.000334  min_lr: 0.000334  loss: 0.4663 (0.4858)  class_acc: 0.9000 (0.9383)  weight_decay: 0.0500 (0.0500)  time: 0.1345  data: 0.0002  max mem: 2500\n",
      "Epoch: [13]  [ 90/227]  eta: 0:00:49  lr: 0.000333  min_lr: 0.000333  loss: 0.4596 (0.4861)  class_acc: 1.0000 (0.9352)  weight_decay: 0.0500 (0.0500)  time: 0.1349  data: 0.0002  max mem: 2500\n",
      "Epoch: [13]  [100/227]  eta: 0:00:43  lr: 0.000333  min_lr: 0.000333  loss: 0.4775 (0.4890)  class_acc: 0.9000 (0.9347)  weight_decay: 0.0500 (0.0500)  time: 0.1337  data: 0.0002  max mem: 2500\n",
      "Epoch: [13]  [110/227]  eta: 0:00:37  lr: 0.000333  min_lr: 0.000333  loss: 0.4673 (0.4869)  class_acc: 0.9000 (0.9342)  weight_decay: 0.0500 (0.0500)  time: 0.1331  data: 0.0002  max mem: 2500\n",
      "Epoch: [13]  [120/227]  eta: 0:00:32  lr: 0.000332  min_lr: 0.000332  loss: 0.4173 (0.4833)  class_acc: 1.0000 (0.9355)  weight_decay: 0.0500 (0.0500)  time: 0.1327  data: 0.0002  max mem: 2500\n",
      "Epoch: [13]  [130/227]  eta: 0:00:28  lr: 0.000332  min_lr: 0.000332  loss: 0.3903 (0.4814)  class_acc: 1.0000 (0.9382)  weight_decay: 0.0500 (0.0500)  time: 0.1333  data: 0.0001  max mem: 2500\n",
      "Epoch: [13]  [140/227]  eta: 0:00:24  lr: 0.000331  min_lr: 0.000331  loss: 0.3929 (0.4781)  class_acc: 1.0000 (0.9390)  weight_decay: 0.0500 (0.0500)  time: 0.1337  data: 0.0001  max mem: 2500\n",
      "Epoch: [13]  [150/227]  eta: 0:00:20  lr: 0.000331  min_lr: 0.000331  loss: 0.4316 (0.4805)  class_acc: 0.9000 (0.9377)  weight_decay: 0.0500 (0.0500)  time: 0.1332  data: 0.0001  max mem: 2500\n",
      "Epoch: [13]  [160/227]  eta: 0:00:17  lr: 0.000330  min_lr: 0.000330  loss: 0.4509 (0.4799)  class_acc: 0.9000 (0.9379)  weight_decay: 0.0500 (0.0500)  time: 0.1345  data: 0.0002  max mem: 2500\n",
      "Epoch: [13]  [170/227]  eta: 0:00:14  lr: 0.000330  min_lr: 0.000330  loss: 0.4457 (0.4791)  class_acc: 0.9000 (0.9386)  weight_decay: 0.0500 (0.0500)  time: 0.1343  data: 0.0002  max mem: 2500\n",
      "Epoch: [13]  [180/227]  eta: 0:00:11  lr: 0.000330  min_lr: 0.000330  loss: 0.4526 (0.4842)  class_acc: 0.9000 (0.9370)  weight_decay: 0.0500 (0.0500)  time: 0.1349  data: 0.0001  max mem: 2500\n",
      "Epoch: [13]  [190/227]  eta: 0:00:08  lr: 0.000329  min_lr: 0.000329  loss: 0.5075 (0.4882)  class_acc: 0.9000 (0.9351)  weight_decay: 0.0500 (0.0500)  time: 0.1349  data: 0.0001  max mem: 2500\n",
      "Epoch: [13]  [200/227]  eta: 0:00:06  lr: 0.000329  min_lr: 0.000329  loss: 0.5694 (0.4944)  class_acc: 0.9000 (0.9318)  weight_decay: 0.0500 (0.0500)  time: 0.1356  data: 0.0001  max mem: 2500\n",
      "Epoch: [13]  [210/227]  eta: 0:00:03  lr: 0.000328  min_lr: 0.000328  loss: 0.4888 (0.4936)  class_acc: 0.9000 (0.9332)  weight_decay: 0.0500 (0.0500)  time: 0.1366  data: 0.0002  max mem: 2500\n",
      "Epoch: [13]  [220/227]  eta: 0:00:01  lr: 0.000328  min_lr: 0.000328  loss: 0.4888 (0.4952)  class_acc: 0.9000 (0.9326)  weight_decay: 0.0500 (0.0500)  time: 0.1341  data: 0.0002  max mem: 2500\n",
      "Epoch: [13]  [226/227]  eta: 0:00:00  lr: 0.000328  min_lr: 0.000328  loss: 0.5080 (0.4940)  class_acc: 0.9000 (0.9335)  weight_decay: 0.0500 (0.0500)  time: 0.1332  data: 0.0001  max mem: 2500\n",
      "Epoch: [13] Total time: 0:00:51 (0.2275 s / it)\n",
      "Averaged stats: lr: 0.000328  min_lr: 0.000328  loss: 0.5080 (0.4940)  class_acc: 0.9000 (0.9335)  weight_decay: 0.0500 (0.0500)\n",
      "Test:  [ 0/38]  eta: 0:13:05  loss: 0.0707 (0.0707)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 20.6691  data: 20.6121  max mem: 2500\n",
      "Test:  [10/38]  eta: 0:00:53  loss: 0.0843 (0.1006)  acc1: 100.0000 (98.7879)  acc5: 100.0000 (100.0000)  time: 1.9214  data: 1.8739  max mem: 2500\n",
      "Test:  [20/38]  eta: 0:00:18  loss: 0.1429 (0.3810)  acc1: 93.3333 (86.3492)  acc5: 100.0000 (100.0000)  time: 0.0467  data: 0.0001  max mem: 2500\n",
      "Test:  [30/38]  eta: 0:00:05  loss: 0.1416 (0.2967)  acc1: 93.3333 (90.3226)  acc5: 100.0000 (100.0000)  time: 0.0466  data: 0.0001  max mem: 2500\n",
      "Test:  [37/38]  eta: 0:00:00  loss: 0.0977 (0.2640)  acc1: 100.0000 (91.7857)  acc5: 100.0000 (100.0000)  time: 0.0450  data: 0.0001  max mem: 2500\n",
      "Test: Total time: 0:00:22 (0.6017 s / it)\n",
      "* Acc@1 91.786 Acc@5 100.000 loss 0.264\n",
      "[[139   0   0   1]\n",
      " [ 35 100   0   5]\n",
      " [  0   4 136   0]\n",
      " [  1   0   0 139]]\n",
      "(4, 4)\n",
      "Accuracy of the model on the 560 test images: 91.8%\n",
      "Max accuracy: 93.93%\n",
      "Epoch: [14]  [  0/227]  eta: 1:18:08  lr: 0.000328  min_lr: 0.000328  loss: 0.3780 (0.3780)  class_acc: 1.0000 (1.0000)  weight_decay: 0.0500 (0.0500)  time: 20.6538  data: 20.5087  max mem: 2500\n",
      "Epoch: [14]  [ 10/227]  eta: 0:07:13  lr: 0.000327  min_lr: 0.000327  loss: 0.3780 (0.4761)  class_acc: 1.0000 (0.9455)  weight_decay: 0.0500 (0.0500)  time: 1.9979  data: 1.8645  max mem: 2500\n",
      "Epoch: [14]  [ 20/227]  eta: 0:03:49  lr: 0.000327  min_lr: 0.000327  loss: 0.4083 (0.5033)  class_acc: 1.0000 (0.9238)  weight_decay: 0.0500 (0.0500)  time: 0.1324  data: 0.0001  max mem: 2500\n",
      "Epoch: [14]  [ 30/227]  eta: 0:02:36  lr: 0.000326  min_lr: 0.000326  loss: 0.4150 (0.4915)  class_acc: 1.0000 (0.9355)  weight_decay: 0.0500 (0.0500)  time: 0.1325  data: 0.0001  max mem: 2500\n",
      "Epoch: [14]  [ 40/227]  eta: 0:01:58  lr: 0.000326  min_lr: 0.000326  loss: 0.4074 (0.4787)  class_acc: 1.0000 (0.9390)  weight_decay: 0.0500 (0.0500)  time: 0.1323  data: 0.0000  max mem: 2500\n",
      "Epoch: [14]  [ 50/227]  eta: 0:01:34  lr: 0.000326  min_lr: 0.000326  loss: 0.3795 (0.4640)  class_acc: 1.0000 (0.9490)  weight_decay: 0.0500 (0.0500)  time: 0.1324  data: 0.0000  max mem: 2500\n",
      "Epoch: [14]  [ 60/227]  eta: 0:01:18  lr: 0.000325  min_lr: 0.000325  loss: 0.3942 (0.4745)  class_acc: 1.0000 (0.9410)  weight_decay: 0.0500 (0.0500)  time: 0.1341  data: 0.0000  max mem: 2500\n",
      "Epoch: [14]  [ 70/227]  eta: 0:01:06  lr: 0.000325  min_lr: 0.000325  loss: 0.4745 (0.4809)  class_acc: 0.9000 (0.9380)  weight_decay: 0.0500 (0.0500)  time: 0.1350  data: 0.0001  max mem: 2500\n",
      "Epoch: [14]  [ 80/227]  eta: 0:00:56  lr: 0.000324  min_lr: 0.000324  loss: 0.4691 (0.4779)  class_acc: 0.9000 (0.9370)  weight_decay: 0.0500 (0.0500)  time: 0.1336  data: 0.0002  max mem: 2500\n",
      "Epoch: [14]  [ 90/227]  eta: 0:00:49  lr: 0.000324  min_lr: 0.000324  loss: 0.4778 (0.4872)  class_acc: 0.9000 (0.9297)  weight_decay: 0.0500 (0.0500)  time: 0.1351  data: 0.0002  max mem: 2500\n",
      "Epoch: [14]  [100/227]  eta: 0:00:42  lr: 0.000323  min_lr: 0.000323  loss: 0.5070 (0.4912)  class_acc: 0.9000 (0.9287)  weight_decay: 0.0500 (0.0500)  time: 0.1364  data: 0.0002  max mem: 2500\n",
      "Epoch: [14]  [110/227]  eta: 0:00:37  lr: 0.000323  min_lr: 0.000323  loss: 0.4613 (0.4940)  class_acc: 0.9000 (0.9252)  weight_decay: 0.0500 (0.0500)  time: 0.1340  data: 0.0003  max mem: 2500\n",
      "Epoch: [14]  [120/227]  eta: 0:00:32  lr: 0.000322  min_lr: 0.000322  loss: 0.4603 (0.4938)  class_acc: 0.9000 (0.9264)  weight_decay: 0.0500 (0.0500)  time: 0.1340  data: 0.0002  max mem: 2500\n",
      "Epoch: [14]  [130/227]  eta: 0:00:28  lr: 0.000322  min_lr: 0.000322  loss: 0.4199 (0.4935)  class_acc: 0.9000 (0.9275)  weight_decay: 0.0500 (0.0500)  time: 0.1350  data: 0.0001  max mem: 2500\n",
      "Epoch: [14]  [140/227]  eta: 0:00:24  lr: 0.000322  min_lr: 0.000322  loss: 0.4193 (0.4913)  class_acc: 0.9000 (0.9284)  weight_decay: 0.0500 (0.0500)  time: 0.1337  data: 0.0004  max mem: 2500\n",
      "Epoch: [14]  [150/227]  eta: 0:00:20  lr: 0.000321  min_lr: 0.000321  loss: 0.4193 (0.4918)  class_acc: 0.9000 (0.9278)  weight_decay: 0.0500 (0.0500)  time: 0.1336  data: 0.0004  max mem: 2500\n",
      "Epoch: [14]  [160/227]  eta: 0:00:17  lr: 0.000321  min_lr: 0.000321  loss: 0.4168 (0.4907)  class_acc: 0.9000 (0.9280)  weight_decay: 0.0500 (0.0500)  time: 0.1338  data: 0.0002  max mem: 2500\n",
      "Epoch: [14]  [170/227]  eta: 0:00:14  lr: 0.000320  min_lr: 0.000320  loss: 0.4388 (0.4904)  class_acc: 1.0000 (0.9292)  weight_decay: 0.0500 (0.0500)  time: 0.1342  data: 0.0001  max mem: 2500\n",
      "Epoch: [14]  [180/227]  eta: 0:00:11  lr: 0.000320  min_lr: 0.000320  loss: 0.4193 (0.4882)  class_acc: 1.0000 (0.9304)  weight_decay: 0.0500 (0.0500)  time: 0.1342  data: 0.0000  max mem: 2500\n",
      "Epoch: [14]  [190/227]  eta: 0:00:08  lr: 0.000319  min_lr: 0.000319  loss: 0.4313 (0.4897)  class_acc: 1.0000 (0.9304)  weight_decay: 0.0500 (0.0500)  time: 0.1346  data: 0.0001  max mem: 2500\n",
      "Epoch: [14]  [200/227]  eta: 0:00:06  lr: 0.000319  min_lr: 0.000319  loss: 0.4504 (0.4896)  class_acc: 0.9000 (0.9299)  weight_decay: 0.0500 (0.0500)  time: 0.1342  data: 0.0003  max mem: 2500\n",
      "Epoch: [14]  [210/227]  eta: 0:00:03  lr: 0.000319  min_lr: 0.000319  loss: 0.4504 (0.4896)  class_acc: 0.9000 (0.9299)  weight_decay: 0.0500 (0.0500)  time: 0.1340  data: 0.0003  max mem: 2500\n",
      "Epoch: [14]  [220/227]  eta: 0:00:01  lr: 0.000318  min_lr: 0.000318  loss: 0.4187 (0.4873)  class_acc: 0.9000 (0.9312)  weight_decay: 0.0500 (0.0500)  time: 0.1369  data: 0.0001  max mem: 2500\n",
      "Epoch: [14]  [226/227]  eta: 0:00:00  lr: 0.000318  min_lr: 0.000318  loss: 0.4187 (0.4887)  class_acc: 1.0000 (0.9300)  weight_decay: 0.0500 (0.0500)  time: 0.1363  data: 0.0001  max mem: 2500\n",
      "Epoch: [14] Total time: 0:00:51 (0.2268 s / it)\n",
      "Averaged stats: lr: 0.000318  min_lr: 0.000318  loss: 0.4187 (0.4887)  class_acc: 1.0000 (0.9300)  weight_decay: 0.0500 (0.0500)\n",
      "Test:  [ 0/38]  eta: 0:13:02  loss: 0.1034 (0.1034)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 20.5854  data: 20.5294  max mem: 2500\n",
      "Test:  [10/38]  eta: 0:00:53  loss: 0.1416 (0.1357)  acc1: 100.0000 (98.1818)  acc5: 100.0000 (100.0000)  time: 1.9139  data: 1.8665  max mem: 2500\n",
      "Test:  [20/38]  eta: 0:00:18  loss: 0.1716 (0.3373)  acc1: 93.3333 (87.6191)  acc5: 100.0000 (100.0000)  time: 0.0467  data: 0.0002  max mem: 2500\n",
      "Test:  [30/38]  eta: 0:00:05  loss: 0.0903 (0.2549)  acc1: 100.0000 (91.6129)  acc5: 100.0000 (100.0000)  time: 0.0467  data: 0.0001  max mem: 2500\n",
      "Test:  [37/38]  eta: 0:00:00  loss: 0.0807 (0.2239)  acc1: 100.0000 (93.0357)  acc5: 100.0000 (100.0000)  time: 0.0451  data: 0.0001  max mem: 2500"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\qiezh\\anaconda3\\envs\\convnext\\lib\\site-packages\\torchvision\\transforms\\functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  warnings.warn(\n",
      "C:\\Users\\qiezh\\anaconda3\\envs\\convnext\\lib\\site-packages\\torchvision\\transforms\\functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  warnings.warn(\n",
      "C:\\Users\\qiezh\\anaconda3\\envs\\convnext\\lib\\site-packages\\torchvision\\transforms\\functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  warnings.warn(\n",
      "C:\\Users\\qiezh\\anaconda3\\envs\\convnext\\lib\\site-packages\\torchvision\\transforms\\functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  warnings.warn(\n",
      "C:\\Users\\qiezh\\anaconda3\\envs\\convnext\\lib\\site-packages\\torchvision\\transforms\\functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  warnings.warn(\n",
      "C:\\Users\\qiezh\\anaconda3\\envs\\convnext\\lib\\site-packages\\torchvision\\transforms\\functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  warnings.warn(\n",
      "C:\\Users\\qiezh\\anaconda3\\envs\\convnext\\lib\\site-packages\\torchvision\\transforms\\functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  warnings.warn(\n",
      "C:\\Users\\qiezh\\anaconda3\\envs\\convnext\\lib\\site-packages\\torchvision\\transforms\\functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  warnings.warn(\n",
      "C:\\Users\\qiezh\\anaconda3\\envs\\convnext\\lib\\site-packages\\torchvision\\transforms\\functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  warnings.warn(\n",
      "C:\\Users\\qiezh\\anaconda3\\envs\\convnext\\lib\\site-packages\\torchvision\\transforms\\functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  warnings.warn(\n",
      "C:\\Users\\qiezh\\anaconda3\\envs\\convnext\\lib\\site-packages\\torchvision\\transforms\\functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  warnings.warn(\n",
      "C:\\Users\\qiezh\\anaconda3\\envs\\convnext\\lib\\site-packages\\torchvision\\transforms\\functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  warnings.warn(\n",
      "C:\\Users\\qiezh\\anaconda3\\envs\\convnext\\lib\\site-packages\\torchvision\\transforms\\functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  warnings.warn(\n",
      "C:\\Users\\qiezh\\anaconda3\\envs\\convnext\\lib\\site-packages\\torchvision\\transforms\\functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  warnings.warn(\n",
      "C:\\Users\\qiezh\\anaconda3\\envs\\convnext\\lib\\site-packages\\torchvision\\transforms\\functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  warnings.warn(\n",
      "C:\\Users\\qiezh\\anaconda3\\envs\\convnext\\lib\\site-packages\\torchvision\\transforms\\functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  warnings.warn(\n",
      "C:\\Users\\qiezh\\anaconda3\\envs\\convnext\\lib\\site-packages\\torchvision\\transforms\\functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  warnings.warn(\n",
      "C:\\Users\\qiezh\\anaconda3\\envs\\convnext\\lib\\site-packages\\torchvision\\transforms\\functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  warnings.warn(\n",
      "C:\\Users\\qiezh\\anaconda3\\envs\\convnext\\lib\\site-packages\\torchvision\\transforms\\functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  warnings.warn(\n",
      "C:\\Users\\qiezh\\anaconda3\\envs\\convnext\\lib\\site-packages\\torchvision\\transforms\\functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  warnings.warn(\n",
      "C:\\Users\\qiezh\\anaconda3\\envs\\convnext\\lib\\site-packages\\torchvision\\transforms\\functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  warnings.warn(\n",
      "C:\\Users\\qiezh\\anaconda3\\envs\\convnext\\lib\\site-packages\\torchvision\\transforms\\functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  warnings.warn(\n",
      "C:\\Users\\qiezh\\anaconda3\\envs\\convnext\\lib\\site-packages\\torchvision\\transforms\\functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  warnings.warn(\n",
      "C:\\Users\\qiezh\\anaconda3\\envs\\convnext\\lib\\site-packages\\torchvision\\transforms\\functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  warnings.warn(\n",
      "C:\\Users\\qiezh\\anaconda3\\envs\\convnext\\lib\\site-packages\\torchvision\\transforms\\functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  warnings.warn(\n",
      "C:\\Users\\qiezh\\anaconda3\\envs\\convnext\\lib\\site-packages\\torchvision\\transforms\\functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  warnings.warn(\n",
      "C:\\Users\\qiezh\\anaconda3\\envs\\convnext\\lib\\site-packages\\torchvision\\transforms\\functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  warnings.warn(\n",
      "C:\\Users\\qiezh\\anaconda3\\envs\\convnext\\lib\\site-packages\\torchvision\\transforms\\functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  warnings.warn(\n",
      "C:\\Users\\qiezh\\anaconda3\\envs\\convnext\\lib\\site-packages\\torchvision\\transforms\\functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  warnings.warn(\n",
      "C:\\Users\\qiezh\\anaconda3\\envs\\convnext\\lib\\site-packages\\torchvision\\transforms\\functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  warnings.warn(\n",
      "C:\\Users\\qiezh\\anaconda3\\envs\\convnext\\lib\\site-packages\\torchvision\\transforms\\functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  warnings.warn(\n",
      "C:\\Users\\qiezh\\anaconda3\\envs\\convnext\\lib\\site-packages\\torchvision\\transforms\\functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  warnings.warn(\n",
      "C:\\Users\\qiezh\\anaconda3\\envs\\convnext\\lib\\site-packages\\torchvision\\transforms\\functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  warnings.warn(\n",
      "C:\\Users\\qiezh\\anaconda3\\envs\\convnext\\lib\\site-packages\\torchvision\\transforms\\functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  warnings.warn(\n",
      "C:\\Users\\qiezh\\anaconda3\\envs\\convnext\\lib\\site-packages\\torchvision\\transforms\\functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  warnings.warn(\n",
      "C:\\Users\\qiezh\\anaconda3\\envs\\convnext\\lib\\site-packages\\torchvision\\transforms\\functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  warnings.warn(\n",
      "C:\\Users\\qiezh\\anaconda3\\envs\\convnext\\lib\\site-packages\\torchvision\\transforms\\functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  warnings.warn(\n",
      "C:\\Users\\qiezh\\anaconda3\\envs\\convnext\\lib\\site-packages\\torchvision\\transforms\\functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  warnings.warn(\n",
      "C:\\Users\\qiezh\\anaconda3\\envs\\convnext\\lib\\site-packages\\torchvision\\transforms\\functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  warnings.warn(\n",
      "C:\\Users\\qiezh\\anaconda3\\envs\\convnext\\lib\\site-packages\\torchvision\\transforms\\functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  warnings.warn(\n",
      "C:\\Users\\qiezh\\anaconda3\\envs\\convnext\\lib\\site-packages\\torchvision\\transforms\\functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  warnings.warn(\n",
      "C:\\Users\\qiezh\\anaconda3\\envs\\convnext\\lib\\site-packages\\torchvision\\transforms\\functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  warnings.warn(\n",
      "C:\\Users\\qiezh\\anaconda3\\envs\\convnext\\lib\\site-packages\\torchvision\\transforms\\functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  warnings.warn(\n",
      "C:\\Users\\qiezh\\anaconda3\\envs\\convnext\\lib\\site-packages\\torchvision\\transforms\\functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  warnings.warn(\n",
      "C:\\Users\\qiezh\\anaconda3\\envs\\convnext\\lib\\site-packages\\torchvision\\transforms\\functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  warnings.warn(\n",
      "C:\\Users\\qiezh\\anaconda3\\envs\\convnext\\lib\\site-packages\\torchvision\\transforms\\functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  warnings.warn(\n",
      "C:\\Users\\qiezh\\anaconda3\\envs\\convnext\\lib\\site-packages\\torchvision\\transforms\\functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  warnings.warn(\n",
      "C:\\Users\\qiezh\\anaconda3\\envs\\convnext\\lib\\site-packages\\torchvision\\transforms\\functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  warnings.warn(\n",
      "C:\\Users\\qiezh\\anaconda3\\envs\\convnext\\lib\\site-packages\\torchvision\\transforms\\functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  warnings.warn(\n",
      "C:\\Users\\qiezh\\anaconda3\\envs\\convnext\\lib\\site-packages\\torchvision\\transforms\\functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  warnings.warn(\n",
      "C:\\Users\\qiezh\\anaconda3\\envs\\convnext\\lib\\site-packages\\torchvision\\transforms\\functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  warnings.warn(\n",
      "C:\\Users\\qiezh\\anaconda3\\envs\\convnext\\lib\\site-packages\\torchvision\\transforms\\functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  warnings.warn(\n",
      "C:\\Users\\qiezh\\anaconda3\\envs\\convnext\\lib\\site-packages\\torchvision\\transforms\\functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  warnings.warn(\n",
      "C:\\Users\\qiezh\\anaconda3\\envs\\convnext\\lib\\site-packages\\torchvision\\transforms\\functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  warnings.warn(\n",
      "C:\\Users\\qiezh\\anaconda3\\envs\\convnext\\lib\\site-packages\\torchvision\\transforms\\functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  warnings.warn(\n",
      "C:\\Users\\qiezh\\anaconda3\\envs\\convnext\\lib\\site-packages\\torchvision\\transforms\\functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  warnings.warn(\n",
      "C:\\Users\\qiezh\\anaconda3\\envs\\convnext\\lib\\site-packages\\torchvision\\transforms\\functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  warnings.warn(\n",
      "C:\\Users\\qiezh\\anaconda3\\envs\\convnext\\lib\\site-packages\\torchvision\\transforms\\functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  warnings.warn(\n",
      "C:\\Users\\qiezh\\anaconda3\\envs\\convnext\\lib\\site-packages\\torchvision\\transforms\\functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  warnings.warn(\n",
      "C:\\Users\\qiezh\\anaconda3\\envs\\convnext\\lib\\site-packages\\torchvision\\transforms\\functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  warnings.warn(\n",
      "C:\\Users\\qiezh\\anaconda3\\envs\\convnext\\lib\\site-packages\\torchvision\\transforms\\functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  warnings.warn(\n",
      "C:\\Users\\qiezh\\anaconda3\\envs\\convnext\\lib\\site-packages\\torchvision\\transforms\\functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  warnings.warn(\n",
      "C:\\Users\\qiezh\\anaconda3\\envs\\convnext\\lib\\site-packages\\torchvision\\transforms\\functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  warnings.warn(\n",
      "C:\\Users\\qiezh\\anaconda3\\envs\\convnext\\lib\\site-packages\\torchvision\\transforms\\functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  warnings.warn(\n",
      "C:\\Users\\qiezh\\anaconda3\\envs\\convnext\\lib\\site-packages\\torchvision\\transforms\\functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  warnings.warn(\n",
      "C:\\Users\\qiezh\\anaconda3\\envs\\convnext\\lib\\site-packages\\torchvision\\transforms\\functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  warnings.warn(\n",
      "C:\\Users\\qiezh\\anaconda3\\envs\\convnext\\lib\\site-packages\\torchvision\\transforms\\functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  warnings.warn(\n",
      "C:\\Users\\qiezh\\anaconda3\\envs\\convnext\\lib\\site-packages\\torchvision\\transforms\\functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  warnings.warn(\n",
      "C:\\Users\\qiezh\\anaconda3\\envs\\convnext\\lib\\site-packages\\torchvision\\transforms\\functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  warnings.warn(\n",
      "C:\\Users\\qiezh\\anaconda3\\envs\\convnext\\lib\\site-packages\\torchvision\\transforms\\functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  warnings.warn(\n",
      "C:\\Users\\qiezh\\anaconda3\\envs\\convnext\\lib\\site-packages\\torchvision\\transforms\\functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  warnings.warn(\n",
      "C:\\Users\\qiezh\\anaconda3\\envs\\convnext\\lib\\site-packages\\torchvision\\transforms\\functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  warnings.warn(\n",
      "C:\\Users\\qiezh\\anaconda3\\envs\\convnext\\lib\\site-packages\\torchvision\\transforms\\functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  warnings.warn(\n",
      "C:\\Users\\qiezh\\anaconda3\\envs\\convnext\\lib\\site-packages\\torchvision\\transforms\\functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  warnings.warn(\n",
      "C:\\Users\\qiezh\\anaconda3\\envs\\convnext\\lib\\site-packages\\torchvision\\transforms\\functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  warnings.warn(\n",
      "C:\\Users\\qiezh\\anaconda3\\envs\\convnext\\lib\\site-packages\\torchvision\\transforms\\functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  warnings.warn(\n",
      "C:\\Users\\qiezh\\anaconda3\\envs\\convnext\\lib\\site-packages\\torchvision\\transforms\\functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  warnings.warn(\n",
      "C:\\Users\\qiezh\\anaconda3\\envs\\convnext\\lib\\site-packages\\torchvision\\transforms\\functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  warnings.warn(\n",
      "C:\\Users\\qiezh\\anaconda3\\envs\\convnext\\lib\\site-packages\\torchvision\\transforms\\functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  warnings.warn(\n",
      "C:\\Users\\qiezh\\anaconda3\\envs\\convnext\\lib\\site-packages\\torchvision\\transforms\\functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  warnings.warn(\n",
      "C:\\Users\\qiezh\\anaconda3\\envs\\convnext\\lib\\site-packages\\torchvision\\transforms\\functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  warnings.warn(\n",
      "C:\\Users\\qiezh\\anaconda3\\envs\\convnext\\lib\\site-packages\\torchvision\\transforms\\functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  warnings.warn(\n",
      "C:\\Users\\qiezh\\anaconda3\\envs\\convnext\\lib\\site-packages\\torchvision\\transforms\\functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  warnings.warn(\n",
      "C:\\Users\\qiezh\\anaconda3\\envs\\convnext\\lib\\site-packages\\torchvision\\transforms\\functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  warnings.warn(\n",
      "C:\\Users\\qiezh\\anaconda3\\envs\\convnext\\lib\\site-packages\\torchvision\\transforms\\functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  warnings.warn(\n",
      "C:\\Users\\qiezh\\anaconda3\\envs\\convnext\\lib\\site-packages\\torchvision\\transforms\\functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  warnings.warn(\n",
      "C:\\Users\\qiezh\\anaconda3\\envs\\convnext\\lib\\site-packages\\torchvision\\transforms\\functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  warnings.warn(\n",
      "C:\\Users\\qiezh\\anaconda3\\envs\\convnext\\lib\\site-packages\\torchvision\\transforms\\functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  warnings.warn(\n",
      "C:\\Users\\qiezh\\anaconda3\\envs\\convnext\\lib\\site-packages\\torchvision\\transforms\\functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  warnings.warn(\n",
      "C:\\Users\\qiezh\\anaconda3\\envs\\convnext\\lib\\site-packages\\torchvision\\transforms\\functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  warnings.warn(\n",
      "C:\\Users\\qiezh\\anaconda3\\envs\\convnext\\lib\\site-packages\\torchvision\\transforms\\functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  warnings.warn(\n",
      "C:\\Users\\qiezh\\anaconda3\\envs\\convnext\\lib\\site-packages\\torchvision\\transforms\\functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  warnings.warn(\n",
      "C:\\Users\\qiezh\\anaconda3\\envs\\convnext\\lib\\site-packages\\torchvision\\transforms\\functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  warnings.warn(\n",
      "C:\\Users\\qiezh\\anaconda3\\envs\\convnext\\lib\\site-packages\\torchvision\\transforms\\functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  warnings.warn(\n",
      "C:\\Users\\qiezh\\anaconda3\\envs\\convnext\\lib\\site-packages\\torchvision\\transforms\\functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  warnings.warn(\n",
      "C:\\Users\\qiezh\\anaconda3\\envs\\convnext\\lib\\site-packages\\torchvision\\transforms\\functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  warnings.warn(\n",
      "C:\\Users\\qiezh\\anaconda3\\envs\\convnext\\lib\\site-packages\\torchvision\\transforms\\functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  warnings.warn(\n",
      "C:\\Users\\qiezh\\anaconda3\\envs\\convnext\\lib\\site-packages\\torchvision\\transforms\\functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  warnings.warn(\n",
      "C:\\Users\\qiezh\\anaconda3\\envs\\convnext\\lib\\site-packages\\torchvision\\transforms\\functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  warnings.warn(\n",
      "C:\\Users\\qiezh\\anaconda3\\envs\\convnext\\lib\\site-packages\\torchvision\\transforms\\functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  warnings.warn(\n",
      "C:\\Users\\qiezh\\anaconda3\\envs\\convnext\\lib\\site-packages\\torchvision\\transforms\\functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  warnings.warn(\n",
      "C:\\Users\\qiezh\\anaconda3\\envs\\convnext\\lib\\site-packages\\torchvision\\transforms\\functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  warnings.warn(\n",
      "C:\\Users\\qiezh\\anaconda3\\envs\\convnext\\lib\\site-packages\\torchvision\\transforms\\functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  warnings.warn(\n",
      "C:\\Users\\qiezh\\anaconda3\\envs\\convnext\\lib\\site-packages\\torchvision\\transforms\\functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  warnings.warn(\n",
      "C:\\Users\\qiezh\\anaconda3\\envs\\convnext\\lib\\site-packages\\torchvision\\transforms\\functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  warnings.warn(\n",
      "C:\\Users\\qiezh\\anaconda3\\envs\\convnext\\lib\\site-packages\\torchvision\\transforms\\functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  warnings.warn(\n",
      "C:\\Users\\qiezh\\anaconda3\\envs\\convnext\\lib\\site-packages\\torchvision\\transforms\\functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  warnings.warn(\n",
      "C:\\Users\\qiezh\\anaconda3\\envs\\convnext\\lib\\site-packages\\torchvision\\transforms\\functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  warnings.warn(\n",
      "C:\\Users\\qiezh\\anaconda3\\envs\\convnext\\lib\\site-packages\\torchvision\\transforms\\functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  warnings.warn(\n",
      "C:\\Users\\qiezh\\anaconda3\\envs\\convnext\\lib\\site-packages\\torchvision\\transforms\\functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  warnings.warn(\n",
      "C:\\Users\\qiezh\\anaconda3\\envs\\convnext\\lib\\site-packages\\torchvision\\transforms\\functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  warnings.warn(\n",
      "C:\\Users\\qiezh\\anaconda3\\envs\\convnext\\lib\\site-packages\\torchvision\\transforms\\functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  warnings.warn(\n",
      "C:\\Users\\qiezh\\anaconda3\\envs\\convnext\\lib\\site-packages\\torchvision\\transforms\\functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  warnings.warn(\n",
      "C:\\Users\\qiezh\\anaconda3\\envs\\convnext\\lib\\site-packages\\torchvision\\transforms\\functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  warnings.warn(\n",
      "C:\\Users\\qiezh\\anaconda3\\envs\\convnext\\lib\\site-packages\\torchvision\\transforms\\functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  warnings.warn(\n",
      "C:\\Users\\qiezh\\anaconda3\\envs\\convnext\\lib\\site-packages\\torchvision\\transforms\\functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  warnings.warn(\n",
      "C:\\Users\\qiezh\\anaconda3\\envs\\convnext\\lib\\site-packages\\torchvision\\transforms\\functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  warnings.warn(\n",
      "C:\\Users\\qiezh\\anaconda3\\envs\\convnext\\lib\\site-packages\\torchvision\\transforms\\functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  warnings.warn(\n",
      "C:\\Users\\qiezh\\anaconda3\\envs\\convnext\\lib\\site-packages\\torchvision\\transforms\\functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  warnings.warn(\n",
      "C:\\Users\\qiezh\\anaconda3\\envs\\convnext\\lib\\site-packages\\torchvision\\transforms\\functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  warnings.warn(\n",
      "C:\\Users\\qiezh\\anaconda3\\envs\\convnext\\lib\\site-packages\\torchvision\\transforms\\functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  warnings.warn(\n",
      "C:\\Users\\qiezh\\anaconda3\\envs\\convnext\\lib\\site-packages\\torchvision\\transforms\\functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  warnings.warn(\n",
      "C:\\Users\\qiezh\\anaconda3\\envs\\convnext\\lib\\site-packages\\torchvision\\transforms\\functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  warnings.warn(\n",
      "C:\\Users\\qiezh\\anaconda3\\envs\\convnext\\lib\\site-packages\\torchvision\\transforms\\functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  warnings.warn(\n",
      "C:\\Users\\qiezh\\anaconda3\\envs\\convnext\\lib\\site-packages\\torchvision\\transforms\\functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  warnings.warn(\n",
      "C:\\Users\\qiezh\\anaconda3\\envs\\convnext\\lib\\site-packages\\torchvision\\transforms\\functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  warnings.warn(\n",
      "C:\\Users\\qiezh\\anaconda3\\envs\\convnext\\lib\\site-packages\\torchvision\\transforms\\functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  warnings.warn(\n",
      "C:\\Users\\qiezh\\anaconda3\\envs\\convnext\\lib\\site-packages\\torchvision\\transforms\\functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  warnings.warn(\n",
      "C:\\Users\\qiezh\\anaconda3\\envs\\convnext\\lib\\site-packages\\torchvision\\transforms\\functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  warnings.warn(\n",
      "C:\\Users\\qiezh\\anaconda3\\envs\\convnext\\lib\\site-packages\\torchvision\\transforms\\functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  warnings.warn(\n",
      "C:\\Users\\qiezh\\anaconda3\\envs\\convnext\\lib\\site-packages\\torchvision\\transforms\\functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  warnings.warn(\n",
      "C:\\Users\\qiezh\\anaconda3\\envs\\convnext\\lib\\site-packages\\torchvision\\transforms\\functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  warnings.warn(\n",
      "C:\\Users\\qiezh\\anaconda3\\envs\\convnext\\lib\\site-packages\\torchvision\\transforms\\functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  warnings.warn(\n",
      "C:\\Users\\qiezh\\anaconda3\\envs\\convnext\\lib\\site-packages\\torchvision\\transforms\\functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  warnings.warn(\n",
      "C:\\Users\\qiezh\\anaconda3\\envs\\convnext\\lib\\site-packages\\torchvision\\transforms\\functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  warnings.warn(\n",
      "C:\\Users\\qiezh\\anaconda3\\envs\\convnext\\lib\\site-packages\\torchvision\\transforms\\functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  warnings.warn(\n",
      "C:\\Users\\qiezh\\anaconda3\\envs\\convnext\\lib\\site-packages\\torchvision\\transforms\\functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  warnings.warn(\n",
      "C:\\Users\\qiezh\\anaconda3\\envs\\convnext\\lib\\site-packages\\torchvision\\transforms\\functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  warnings.warn(\n",
      "C:\\Users\\qiezh\\anaconda3\\envs\\convnext\\lib\\site-packages\\torchvision\\transforms\\functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  warnings.warn(\n",
      "C:\\Users\\qiezh\\anaconda3\\envs\\convnext\\lib\\site-packages\\torchvision\\transforms\\functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  warnings.warn(\n",
      "C:\\Users\\qiezh\\anaconda3\\envs\\convnext\\lib\\site-packages\\torchvision\\transforms\\functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  warnings.warn(\n",
      "C:\\Users\\qiezh\\anaconda3\\envs\\convnext\\lib\\site-packages\\torchvision\\transforms\\functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  warnings.warn(\n",
      "C:\\Users\\qiezh\\anaconda3\\envs\\convnext\\lib\\site-packages\\torchvision\\transforms\\functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  warnings.warn(\n",
      "C:\\Users\\qiezh\\anaconda3\\envs\\convnext\\lib\\site-packages\\torchvision\\transforms\\functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  warnings.warn(\n",
      "C:\\Users\\qiezh\\anaconda3\\envs\\convnext\\lib\\site-packages\\torchvision\\transforms\\functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  warnings.warn(\n",
      "C:\\Users\\qiezh\\anaconda3\\envs\\convnext\\lib\\site-packages\\torchvision\\transforms\\functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  warnings.warn(\n",
      "C:\\Users\\qiezh\\anaconda3\\envs\\convnext\\lib\\site-packages\\torchvision\\transforms\\functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  warnings.warn(\n",
      "C:\\Users\\qiezh\\anaconda3\\envs\\convnext\\lib\\site-packages\\torchvision\\transforms\\functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  warnings.warn(\n",
      "C:\\Users\\qiezh\\anaconda3\\envs\\convnext\\lib\\site-packages\\torchvision\\transforms\\functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  warnings.warn(\n",
      "C:\\Users\\qiezh\\anaconda3\\envs\\convnext\\lib\\site-packages\\torchvision\\transforms\\functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  warnings.warn(\n",
      "C:\\Users\\qiezh\\anaconda3\\envs\\convnext\\lib\\site-packages\\torchvision\\transforms\\functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  warnings.warn(\n",
      "C:\\Users\\qiezh\\anaconda3\\envs\\convnext\\lib\\site-packages\\torchvision\\transforms\\functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  warnings.warn(\n",
      "C:\\Users\\qiezh\\anaconda3\\envs\\convnext\\lib\\site-packages\\torchvision\\transforms\\functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  warnings.warn(\n",
      "C:\\Users\\qiezh\\anaconda3\\envs\\convnext\\lib\\site-packages\\torchvision\\transforms\\functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  warnings.warn(\n",
      "C:\\Users\\qiezh\\anaconda3\\envs\\convnext\\lib\\site-packages\\torchvision\\transforms\\functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  warnings.warn(\n",
      "C:\\Users\\qiezh\\anaconda3\\envs\\convnext\\lib\\site-packages\\torchvision\\transforms\\functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  warnings.warn(\n",
      "C:\\Users\\qiezh\\anaconda3\\envs\\convnext\\lib\\site-packages\\torchvision\\transforms\\functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  warnings.warn(\n",
      "C:\\Users\\qiezh\\anaconda3\\envs\\convnext\\lib\\site-packages\\torchvision\\transforms\\functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  warnings.warn(\n",
      "C:\\Users\\qiezh\\anaconda3\\envs\\convnext\\lib\\site-packages\\torchvision\\transforms\\functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  warnings.warn(\n",
      "C:\\Users\\qiezh\\anaconda3\\envs\\convnext\\lib\\site-packages\\torchvision\\transforms\\functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  warnings.warn(\n",
      "C:\\Users\\qiezh\\anaconda3\\envs\\convnext\\lib\\site-packages\\torchvision\\transforms\\functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  warnings.warn(\n",
      "C:\\Users\\qiezh\\anaconda3\\envs\\convnext\\lib\\site-packages\\torchvision\\transforms\\functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  warnings.warn(\n",
      "C:\\Users\\qiezh\\anaconda3\\envs\\convnext\\lib\\site-packages\\torchvision\\transforms\\functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  warnings.warn(\n",
      "C:\\Users\\qiezh\\anaconda3\\envs\\convnext\\lib\\site-packages\\torchvision\\transforms\\functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  warnings.warn(\n",
      "C:\\Users\\qiezh\\anaconda3\\envs\\convnext\\lib\\site-packages\\torchvision\\transforms\\functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  warnings.warn(\n",
      "C:\\Users\\qiezh\\anaconda3\\envs\\convnext\\lib\\site-packages\\torchvision\\transforms\\functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  warnings.warn(\n",
      "C:\\Users\\qiezh\\anaconda3\\envs\\convnext\\lib\\site-packages\\torchvision\\transforms\\functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  warnings.warn(\n",
      "C:\\Users\\qiezh\\anaconda3\\envs\\convnext\\lib\\site-packages\\torchvision\\transforms\\functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  warnings.warn(\n",
      "C:\\Users\\qiezh\\anaconda3\\envs\\convnext\\lib\\site-packages\\torchvision\\transforms\\functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  warnings.warn(\n",
      "C:\\Users\\qiezh\\anaconda3\\envs\\convnext\\lib\\site-packages\\torchvision\\transforms\\functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  warnings.warn(\n",
      "C:\\Users\\qiezh\\anaconda3\\envs\\convnext\\lib\\site-packages\\torchvision\\transforms\\functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  warnings.warn(\n",
      "C:\\Users\\qiezh\\anaconda3\\envs\\convnext\\lib\\site-packages\\torchvision\\transforms\\functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  warnings.warn(\n",
      "C:\\Users\\qiezh\\anaconda3\\envs\\convnext\\lib\\site-packages\\torchvision\\transforms\\functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  warnings.warn(\n",
      "C:\\Users\\qiezh\\anaconda3\\envs\\convnext\\lib\\site-packages\\torchvision\\transforms\\functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  warnings.warn(\n",
      "C:\\Users\\qiezh\\anaconda3\\envs\\convnext\\lib\\site-packages\\torchvision\\transforms\\functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  warnings.warn(\n",
      "C:\\Users\\qiezh\\anaconda3\\envs\\convnext\\lib\\site-packages\\torchvision\\transforms\\functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  warnings.warn(\n",
      "C:\\Users\\qiezh\\anaconda3\\envs\\convnext\\lib\\site-packages\\torchvision\\transforms\\functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  warnings.warn(\n",
      "C:\\Users\\qiezh\\anaconda3\\envs\\convnext\\lib\\site-packages\\torchvision\\transforms\\functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  warnings.warn(\n",
      "C:\\Users\\qiezh\\anaconda3\\envs\\convnext\\lib\\site-packages\\torchvision\\transforms\\functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  warnings.warn(\n",
      "C:\\Users\\qiezh\\anaconda3\\envs\\convnext\\lib\\site-packages\\torchvision\\transforms\\functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  warnings.warn(\n",
      "C:\\Users\\qiezh\\anaconda3\\envs\\convnext\\lib\\site-packages\\torchvision\\transforms\\functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  warnings.warn(\n",
      "C:\\Users\\qiezh\\anaconda3\\envs\\convnext\\lib\\site-packages\\torchvision\\transforms\\functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  warnings.warn(\n",
      "C:\\Users\\qiezh\\anaconda3\\envs\\convnext\\lib\\site-packages\\torchvision\\transforms\\functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  warnings.warn(\n",
      "C:\\Users\\qiezh\\anaconda3\\envs\\convnext\\lib\\site-packages\\torchvision\\transforms\\functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  warnings.warn(\n",
      "C:\\Users\\qiezh\\anaconda3\\envs\\convnext\\lib\\site-packages\\torchvision\\transforms\\functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  warnings.warn(\n",
      "C:\\Users\\qiezh\\anaconda3\\envs\\convnext\\lib\\site-packages\\torchvision\\transforms\\functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  warnings.warn(\n",
      "C:\\Users\\qiezh\\anaconda3\\envs\\convnext\\lib\\site-packages\\torchvision\\transforms\\functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  warnings.warn(\n",
      "C:\\Users\\qiezh\\anaconda3\\envs\\convnext\\lib\\site-packages\\torchvision\\transforms\\functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  warnings.warn(\n",
      "C:\\Users\\qiezh\\anaconda3\\envs\\convnext\\lib\\site-packages\\torchvision\\transforms\\functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  warnings.warn(\n",
      "C:\\Users\\qiezh\\anaconda3\\envs\\convnext\\lib\\site-packages\\torchvision\\transforms\\functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  warnings.warn(\n",
      "C:\\Users\\qiezh\\anaconda3\\envs\\convnext\\lib\\site-packages\\torchvision\\transforms\\functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  warnings.warn(\n",
      "C:\\Users\\qiezh\\anaconda3\\envs\\convnext\\lib\\site-packages\\torchvision\\transforms\\functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  warnings.warn(\n",
      "C:\\Users\\qiezh\\anaconda3\\envs\\convnext\\lib\\site-packages\\torchvision\\transforms\\functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  warnings.warn(\n",
      "C:\\Users\\qiezh\\anaconda3\\envs\\convnext\\lib\\site-packages\\torchvision\\transforms\\functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  warnings.warn(\n",
      "C:\\Users\\qiezh\\anaconda3\\envs\\convnext\\lib\\site-packages\\torchvision\\transforms\\functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  warnings.warn(\n",
      "C:\\Users\\qiezh\\anaconda3\\envs\\convnext\\lib\\site-packages\\torchvision\\transforms\\functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  warnings.warn(\n",
      "C:\\Users\\qiezh\\anaconda3\\envs\\convnext\\lib\\site-packages\\torchvision\\transforms\\functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  warnings.warn(\n",
      "C:\\Users\\qiezh\\anaconda3\\envs\\convnext\\lib\\site-packages\\torchvision\\transforms\\functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  warnings.warn(\n",
      "C:\\Users\\qiezh\\anaconda3\\envs\\convnext\\lib\\site-packages\\torchvision\\transforms\\functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  warnings.warn(\n",
      "C:\\Users\\qiezh\\anaconda3\\envs\\convnext\\lib\\site-packages\\torchvision\\transforms\\functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  warnings.warn(\n",
      "C:\\Users\\qiezh\\anaconda3\\envs\\convnext\\lib\\site-packages\\torchvision\\transforms\\functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  warnings.warn(\n",
      "C:\\Users\\qiezh\\anaconda3\\envs\\convnext\\lib\\site-packages\\torchvision\\transforms\\functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  warnings.warn(\n",
      "C:\\Users\\qiezh\\anaconda3\\envs\\convnext\\lib\\site-packages\\torchvision\\transforms\\functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  warnings.warn(\n",
      "C:\\Users\\qiezh\\anaconda3\\envs\\convnext\\lib\\site-packages\\torchvision\\transforms\\functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  warnings.warn(\n",
      "C:\\Users\\qiezh\\anaconda3\\envs\\convnext\\lib\\site-packages\\torchvision\\transforms\\functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  warnings.warn(\n",
      "C:\\Users\\qiezh\\anaconda3\\envs\\convnext\\lib\\site-packages\\torchvision\\transforms\\functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  warnings.warn(\n",
      "C:\\Users\\qiezh\\anaconda3\\envs\\convnext\\lib\\site-packages\\torchvision\\transforms\\functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  warnings.warn(\n",
      "C:\\Users\\qiezh\\anaconda3\\envs\\convnext\\lib\\site-packages\\torchvision\\transforms\\functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  warnings.warn(\n",
      "C:\\Users\\qiezh\\anaconda3\\envs\\convnext\\lib\\site-packages\\torchvision\\transforms\\functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  warnings.warn(\n",
      "C:\\Users\\qiezh\\anaconda3\\envs\\convnext\\lib\\site-packages\\torchvision\\transforms\\functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  warnings.warn(\n",
      "C:\\Users\\qiezh\\anaconda3\\envs\\convnext\\lib\\site-packages\\torchvision\\transforms\\functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  warnings.warn(\n",
      "C:\\Users\\qiezh\\anaconda3\\envs\\convnext\\lib\\site-packages\\torchvision\\transforms\\functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  warnings.warn(\n",
      "C:\\Users\\qiezh\\anaconda3\\envs\\convnext\\lib\\site-packages\\torchvision\\transforms\\functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  warnings.warn(\n",
      "C:\\Users\\qiezh\\anaconda3\\envs\\convnext\\lib\\site-packages\\torchvision\\transforms\\functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  warnings.warn(\n",
      "C:\\Users\\qiezh\\anaconda3\\envs\\convnext\\lib\\site-packages\\torchvision\\transforms\\functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  warnings.warn(\n",
      "C:\\Users\\qiezh\\anaconda3\\envs\\convnext\\lib\\site-packages\\torchvision\\transforms\\functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  warnings.warn(\n",
      "C:\\Users\\qiezh\\anaconda3\\envs\\convnext\\lib\\site-packages\\torchvision\\transforms\\functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  warnings.warn(\n",
      "C:\\Users\\qiezh\\anaconda3\\envs\\convnext\\lib\\site-packages\\torchvision\\transforms\\functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  warnings.warn(\n",
      "C:\\Users\\qiezh\\anaconda3\\envs\\convnext\\lib\\site-packages\\torchvision\\transforms\\functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  warnings.warn(\n",
      "C:\\Users\\qiezh\\anaconda3\\envs\\convnext\\lib\\site-packages\\torchvision\\transforms\\functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  warnings.warn(\n",
      "C:\\Users\\qiezh\\anaconda3\\envs\\convnext\\lib\\site-packages\\torchvision\\transforms\\functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  warnings.warn(\n",
      "C:\\Users\\qiezh\\anaconda3\\envs\\convnext\\lib\\site-packages\\torchvision\\transforms\\functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  warnings.warn(\n",
      "C:\\Users\\qiezh\\anaconda3\\envs\\convnext\\lib\\site-packages\\torchvision\\transforms\\functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  warnings.warn(\n",
      "C:\\Users\\qiezh\\anaconda3\\envs\\convnext\\lib\\site-packages\\torchvision\\transforms\\functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  warnings.warn(\n",
      "C:\\Users\\qiezh\\anaconda3\\envs\\convnext\\lib\\site-packages\\torchvision\\transforms\\functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  warnings.warn(\n",
      "C:\\Users\\qiezh\\anaconda3\\envs\\convnext\\lib\\site-packages\\torchvision\\transforms\\functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  warnings.warn(\n",
      "C:\\Users\\qiezh\\anaconda3\\envs\\convnext\\lib\\site-packages\\torchvision\\transforms\\functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  warnings.warn(\n",
      "C:\\Users\\qiezh\\anaconda3\\envs\\convnext\\lib\\site-packages\\torchvision\\transforms\\functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  warnings.warn(\n",
      "C:\\Users\\qiezh\\anaconda3\\envs\\convnext\\lib\\site-packages\\torchvision\\transforms\\functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  warnings.warn(\n",
      "C:\\Users\\qiezh\\anaconda3\\envs\\convnext\\lib\\site-packages\\torchvision\\transforms\\functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  warnings.warn(\n",
      "C:\\Users\\qiezh\\anaconda3\\envs\\convnext\\lib\\site-packages\\torchvision\\transforms\\functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  warnings.warn(\n",
      "C:\\Users\\qiezh\\anaconda3\\envs\\convnext\\lib\\site-packages\\torchvision\\transforms\\functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  warnings.warn(\n",
      "C:\\Users\\qiezh\\anaconda3\\envs\\convnext\\lib\\site-packages\\torchvision\\transforms\\functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  warnings.warn(\n",
      "C:\\Users\\qiezh\\anaconda3\\envs\\convnext\\lib\\site-packages\\torchvision\\transforms\\functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  warnings.warn(\n",
      "C:\\Users\\qiezh\\anaconda3\\envs\\convnext\\lib\\site-packages\\torchvision\\transforms\\functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  warnings.warn(\n",
      "C:\\Users\\qiezh\\anaconda3\\envs\\convnext\\lib\\site-packages\\torchvision\\transforms\\functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  warnings.warn(\n",
      "C:\\Users\\qiezh\\anaconda3\\envs\\convnext\\lib\\site-packages\\torchvision\\transforms\\functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  warnings.warn(\n",
      "C:\\Users\\qiezh\\anaconda3\\envs\\convnext\\lib\\site-packages\\torchvision\\transforms\\functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  warnings.warn(\n",
      "C:\\Users\\qiezh\\anaconda3\\envs\\convnext\\lib\\site-packages\\torchvision\\transforms\\functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  warnings.warn(\n",
      "C:\\Users\\qiezh\\anaconda3\\envs\\convnext\\lib\\site-packages\\torchvision\\transforms\\functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  warnings.warn(\n",
      "C:\\Users\\qiezh\\anaconda3\\envs\\convnext\\lib\\site-packages\\torchvision\\transforms\\functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  warnings.warn(\n",
      "C:\\Users\\qiezh\\anaconda3\\envs\\convnext\\lib\\site-packages\\torchvision\\transforms\\functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  warnings.warn(\n",
      "C:\\Users\\qiezh\\anaconda3\\envs\\convnext\\lib\\site-packages\\torchvision\\transforms\\functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  warnings.warn(\n",
      "C:\\Users\\qiezh\\anaconda3\\envs\\convnext\\lib\\site-packages\\torchvision\\transforms\\functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  warnings.warn(\n",
      "C:\\Users\\qiezh\\anaconda3\\envs\\convnext\\lib\\site-packages\\torchvision\\transforms\\functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  warnings.warn(\n",
      "C:\\Users\\qiezh\\anaconda3\\envs\\convnext\\lib\\site-packages\\torchvision\\transforms\\functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  warnings.warn(\n",
      "C:\\Users\\qiezh\\anaconda3\\envs\\convnext\\lib\\site-packages\\torchvision\\transforms\\functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  warnings.warn(\n",
      "C:\\Users\\qiezh\\anaconda3\\envs\\convnext\\lib\\site-packages\\torchvision\\transforms\\functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  warnings.warn(\n",
      "C:\\Users\\qiezh\\anaconda3\\envs\\convnext\\lib\\site-packages\\torchvision\\transforms\\functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  warnings.warn(\n",
      "C:\\Users\\qiezh\\anaconda3\\envs\\convnext\\lib\\site-packages\\torchvision\\transforms\\functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  warnings.warn(\n",
      "C:\\Users\\qiezh\\anaconda3\\envs\\convnext\\lib\\site-packages\\torchvision\\transforms\\functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  warnings.warn(\n",
      "C:\\Users\\qiezh\\anaconda3\\envs\\convnext\\lib\\site-packages\\torchvision\\transforms\\functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  warnings.warn(\n",
      "C:\\Users\\qiezh\\anaconda3\\envs\\convnext\\lib\\site-packages\\torchvision\\transforms\\functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  warnings.warn(\n",
      "C:\\Users\\qiezh\\anaconda3\\envs\\convnext\\lib\\site-packages\\torchvision\\transforms\\functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  warnings.warn(\n",
      "C:\\Users\\qiezh\\anaconda3\\envs\\convnext\\lib\\site-packages\\torchvision\\transforms\\functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  warnings.warn(\n",
      "C:\\Users\\qiezh\\anaconda3\\envs\\convnext\\lib\\site-packages\\torchvision\\transforms\\functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  warnings.warn(\n",
      "C:\\Users\\qiezh\\anaconda3\\envs\\convnext\\lib\\site-packages\\torchvision\\transforms\\functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  warnings.warn(\n",
      "C:\\Users\\qiezh\\anaconda3\\envs\\convnext\\lib\\site-packages\\torchvision\\transforms\\functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  warnings.warn(\n",
      "C:\\Users\\qiezh\\anaconda3\\envs\\convnext\\lib\\site-packages\\torchvision\\transforms\\functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  warnings.warn(\n",
      "C:\\Users\\qiezh\\anaconda3\\envs\\convnext\\lib\\site-packages\\torchvision\\transforms\\functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  warnings.warn(\n",
      "C:\\Users\\qiezh\\anaconda3\\envs\\convnext\\lib\\site-packages\\torchvision\\transforms\\functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  warnings.warn(\n",
      "C:\\Users\\qiezh\\anaconda3\\envs\\convnext\\lib\\site-packages\\torchvision\\transforms\\functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  warnings.warn(\n",
      "C:\\Users\\qiezh\\anaconda3\\envs\\convnext\\lib\\site-packages\\torchvision\\transforms\\functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  warnings.warn(\n",
      "C:\\Users\\qiezh\\anaconda3\\envs\\convnext\\lib\\site-packages\\torchvision\\transforms\\functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  warnings.warn(\n",
      "C:\\Users\\qiezh\\anaconda3\\envs\\convnext\\lib\\site-packages\\torchvision\\transforms\\functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  warnings.warn(\n",
      "C:\\Users\\qiezh\\anaconda3\\envs\\convnext\\lib\\site-packages\\torchvision\\transforms\\functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  warnings.warn(\n",
      "C:\\Users\\qiezh\\anaconda3\\envs\\convnext\\lib\\site-packages\\torchvision\\transforms\\functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  warnings.warn(\n",
      "C:\\Users\\qiezh\\anaconda3\\envs\\convnext\\lib\\site-packages\\torchvision\\transforms\\functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  warnings.warn(\n",
      "C:\\Users\\qiezh\\anaconda3\\envs\\convnext\\lib\\site-packages\\torchvision\\transforms\\functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  warnings.warn(\n",
      "C:\\Users\\qiezh\\anaconda3\\envs\\convnext\\lib\\site-packages\\torchvision\\transforms\\functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  warnings.warn(\n",
      "C:\\Users\\qiezh\\anaconda3\\envs\\convnext\\lib\\site-packages\\torchvision\\transforms\\functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  warnings.warn(\n",
      "C:\\Users\\qiezh\\anaconda3\\envs\\convnext\\lib\\site-packages\\torchvision\\transforms\\functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  warnings.warn(\n",
      "C:\\Users\\qiezh\\anaconda3\\envs\\convnext\\lib\\site-packages\\torchvision\\transforms\\functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  warnings.warn(\n",
      "C:\\Users\\qiezh\\anaconda3\\envs\\convnext\\lib\\site-packages\\torchvision\\transforms\\functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  warnings.warn(\n",
      "C:\\Users\\qiezh\\anaconda3\\envs\\convnext\\lib\\site-packages\\torchvision\\transforms\\functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  warnings.warn(\n",
      "C:\\Users\\qiezh\\anaconda3\\envs\\convnext\\lib\\site-packages\\torchvision\\transforms\\functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  warnings.warn(\n",
      "wandb: Adding directory to artifact (C:\\Users\\qiezh\\Desktop\\FYP\\FYPConvNext\\ConvNextResults\\Results50epoch)... Done. 1.1s\n",
      "wandb: Waiting for W&B process to finish... (success).\n",
      "wandb: - 1274.365 MB of 1274.365 MB uploaded (0.000 MB deduped)\n",
      "wandb: \\ 1274.365 MB of 1274.365 MB uploaded (0.000 MB deduped)\n",
      "wandb: | 1274.365 MB of 1274.667 MB uploaded (0.000 MB deduped)\n",
      "wandb: / 1274.365 MB of 1274.667 MB uploaded (0.000 MB deduped)\n",
      "wandb: - 1274.365 MB of 1274.667 MB uploaded (0.000 MB deduped)\n",
      "wandb: \\ 1274.455 MB of 1274.667 MB uploaded (0.000 MB deduped)\n",
      "wandb: | 1274.667 MB of 1274.667 MB uploaded (0.000 MB deduped)\n",
      "wandb: / 1274.667 MB of 1274.667 MB uploaded (0.000 MB deduped)\n",
      "wandb: - 1274.667 MB of 1274.667 MB uploaded (0.000 MB deduped)\n",
      "wandb: \\ 1274.667 MB of 1274.667 MB uploaded (0.000 MB deduped)\n",
      "wandb: | 1274.667 MB of 1274.667 MB uploaded (0.000 MB deduped)\n",
      "wandb: / 1274.667 MB of 1274.667 MB uploaded (0.000 MB deduped)\n",
      "wandb: - 1274.667 MB of 1274.667 MB uploaded (0.000 MB deduped)\n",
      "wandb: \\ 1274.667 MB of 1274.667 MB uploaded (0.000 MB deduped)\n",
      "wandb: | 1274.667 MB of 1274.667 MB uploaded (0.000 MB deduped)\n",
      "wandb: / 1274.667 MB of 1274.667 MB uploaded (0.000 MB deduped)\n",
      "wandb:                                                                                \n",
      "wandb: \n",
      "wandb: Run summary:\n",
      "wandb:               Global Test/test_acc1 96.60715\n",
      "wandb:               Global Test/test_acc5 100.00001\n",
      "wandb:               Global Test/test_loss 0.16033\n",
      "wandb:        Global Train/train_class_acc 0.98238\n",
      "wandb:             Global Train/train_loss 0.3862\n",
      "wandb:               Global Train/train_lr 0.0\n",
      "wandb:           Global Train/train_min_lr 0.0\n",
      "wandb:     Global Train/train_weight_decay 0.05\n",
      "wandb: Rank-0 Batch Wise/global_train_step 11349\n",
      "wandb:   Rank-0 Batch Wise/train_class_acc 1.0\n",
      "wandb:        Rank-0 Batch Wise/train_loss 0.36798\n",
      "wandb:      Rank-0 Batch Wise/train_max_lr 0.0\n",
      "wandb:      Rank-0 Batch Wise/train_min_lr 0.0\n",
      "wandb:                               epoch 49\n",
      "wandb:                        n_parameters 27823204\n",
      "wandb: \n",
      "wandb: Synced genial-cosmos-9: https://wandb.ai/qpua0001/convnext/runs/tzjm3gaq\n",
      "wandb: Synced 6 W&B file(s), 0 media file(s), 5 artifact file(s) and 0 other file(s)\n",
      "wandb: Find logs at: .\\wandb\\run-20220521_222210-tzjm3gaq\\logs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test: Total time: 0:00:22 (0.5996 s / it)\n",
      "* Acc@1 93.036 Acc@5 100.000 loss 0.224\n",
      "[[138   0   0   2]\n",
      " [ 24 105   0  11]\n",
      " [  1   0 138   1]\n",
      " [  0   0   0 140]]\n",
      "(4, 4)\n",
      "Accuracy of the model on the 560 test images: 93.0%\n",
      "Max accuracy: 93.93%\n",
      "Epoch: [15]  [  0/227]  eta: 1:18:27  lr: 0.000318  min_lr: 0.000318  loss: 0.4174 (0.4174)  class_acc: 1.0000 (1.0000)  weight_decay: 0.0500 (0.0500)  time: 20.7401  data: 20.6000  max mem: 2500\n",
      "Epoch: [15]  [ 10/227]  eta: 0:07:15  lr: 0.000317  min_lr: 0.000317  loss: 0.4174 (0.4335)  class_acc: 1.0000 (0.9636)  weight_decay: 0.0500 (0.0500)  time: 2.0079  data: 1.8728  max mem: 2500\n",
      "Epoch: [15]  [ 20/227]  eta: 0:03:50  lr: 0.000317  min_lr: 0.000317  loss: 0.4290 (0.4590)  class_acc: 1.0000 (0.9381)  weight_decay: 0.0500 (0.0500)  time: 0.1344  data: 0.0001  max mem: 2500\n",
      "Epoch: [15]  [ 30/227]  eta: 0:02:37  lr: 0.000316  min_lr: 0.000316  loss: 0.4179 (0.4722)  class_acc: 1.0000 (0.9355)  weight_decay: 0.0500 (0.0500)  time: 0.1338  data: 0.0002  max mem: 2500\n",
      "Epoch: [15]  [ 40/227]  eta: 0:01:59  lr: 0.000316  min_lr: 0.000316  loss: 0.3918 (0.4624)  class_acc: 1.0000 (0.9439)  weight_decay: 0.0500 (0.0500)  time: 0.1353  data: 0.0001  max mem: 2500\n",
      "Epoch: [15]  [ 50/227]  eta: 0:01:35  lr: 0.000316  min_lr: 0.000316  loss: 0.3866 (0.4572)  class_acc: 1.0000 (0.9451)  weight_decay: 0.0500 (0.0500)  time: 0.1358  data: 0.0001  max mem: 2500\n",
      "Epoch: [15]  [ 60/227]  eta: 0:01:18  lr: 0.000315  min_lr: 0.000315  loss: 0.4093 (0.4578)  class_acc: 1.0000 (0.9459)  weight_decay: 0.0500 (0.0500)  time: 0.1334  data: 0.0003  max mem: 2500\n",
      "Epoch: [15]  [ 70/227]  eta: 0:01:06  lr: 0.000315  min_lr: 0.000315  loss: 0.4487 (0.4628)  class_acc: 0.9000 (0.9451)  weight_decay: 0.0500 (0.0500)  time: 0.1333  data: 0.0002  max mem: 2500\n",
      "Epoch: [15]  [ 80/227]  eta: 0:00:57  lr: 0.000314  min_lr: 0.000314  loss: 0.4243 (0.4570)  class_acc: 1.0000 (0.9469)  weight_decay: 0.0500 (0.0500)  time: 0.1350  data: 0.0002  max mem: 2500\n",
      "Epoch: [15]  [ 90/227]  eta: 0:00:49  lr: 0.000314  min_lr: 0.000314  loss: 0.3921 (0.4501)  class_acc: 1.0000 (0.9505)  weight_decay: 0.0500 (0.0500)  time: 0.1340  data: 0.0003  max mem: 2500\n",
      "Epoch: [15]  [100/227]  eta: 0:00:42  lr: 0.000313  min_lr: 0.000313  loss: 0.4065 (0.4577)  class_acc: 1.0000 (0.9465)  weight_decay: 0.0500 (0.0500)  time: 0.1330  data: 0.0002  max mem: 2500\n",
      "Epoch: [15]  [110/227]  eta: 0:00:37  lr: 0.000313  min_lr: 0.000313  loss: 0.4270 (0.4605)  class_acc: 0.9000 (0.9441)  weight_decay: 0.0500 (0.0500)  time: 0.1341  data: 0.0001  max mem: 2500\n",
      "Epoch: [15]  [120/227]  eta: 0:00:32  lr: 0.000312  min_lr: 0.000312  loss: 0.3986 (0.4562)  class_acc: 1.0000 (0.9463)  weight_decay: 0.0500 (0.0500)  time: 0.1341  data: 0.0000  max mem: 2500\n",
      "Epoch: [15]  [130/227]  eta: 0:00:28  lr: 0.000312  min_lr: 0.000312  loss: 0.3995 (0.4597)  class_acc: 1.0000 (0.9458)  weight_decay: 0.0500 (0.0500)  time: 0.1349  data: 0.0002  max mem: 2500\n",
      "Epoch: [15]  [140/227]  eta: 0:00:24  lr: 0.000311  min_lr: 0.000311  loss: 0.3997 (0.4573)  class_acc: 1.0000 (0.9468)  weight_decay: 0.0500 (0.0500)  time: 0.1352  data: 0.0002  max mem: 2500\n",
      "Epoch: [15]  [150/227]  eta: 0:00:20  lr: 0.000311  min_lr: 0.000311  loss: 0.3742 (0.4561)  class_acc: 1.0000 (0.9470)  weight_decay: 0.0500 (0.0500)  time: 0.1339  data: 0.0000  max mem: 2500\n",
      "Epoch: [15]  [160/227]  eta: 0:00:17  lr: 0.000311  min_lr: 0.000311  loss: 0.3698 (0.4537)  class_acc: 1.0000 (0.9484)  weight_decay: 0.0500 (0.0500)  time: 0.1385  data: 0.0001  max mem: 2500\n",
      "Epoch: [15]  [170/227]  eta: 0:00:14  lr: 0.000310  min_lr: 0.000310  loss: 0.4625 (0.4595)  class_acc: 0.9000 (0.9450)  weight_decay: 0.0500 (0.0500)  time: 0.1460  data: 0.0002  max mem: 2500\n",
      "Epoch: [15]  [180/227]  eta: 0:00:11  lr: 0.000310  min_lr: 0.000310  loss: 0.5118 (0.4595)  class_acc: 0.9000 (0.9453)  weight_decay: 0.0500 (0.0500)  time: 0.1476  data: 0.0002  max mem: 2500\n",
      "Epoch: [15]  [190/227]  eta: 0:00:09  lr: 0.000309  min_lr: 0.000309  loss: 0.4249 (0.4581)  class_acc: 1.0000 (0.9461)  weight_decay: 0.0500 (0.0500)  time: 0.1465  data: 0.0002  max mem: 2500\n",
      "Epoch: [15]  [200/227]  eta: 0:00:06  lr: 0.000309  min_lr: 0.000309  loss: 0.3950 (0.4552)  class_acc: 1.0000 (0.9473)  weight_decay: 0.0500 (0.0500)  time: 0.1459  data: 0.0002  max mem: 2500\n",
      "Epoch: [15]  [210/227]  eta: 0:00:04  lr: 0.000308  min_lr: 0.000308  loss: 0.4080 (0.4567)  class_acc: 1.0000 (0.9469)  weight_decay: 0.0500 (0.0500)  time: 0.1457  data: 0.0000  max mem: 2500\n",
      "Epoch: [15]  [220/227]  eta: 0:00:01  lr: 0.000308  min_lr: 0.000308  loss: 0.4135 (0.4558)  class_acc: 0.9000 (0.9471)  weight_decay: 0.0500 (0.0500)  time: 0.1452  data: 0.0001  max mem: 2500\n",
      "Epoch: [15]  [226/227]  eta: 0:00:00  lr: 0.000307  min_lr: 0.000307  loss: 0.4135 (0.4556)  class_acc: 0.9000 (0.9467)  weight_decay: 0.0500 (0.0500)  time: 0.1450  data: 0.0001  max mem: 2500\n",
      "Epoch: [15] Total time: 0:00:52 (0.2313 s / it)\n",
      "Averaged stats: lr: 0.000307  min_lr: 0.000307  loss: 0.4135 (0.4556)  class_acc: 0.9000 (0.9467)  weight_decay: 0.0500 (0.0500)\n",
      "Test:  [ 0/38]  eta: 0:13:07  loss: 0.1166 (0.1166)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 20.7109  data: 20.6539  max mem: 2500\n",
      "Test:  [10/38]  eta: 0:00:53  loss: 0.1735 (0.1902)  acc1: 93.3333 (95.1515)  acc5: 100.0000 (100.0000)  time: 1.9253  data: 1.8777  max mem: 2500\n",
      "Test:  [20/38]  eta: 0:00:18  loss: 0.2125 (0.4163)  acc1: 93.3333 (85.7143)  acc5: 100.0000 (100.0000)  time: 0.0466  data: 0.0001  max mem: 2500\n",
      "Test:  [30/38]  eta: 0:00:05  loss: 0.1036 (0.3078)  acc1: 100.0000 (90.3226)  acc5: 100.0000 (100.0000)  time: 0.0465  data: 0.0001  max mem: 2500\n",
      "Test:  [37/38]  eta: 0:00:00  loss: 0.0735 (0.2652)  acc1: 100.0000 (91.9643)  acc5: 100.0000 (100.0000)  time: 0.0451  data: 0.0001  max mem: 2500\n",
      "Test: Total time: 0:00:22 (0.6029 s / it)\n",
      "* Acc@1 91.964 Acc@5 100.000 loss 0.265\n",
      "[[133   0   1   6]\n",
      " [ 28 103   0   9]\n",
      " [  0   1 139   0]\n",
      " [  0   0   0 140]]\n",
      "(4, 4)\n",
      "Accuracy of the model on the 560 test images: 92.0%\n",
      "Max accuracy: 93.93%\n",
      "Epoch: [16]  [  0/227]  eta: 1:18:48  lr: 0.000307  min_lr: 0.000307  loss: 0.4901 (0.4901)  class_acc: 0.9000 (0.9000)  weight_decay: 0.0500 (0.0500)  time: 20.8296  data: 20.6815  max mem: 2500\n",
      "Epoch: [16]  [ 10/227]  eta: 0:07:17  lr: 0.000307  min_lr: 0.000307  loss: 0.4334 (0.4435)  class_acc: 0.9000 (0.9364)  weight_decay: 0.0500 (0.0500)  time: 2.0154  data: 1.8801  max mem: 2500\n",
      "Epoch: [16]  [ 20/227]  eta: 0:03:51  lr: 0.000306  min_lr: 0.000306  loss: 0.4456 (0.4843)  class_acc: 0.9000 (0.9095)  weight_decay: 0.0500 (0.0500)  time: 0.1341  data: 0.0001  max mem: 2500\n",
      "Epoch: [16]  [ 30/227]  eta: 0:02:38  lr: 0.000306  min_lr: 0.000306  loss: 0.5057 (0.5000)  class_acc: 0.9000 (0.9032)  weight_decay: 0.0500 (0.0500)  time: 0.1348  data: 0.0001  max mem: 2500\n",
      "Epoch: [16]  [ 40/227]  eta: 0:01:59  lr: 0.000306  min_lr: 0.000306  loss: 0.4679 (0.4848)  class_acc: 0.9000 (0.9171)  weight_decay: 0.0500 (0.0500)  time: 0.1338  data: 0.0002  max mem: 2500\n",
      "Epoch: [16]  [ 50/227]  eta: 0:01:35  lr: 0.000305  min_lr: 0.000305  loss: 0.4110 (0.4768)  class_acc: 1.0000 (0.9235)  weight_decay: 0.0500 (0.0500)  time: 0.1340  data: 0.0002  max mem: 2500\n",
      "Epoch: [16]  [ 60/227]  eta: 0:01:19  lr: 0.000305  min_lr: 0.000305  loss: 0.4030 (0.4797)  class_acc: 1.0000 (0.9262)  weight_decay: 0.0500 (0.0500)  time: 0.1350  data: 0.0003  max mem: 2500\n",
      "Epoch: [16]  [ 70/227]  eta: 0:01:06  lr: 0.000304  min_lr: 0.000304  loss: 0.4117 (0.4750)  class_acc: 1.0000 (0.9296)  weight_decay: 0.0500 (0.0500)  time: 0.1340  data: 0.0003  max mem: 2500\n",
      "Epoch: [16]  [ 80/227]  eta: 0:00:57  lr: 0.000304  min_lr: 0.000304  loss: 0.4530 (0.4772)  class_acc: 0.9000 (0.9272)  weight_decay: 0.0500 (0.0500)  time: 0.1338  data: 0.0001  max mem: 2500\n",
      "Epoch: [16]  [ 90/227]  eta: 0:00:49  lr: 0.000303  min_lr: 0.000303  loss: 0.4840 (0.4838)  class_acc: 0.9000 (0.9242)  weight_decay: 0.0500 (0.0500)  time: 0.1338  data: 0.0001  max mem: 2500\n",
      "Epoch: [16]  [100/227]  eta: 0:00:43  lr: 0.000303  min_lr: 0.000303  loss: 0.4212 (0.4837)  class_acc: 0.9000 (0.9228)  weight_decay: 0.0500 (0.0500)  time: 0.1332  data: 0.0002  max mem: 2500\n",
      "Epoch: [16]  [110/227]  eta: 0:00:37  lr: 0.000302  min_lr: 0.000302  loss: 0.4314 (0.4831)  class_acc: 0.9000 (0.9225)  weight_decay: 0.0500 (0.0500)  time: 0.1325  data: 0.0002  max mem: 2500\n",
      "Epoch: [16]  [120/227]  eta: 0:00:32  lr: 0.000302  min_lr: 0.000302  loss: 0.4278 (0.4808)  class_acc: 0.9000 (0.9248)  weight_decay: 0.0500 (0.0500)  time: 0.1354  data: 0.0002  max mem: 2500\n",
      "Epoch: [16]  [130/227]  eta: 0:00:28  lr: 0.000301  min_lr: 0.000301  loss: 0.4397 (0.4827)  class_acc: 0.9000 (0.9237)  weight_decay: 0.0500 (0.0500)  time: 0.1374  data: 0.0001  max mem: 2500\n",
      "Epoch: [16]  [140/227]  eta: 0:00:24  lr: 0.000301  min_lr: 0.000301  loss: 0.4472 (0.4815)  class_acc: 0.9000 (0.9241)  weight_decay: 0.0500 (0.0500)  time: 0.1349  data: 0.0001  max mem: 2500\n",
      "Epoch: [16]  [150/227]  eta: 0:00:20  lr: 0.000300  min_lr: 0.000300  loss: 0.4999 (0.4882)  class_acc: 0.9000 (0.9205)  weight_decay: 0.0500 (0.0500)  time: 0.1335  data: 0.0001  max mem: 2500\n",
      "Epoch: [16]  [160/227]  eta: 0:00:17  lr: 0.000300  min_lr: 0.000300  loss: 0.4352 (0.4851)  class_acc: 0.9000 (0.9224)  weight_decay: 0.0500 (0.0500)  time: 0.1336  data: 0.0001  max mem: 2500\n",
      "Epoch: [16]  [170/227]  eta: 0:00:14  lr: 0.000299  min_lr: 0.000299  loss: 0.4308 (0.4869)  class_acc: 0.9000 (0.9216)  weight_decay: 0.0500 (0.0500)  time: 0.1331  data: 0.0001  max mem: 2500\n",
      "Epoch: [16]  [180/227]  eta: 0:00:11  lr: 0.000299  min_lr: 0.000299  loss: 0.4423 (0.4862)  class_acc: 0.9000 (0.9221)  weight_decay: 0.0500 (0.0500)  time: 0.1332  data: 0.0001  max mem: 2500\n",
      "Epoch: [16]  [190/227]  eta: 0:00:08  lr: 0.000298  min_lr: 0.000298  loss: 0.4423 (0.4857)  class_acc: 0.9000 (0.9225)  weight_decay: 0.0500 (0.0500)  time: 0.1355  data: 0.0002  max mem: 2500\n",
      "Epoch: [16]  [200/227]  eta: 0:00:06  lr: 0.000298  min_lr: 0.000298  loss: 0.4385 (0.4851)  class_acc: 0.9000 (0.9234)  weight_decay: 0.0500 (0.0500)  time: 0.1353  data: 0.0003  max mem: 2500\n",
      "Epoch: [16]  [210/227]  eta: 0:00:03  lr: 0.000297  min_lr: 0.000297  loss: 0.4344 (0.4847)  class_acc: 0.9000 (0.9237)  weight_decay: 0.0500 (0.0500)  time: 0.1325  data: 0.0002  max mem: 2500\n",
      "Epoch: [16]  [220/227]  eta: 0:00:01  lr: 0.000297  min_lr: 0.000297  loss: 0.3817 (0.4803)  class_acc: 1.0000 (0.9258)  weight_decay: 0.0500 (0.0500)  time: 0.1327  data: 0.0002  max mem: 2500\n",
      "Epoch: [16]  [226/227]  eta: 0:00:00  lr: 0.000297  min_lr: 0.000297  loss: 0.3720 (0.4784)  class_acc: 1.0000 (0.9269)  weight_decay: 0.0500 (0.0500)  time: 0.1328  data: 0.0002  max mem: 2500\n",
      "Epoch: [16] Total time: 0:00:51 (0.2275 s / it)\n",
      "Averaged stats: lr: 0.000297  min_lr: 0.000297  loss: 0.3720 (0.4784)  class_acc: 1.0000 (0.9269)  weight_decay: 0.0500 (0.0500)\n",
      "Test:  [ 0/38]  eta: 0:13:03  loss: 0.1041 (0.1041)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 20.6140  data: 20.5560  max mem: 2500\n",
      "Test:  [10/38]  eta: 0:00:53  loss: 0.1242 (0.1678)  acc1: 100.0000 (95.7576)  acc5: 100.0000 (100.0000)  time: 1.9165  data: 1.8690  max mem: 2500\n",
      "Test:  [20/38]  eta: 0:00:18  loss: 0.1520 (0.2815)  acc1: 93.3333 (91.7460)  acc5: 100.0000 (100.0000)  time: 0.0467  data: 0.0002  max mem: 2500\n",
      "Test:  [30/38]  eta: 0:00:05  loss: 0.1011 (0.2226)  acc1: 100.0000 (93.9785)  acc5: 100.0000 (100.0000)  time: 0.0465  data: 0.0002  max mem: 2500\n",
      "Test:  [37/38]  eta: 0:00:00  loss: 0.0791 (0.1996)  acc1: 100.0000 (95.0000)  acc5: 100.0000 (100.0000)  time: 0.0449  data: 0.0001  max mem: 2500\n",
      "Test: Total time: 0:00:22 (0.6005 s / it)\n",
      "* Acc@1 95.000 Acc@5 100.000 loss 0.200\n",
      "[[133   6   0   1]\n",
      " [ 17 121   0   2]\n",
      " [  0   0 140   0]\n",
      " [  1   0   1 138]]\n",
      "(4, 4)\n",
      "Accuracy of the model on the 560 test images: 95.0%\n",
      "Max accuracy: 95.00%\n",
      "Epoch: [17]  [  0/227]  eta: 1:18:29  lr: 0.000297  min_lr: 0.000297  loss: 0.3808 (0.3808)  class_acc: 1.0000 (1.0000)  weight_decay: 0.0500 (0.0500)  time: 20.7479  data: 20.6038  max mem: 2500\n",
      "Epoch: [17]  [ 10/227]  eta: 0:07:15  lr: 0.000296  min_lr: 0.000296  loss: 0.4151 (0.4453)  class_acc: 1.0000 (0.9545)  weight_decay: 0.0500 (0.0500)  time: 2.0079  data: 1.8732  max mem: 2500\n",
      "Epoch: [17]  [ 20/227]  eta: 0:03:50  lr: 0.000296  min_lr: 0.000296  loss: 0.3930 (0.4475)  class_acc: 1.0000 (0.9571)  weight_decay: 0.0500 (0.0500)  time: 0.1338  data: 0.0001  max mem: 2500\n",
      "Epoch: [17]  [ 30/227]  eta: 0:02:37  lr: 0.000295  min_lr: 0.000295  loss: 0.4592 (0.4625)  class_acc: 0.9000 (0.9419)  weight_decay: 0.0500 (0.0500)  time: 0.1338  data: 0.0002  max mem: 2500\n",
      "Epoch: [17]  [ 40/227]  eta: 0:01:59  lr: 0.000295  min_lr: 0.000295  loss: 0.4592 (0.4631)  class_acc: 0.9000 (0.9415)  weight_decay: 0.0500 (0.0500)  time: 0.1338  data: 0.0003  max mem: 2500\n",
      "Epoch: [17]  [ 50/227]  eta: 0:01:35  lr: 0.000294  min_lr: 0.000294  loss: 0.3730 (0.4538)  class_acc: 1.0000 (0.9451)  weight_decay: 0.0500 (0.0500)  time: 0.1348  data: 0.0003  max mem: 2500\n",
      "Epoch: [17]  [ 60/227]  eta: 0:01:18  lr: 0.000294  min_lr: 0.000294  loss: 0.4207 (0.4678)  class_acc: 0.9000 (0.9361)  weight_decay: 0.0500 (0.0500)  time: 0.1342  data: 0.0001  max mem: 2500\n",
      "Epoch: [17]  [ 70/227]  eta: 0:01:06  lr: 0.000293  min_lr: 0.000293  loss: 0.4492 (0.4711)  class_acc: 0.9000 (0.9338)  weight_decay: 0.0500 (0.0500)  time: 0.1325  data: 0.0001  max mem: 2500\n",
      "Epoch: [17]  [ 80/227]  eta: 0:00:57  lr: 0.000293  min_lr: 0.000293  loss: 0.4168 (0.4642)  class_acc: 1.0000 (0.9395)  weight_decay: 0.0500 (0.0500)  time: 0.1326  data: 0.0002  max mem: 2500\n",
      "Epoch: [17]  [ 90/227]  eta: 0:00:49  lr: 0.000292  min_lr: 0.000292  loss: 0.3968 (0.4619)  class_acc: 1.0000 (0.9396)  weight_decay: 0.0500 (0.0500)  time: 0.1329  data: 0.0003  max mem: 2500\n",
      "Epoch: [17]  [100/227]  eta: 0:00:42  lr: 0.000292  min_lr: 0.000292  loss: 0.4480 (0.4639)  class_acc: 0.9000 (0.9376)  weight_decay: 0.0500 (0.0500)  time: 0.1330  data: 0.0002  max mem: 2500\n",
      "Epoch: [17]  [110/227]  eta: 0:00:37  lr: 0.000291  min_lr: 0.000291  loss: 0.4561 (0.4630)  class_acc: 0.9000 (0.9378)  weight_decay: 0.0500 (0.0500)  time: 0.1329  data: 0.0002  max mem: 2500\n",
      "Epoch: [17]  [120/227]  eta: 0:00:32  lr: 0.000291  min_lr: 0.000291  loss: 0.4188 (0.4607)  class_acc: 0.9000 (0.9388)  weight_decay: 0.0500 (0.0500)  time: 0.1337  data: 0.0001  max mem: 2500\n",
      "Epoch: [17]  [130/227]  eta: 0:00:28  lr: 0.000290  min_lr: 0.000290  loss: 0.4712 (0.4671)  class_acc: 0.9000 (0.9366)  weight_decay: 0.0500 (0.0500)  time: 0.1340  data: 0.0000  max mem: 2500\n",
      "Epoch: [17]  [140/227]  eta: 0:00:24  lr: 0.000290  min_lr: 0.000290  loss: 0.4605 (0.4648)  class_acc: 0.9000 (0.9376)  weight_decay: 0.0500 (0.0500)  time: 0.1332  data: 0.0001  max mem: 2500\n",
      "Epoch: [17]  [150/227]  eta: 0:00:20  lr: 0.000289  min_lr: 0.000289  loss: 0.4463 (0.4700)  class_acc: 0.9000 (0.9358)  weight_decay: 0.0500 (0.0500)  time: 0.1333  data: 0.0002  max mem: 2500\n",
      "Epoch: [17]  [160/227]  eta: 0:00:17  lr: 0.000289  min_lr: 0.000289  loss: 0.4175 (0.4661)  class_acc: 0.9000 (0.9373)  weight_decay: 0.0500 (0.0500)  time: 0.1333  data: 0.0002  max mem: 2500\n",
      "Epoch: [17]  [170/227]  eta: 0:00:14  lr: 0.000288  min_lr: 0.000288  loss: 0.4077 (0.4648)  class_acc: 1.0000 (0.9392)  weight_decay: 0.0500 (0.0500)  time: 0.1334  data: 0.0002  max mem: 2500\n",
      "Epoch: [17]  [180/227]  eta: 0:00:11  lr: 0.000288  min_lr: 0.000288  loss: 0.3961 (0.4616)  class_acc: 1.0000 (0.9409)  weight_decay: 0.0500 (0.0500)  time: 0.1337  data: 0.0003  max mem: 2500\n",
      "Epoch: [17]  [190/227]  eta: 0:00:08  lr: 0.000287  min_lr: 0.000287  loss: 0.4043 (0.4624)  class_acc: 1.0000 (0.9408)  weight_decay: 0.0500 (0.0500)  time: 0.1349  data: 0.0002  max mem: 2500\n",
      "Epoch: [17]  [200/227]  eta: 0:00:06  lr: 0.000287  min_lr: 0.000287  loss: 0.4354 (0.4654)  class_acc: 1.0000 (0.9398)  weight_decay: 0.0500 (0.0500)  time: 0.1362  data: 0.0001  max mem: 2500\n",
      "Epoch: [17]  [210/227]  eta: 0:00:03  lr: 0.000286  min_lr: 0.000286  loss: 0.3961 (0.4645)  class_acc: 1.0000 (0.9408)  weight_decay: 0.0500 (0.0500)  time: 0.1352  data: 0.0003  max mem: 2500\n",
      "Epoch: [17]  [220/227]  eta: 0:00:01  lr: 0.000286  min_lr: 0.000286  loss: 0.3829 (0.4615)  class_acc: 1.0000 (0.9421)  weight_decay: 0.0500 (0.0500)  time: 0.1342  data: 0.0004  max mem: 2500\n",
      "Epoch: [17]  [226/227]  eta: 0:00:00  lr: 0.000285  min_lr: 0.000285  loss: 0.3682 (0.4607)  class_acc: 1.0000 (0.9423)  weight_decay: 0.0500 (0.0500)  time: 0.1337  data: 0.0003  max mem: 2500\n",
      "Epoch: [17] Total time: 0:00:51 (0.2269 s / it)\n",
      "Averaged stats: lr: 0.000285  min_lr: 0.000285  loss: 0.3682 (0.4607)  class_acc: 1.0000 (0.9423)  weight_decay: 0.0500 (0.0500)\n",
      "Test:  [ 0/38]  eta: 0:13:01  loss: 0.1164 (0.1164)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 20.5592  data: 20.5022  max mem: 2500\n",
      "Test:  [10/38]  eta: 0:00:53  loss: 0.2818 (0.2392)  acc1: 93.3333 (94.5455)  acc5: 100.0000 (100.0000)  time: 1.9115  data: 1.8640  max mem: 2500\n",
      "Test:  [20/38]  eta: 0:00:18  loss: 0.3201 (0.4417)  acc1: 86.6667 (85.0794)  acc5: 100.0000 (100.0000)  time: 0.0467  data: 0.0002  max mem: 2500\n",
      "Test:  [30/38]  eta: 0:00:05  loss: 0.0890 (0.3250)  acc1: 100.0000 (89.8925)  acc5: 100.0000 (100.0000)  time: 0.0466  data: 0.0002  max mem: 2500\n",
      "Test:  [37/38]  eta: 0:00:00  loss: 0.0774 (0.2810)  acc1: 100.0000 (91.6071)  acc5: 100.0000 (100.0000)  time: 0.0450  data: 0.0001  max mem: 2500\n",
      "Test: Total time: 0:00:22 (0.5989 s / it)\n",
      "* Acc@1 91.607 Acc@5 100.000 loss 0.281\n",
      "[[132   2   0   6]\n",
      " [ 20 102   2  16]\n",
      " [  0   1 139   0]\n",
      " [  0   0   0 140]]\n",
      "(4, 4)\n",
      "Accuracy of the model on the 560 test images: 91.6%\n",
      "Max accuracy: 95.00%\n",
      "Epoch: [18]  [  0/227]  eta: 1:18:35  lr: 0.000285  min_lr: 0.000285  loss: 0.3515 (0.3515)  class_acc: 1.0000 (1.0000)  weight_decay: 0.0500 (0.0500)  time: 20.7740  data: 20.6290  max mem: 2500\n",
      "Epoch: [18]  [ 10/227]  eta: 0:07:16  lr: 0.000285  min_lr: 0.000285  loss: 0.4108 (0.5319)  class_acc: 1.0000 (0.9182)  weight_decay: 0.0500 (0.0500)  time: 2.0108  data: 1.8755  max mem: 2500\n",
      "Epoch: [18]  [ 20/227]  eta: 0:03:51  lr: 0.000284  min_lr: 0.000284  loss: 0.4108 (0.5226)  class_acc: 1.0000 (0.9143)  weight_decay: 0.0500 (0.0500)  time: 0.1342  data: 0.0001  max mem: 2500\n",
      "Epoch: [18]  [ 30/227]  eta: 0:02:37  lr: 0.000284  min_lr: 0.000284  loss: 0.5476 (0.5358)  class_acc: 0.9000 (0.9000)  weight_decay: 0.0500 (0.0500)  time: 0.1331  data: 0.0002  max mem: 2500\n",
      "Epoch: [18]  [ 40/227]  eta: 0:01:59  lr: 0.000283  min_lr: 0.000283  loss: 0.4315 (0.5222)  class_acc: 0.9000 (0.9073)  weight_decay: 0.0500 (0.0500)  time: 0.1332  data: 0.0004  max mem: 2500\n",
      "Epoch: [18]  [ 50/227]  eta: 0:01:35  lr: 0.000283  min_lr: 0.000283  loss: 0.3923 (0.5031)  class_acc: 1.0000 (0.9157)  weight_decay: 0.0500 (0.0500)  time: 0.1333  data: 0.0002  max mem: 2500\n",
      "Epoch: [18]  [ 60/227]  eta: 0:01:18  lr: 0.000282  min_lr: 0.000282  loss: 0.3767 (0.4953)  class_acc: 1.0000 (0.9197)  weight_decay: 0.0500 (0.0500)  time: 0.1325  data: 0.0001  max mem: 2500\n",
      "Epoch: [18]  [ 70/227]  eta: 0:01:06  lr: 0.000282  min_lr: 0.000282  loss: 0.4555 (0.4984)  class_acc: 0.9000 (0.9169)  weight_decay: 0.0500 (0.0500)  time: 0.1333  data: 0.0001  max mem: 2500\n",
      "Epoch: [18]  [ 80/227]  eta: 0:00:57  lr: 0.000281  min_lr: 0.000281  loss: 0.4240 (0.4973)  class_acc: 0.9000 (0.9160)  weight_decay: 0.0500 (0.0500)  time: 0.1341  data: 0.0001  max mem: 2500\n",
      "Epoch: [18]  [ 90/227]  eta: 0:00:49  lr: 0.000281  min_lr: 0.000281  loss: 0.4175 (0.4929)  class_acc: 1.0000 (0.9209)  weight_decay: 0.0500 (0.0500)  time: 0.1348  data: 0.0002  max mem: 2500\n",
      "Epoch: [18]  [100/227]  eta: 0:00:42  lr: 0.000280  min_lr: 0.000280  loss: 0.4148 (0.4896)  class_acc: 1.0000 (0.9238)  weight_decay: 0.0500 (0.0500)  time: 0.1349  data: 0.0002  max mem: 2500\n",
      "Epoch: [18]  [110/227]  eta: 0:00:37  lr: 0.000280  min_lr: 0.000280  loss: 0.4148 (0.4878)  class_acc: 1.0000 (0.9252)  weight_decay: 0.0500 (0.0500)  time: 0.1340  data: 0.0001  max mem: 2500\n",
      "Epoch: [18]  [120/227]  eta: 0:00:32  lr: 0.000279  min_lr: 0.000279  loss: 0.3834 (0.4839)  class_acc: 1.0000 (0.9281)  weight_decay: 0.0500 (0.0500)  time: 0.1346  data: 0.0001  max mem: 2500\n",
      "Epoch: [18]  [130/227]  eta: 0:00:28  lr: 0.000279  min_lr: 0.000279  loss: 0.4147 (0.4846)  class_acc: 1.0000 (0.9282)  weight_decay: 0.0500 (0.0500)  time: 0.1341  data: 0.0001  max mem: 2500\n",
      "Epoch: [18]  [140/227]  eta: 0:00:24  lr: 0.000278  min_lr: 0.000278  loss: 0.4378 (0.4803)  class_acc: 1.0000 (0.9298)  weight_decay: 0.0500 (0.0500)  time: 0.1330  data: 0.0002  max mem: 2500\n",
      "Epoch: [18]  [150/227]  eta: 0:00:20  lr: 0.000278  min_lr: 0.000278  loss: 0.4247 (0.4837)  class_acc: 1.0000 (0.9291)  weight_decay: 0.0500 (0.0500)  time: 0.1339  data: 0.0003  max mem: 2500\n",
      "Epoch: [18]  [160/227]  eta: 0:00:17  lr: 0.000277  min_lr: 0.000277  loss: 0.4126 (0.4799)  class_acc: 1.0000 (0.9317)  weight_decay: 0.0500 (0.0500)  time: 0.1358  data: 0.0001  max mem: 2500\n",
      "Epoch: [18]  [170/227]  eta: 0:00:14  lr: 0.000277  min_lr: 0.000277  loss: 0.3972 (0.4797)  class_acc: 1.0000 (0.9322)  weight_decay: 0.0500 (0.0500)  time: 0.1353  data: 0.0000  max mem: 2500\n",
      "Epoch: [18]  [180/227]  eta: 0:00:11  lr: 0.000276  min_lr: 0.000276  loss: 0.3903 (0.4764)  class_acc: 1.0000 (0.9343)  weight_decay: 0.0500 (0.0500)  time: 0.1343  data: 0.0000  max mem: 2500\n",
      "Epoch: [18]  [190/227]  eta: 0:00:08  lr: 0.000276  min_lr: 0.000276  loss: 0.4207 (0.4769)  class_acc: 1.0000 (0.9335)  weight_decay: 0.0500 (0.0500)  time: 0.1337  data: 0.0001  max mem: 2500\n",
      "Epoch: [18]  [200/227]  eta: 0:00:06  lr: 0.000275  min_lr: 0.000275  loss: 0.4675 (0.4776)  class_acc: 0.9000 (0.9313)  weight_decay: 0.0500 (0.0500)  time: 0.1327  data: 0.0002  max mem: 2500\n",
      "Epoch: [18]  [210/227]  eta: 0:00:03  lr: 0.000275  min_lr: 0.000275  loss: 0.4561 (0.4765)  class_acc: 0.9000 (0.9318)  weight_decay: 0.0500 (0.0500)  time: 0.1341  data: 0.0001  max mem: 2500\n",
      "Epoch: [18]  [220/227]  eta: 0:00:01  lr: 0.000274  min_lr: 0.000274  loss: 0.3839 (0.4747)  class_acc: 1.0000 (0.9326)  weight_decay: 0.0500 (0.0500)  time: 0.1347  data: 0.0001  max mem: 2500\n",
      "Epoch: [18]  [226/227]  eta: 0:00:00  lr: 0.000274  min_lr: 0.000274  loss: 0.3800 (0.4741)  class_acc: 1.0000 (0.9330)  weight_decay: 0.0500 (0.0500)  time: 0.1332  data: 0.0001  max mem: 2500\n",
      "Epoch: [18] Total time: 0:00:51 (0.2272 s / it)\n",
      "Averaged stats: lr: 0.000274  min_lr: 0.000274  loss: 0.3800 (0.4741)  class_acc: 1.0000 (0.9330)  weight_decay: 0.0500 (0.0500)\n",
      "Test:  [ 0/38]  eta: 0:13:05  loss: 0.0912 (0.0912)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 20.6623  data: 20.6053  max mem: 2500\n",
      "Test:  [10/38]  eta: 0:00:53  loss: 0.1039 (0.1091)  acc1: 100.0000 (98.7879)  acc5: 100.0000 (100.0000)  time: 1.9209  data: 1.8735  max mem: 2500\n",
      "Test:  [20/38]  eta: 0:00:18  loss: 0.1308 (0.4277)  acc1: 100.0000 (86.0318)  acc5: 100.0000 (100.0000)  time: 0.0468  data: 0.0002  max mem: 2500\n",
      "Test:  [30/38]  eta: 0:00:05  loss: 0.1308 (0.3307)  acc1: 100.0000 (90.3226)  acc5: 100.0000 (100.0000)  time: 0.0467  data: 0.0001  max mem: 2500\n",
      "Test:  [37/38]  eta: 0:00:00  loss: 0.0954 (0.3161)  acc1: 100.0000 (91.2500)  acc5: 100.0000 (100.0000)  time: 0.0451  data: 0.0001  max mem: 2500\n",
      "Test: Total time: 0:00:22 (0.6018 s / it)\n",
      "* Acc@1 91.250 Acc@5 100.000 loss 0.316\n",
      "[[139   1   0   0]\n",
      " [ 41  97   1   1]\n",
      " [  0   0 140   0]\n",
      " [  4   0   1 135]]\n",
      "(4, 4)\n",
      "Accuracy of the model on the 560 test images: 91.3%\n",
      "Max accuracy: 95.00%\n",
      "Epoch: [19]  [  0/227]  eta: 1:18:17  lr: 0.000274  min_lr: 0.000274  loss: 0.4649 (0.4649)  class_acc: 0.9000 (0.9000)  weight_decay: 0.0500 (0.0500)  time: 20.6951  data: 20.5521  max mem: 2500\n",
      "Epoch: [19]  [ 10/227]  eta: 0:07:14  lr: 0.000273  min_lr: 0.000273  loss: 0.4649 (0.5406)  class_acc: 0.9000 (0.9182)  weight_decay: 0.0500 (0.0500)  time: 2.0033  data: 1.8684  max mem: 2500\n",
      "Epoch: [19]  [ 20/227]  eta: 0:03:50  lr: 0.000273  min_lr: 0.000273  loss: 0.4034 (0.5008)  class_acc: 0.9000 (0.9190)  weight_decay: 0.0500 (0.0500)  time: 0.1355  data: 0.0001  max mem: 2500\n",
      "Epoch: [19]  [ 30/227]  eta: 0:02:37  lr: 0.000272  min_lr: 0.000272  loss: 0.3835 (0.4817)  class_acc: 1.0000 (0.9290)  weight_decay: 0.0500 (0.0500)  time: 0.1353  data: 0.0002  max mem: 2500\n",
      "Epoch: [19]  [ 40/227]  eta: 0:01:58  lr: 0.000272  min_lr: 0.000272  loss: 0.3835 (0.4692)  class_acc: 1.0000 (0.9366)  weight_decay: 0.0500 (0.0500)  time: 0.1341  data: 0.0001  max mem: 2500\n",
      "Epoch: [19]  [ 50/227]  eta: 0:01:35  lr: 0.000271  min_lr: 0.000271  loss: 0.3732 (0.4540)  class_acc: 1.0000 (0.9431)  weight_decay: 0.0500 (0.0500)  time: 0.1346  data: 0.0000  max mem: 2500\n",
      "Epoch: [19]  [ 60/227]  eta: 0:01:18  lr: 0.000271  min_lr: 0.000271  loss: 0.3692 (0.4667)  class_acc: 1.0000 (0.9377)  weight_decay: 0.0500 (0.0500)  time: 0.1352  data: 0.0001  max mem: 2500\n",
      "Epoch: [19]  [ 70/227]  eta: 0:01:06  lr: 0.000270  min_lr: 0.000270  loss: 0.4509 (0.4704)  class_acc: 0.9000 (0.9366)  weight_decay: 0.0500 (0.0500)  time: 0.1349  data: 0.0001  max mem: 2500\n",
      "Epoch: [19]  [ 80/227]  eta: 0:00:57  lr: 0.000270  min_lr: 0.000270  loss: 0.4574 (0.4724)  class_acc: 0.9000 (0.9346)  weight_decay: 0.0500 (0.0500)  time: 0.1344  data: 0.0001  max mem: 2500\n",
      "Epoch: [19]  [ 90/227]  eta: 0:00:49  lr: 0.000269  min_lr: 0.000269  loss: 0.4380 (0.4673)  class_acc: 1.0000 (0.9374)  weight_decay: 0.0500 (0.0500)  time: 0.1338  data: 0.0002  max mem: 2500\n",
      "Epoch: [19]  [100/227]  eta: 0:00:42  lr: 0.000269  min_lr: 0.000269  loss: 0.3996 (0.4643)  class_acc: 1.0000 (0.9406)  weight_decay: 0.0500 (0.0500)  time: 0.1332  data: 0.0002  max mem: 2500\n",
      "Epoch: [19]  [110/227]  eta: 0:00:37  lr: 0.000268  min_lr: 0.000268  loss: 0.3980 (0.4620)  class_acc: 1.0000 (0.9423)  weight_decay: 0.0500 (0.0500)  time: 0.1344  data: 0.0002  max mem: 2500\n",
      "Epoch: [19]  [120/227]  eta: 0:00:32  lr: 0.000268  min_lr: 0.000268  loss: 0.3954 (0.4598)  class_acc: 1.0000 (0.9446)  weight_decay: 0.0500 (0.0500)  time: 0.1348  data: 0.0002  max mem: 2500\n",
      "Epoch: [19]  [130/227]  eta: 0:00:28  lr: 0.000267  min_lr: 0.000267  loss: 0.3883 (0.4603)  class_acc: 1.0000 (0.9443)  weight_decay: 0.0500 (0.0500)  time: 0.1335  data: 0.0001  max mem: 2500\n",
      "Epoch: [19]  [140/227]  eta: 0:00:24  lr: 0.000267  min_lr: 0.000267  loss: 0.4159 (0.4624)  class_acc: 1.0000 (0.9440)  weight_decay: 0.0500 (0.0500)  time: 0.1326  data: 0.0001  max mem: 2500\n",
      "Epoch: [19]  [150/227]  eta: 0:00:20  lr: 0.000266  min_lr: 0.000266  loss: 0.4362 (0.4655)  class_acc: 0.9000 (0.9430)  weight_decay: 0.0500 (0.0500)  time: 0.1339  data: 0.0004  max mem: 2500\n",
      "Epoch: [19]  [160/227]  eta: 0:00:17  lr: 0.000266  min_lr: 0.000266  loss: 0.4508 (0.4661)  class_acc: 0.9000 (0.9422)  weight_decay: 0.0500 (0.0500)  time: 0.1345  data: 0.0004  max mem: 2500\n",
      "Epoch: [19]  [170/227]  eta: 0:00:14  lr: 0.000265  min_lr: 0.000265  loss: 0.4508 (0.4669)  class_acc: 0.9000 (0.9415)  weight_decay: 0.0500 (0.0500)  time: 0.1337  data: 0.0001  max mem: 2500\n",
      "Epoch: [19]  [180/227]  eta: 0:00:11  lr: 0.000265  min_lr: 0.000265  loss: 0.3937 (0.4669)  class_acc: 1.0000 (0.9414)  weight_decay: 0.0500 (0.0500)  time: 0.1332  data: 0.0002  max mem: 2500\n",
      "Epoch: [19]  [190/227]  eta: 0:00:08  lr: 0.000264  min_lr: 0.000264  loss: 0.3987 (0.4656)  class_acc: 1.0000 (0.9424)  weight_decay: 0.0500 (0.0500)  time: 0.1332  data: 0.0001  max mem: 2500\n",
      "Epoch: [19]  [200/227]  eta: 0:00:06  lr: 0.000264  min_lr: 0.000264  loss: 0.4003 (0.4643)  class_acc: 1.0000 (0.9428)  weight_decay: 0.0500 (0.0500)  time: 0.1337  data: 0.0002  max mem: 2500\n",
      "Epoch: [19]  [210/227]  eta: 0:00:03  lr: 0.000263  min_lr: 0.000263  loss: 0.4370 (0.4639)  class_acc: 1.0000 (0.9431)  weight_decay: 0.0500 (0.0500)  time: 0.1339  data: 0.0003  max mem: 2500\n",
      "Epoch: [19]  [220/227]  eta: 0:00:01  lr: 0.000263  min_lr: 0.000263  loss: 0.4107 (0.4614)  class_acc: 1.0000 (0.9448)  weight_decay: 0.0500 (0.0500)  time: 0.1335  data: 0.0003  max mem: 2500\n",
      "Epoch: [19]  [226/227]  eta: 0:00:00  lr: 0.000262  min_lr: 0.000262  loss: 0.3821 (0.4608)  class_acc: 1.0000 (0.9449)  weight_decay: 0.0500 (0.0500)  time: 0.1329  data: 0.0003  max mem: 2500\n",
      "Epoch: [19] Total time: 0:00:51 (0.2269 s / it)\n",
      "Averaged stats: lr: 0.000262  min_lr: 0.000262  loss: 0.3821 (0.4608)  class_acc: 1.0000 (0.9449)  weight_decay: 0.0500 (0.0500)\n",
      "Test:  [ 0/38]  eta: 0:13:04  loss: 0.0912 (0.0912)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 20.6423  data: 20.5853  max mem: 2500\n",
      "Test:  [10/38]  eta: 0:00:53  loss: 0.1391 (0.1391)  acc1: 93.3333 (96.3636)  acc5: 100.0000 (100.0000)  time: 1.9189  data: 1.8716  max mem: 2500\n",
      "Test:  [20/38]  eta: 0:00:18  loss: 0.1459 (0.2872)  acc1: 93.3333 (91.4286)  acc5: 100.0000 (100.0000)  time: 0.0466  data: 0.0001  max mem: 2500\n",
      "Test:  [30/38]  eta: 0:00:05  loss: 0.0899 (0.2241)  acc1: 100.0000 (94.1936)  acc5: 100.0000 (100.0000)  time: 0.0465  data: 0.0000  max mem: 2500\n",
      "Test:  [37/38]  eta: 0:00:00  loss: 0.0887 (0.2012)  acc1: 100.0000 (95.1786)  acc5: 100.0000 (100.0000)  time: 0.0449  data: 0.0001  max mem: 2500\n",
      "Test: Total time: 0:00:22 (0.6012 s / it)\n",
      "* Acc@1 95.179 Acc@5 100.000 loss 0.201\n",
      "[[135   3   0   2]\n",
      " [ 17 118   0   5]\n",
      " [  0   0 140   0]\n",
      " [  0   0   0 140]]\n",
      "(4, 4)\n",
      "Accuracy of the model on the 560 test images: 95.2%\n",
      "Max accuracy: 95.18%\n",
      "Epoch: [20]  [  0/227]  eta: 1:18:17  lr: 0.000262  min_lr: 0.000262  loss: 0.3538 (0.3538)  class_acc: 1.0000 (1.0000)  weight_decay: 0.0500 (0.0500)  time: 20.6930  data: 20.5430  max mem: 2500\n",
      "Epoch: [20]  [ 10/227]  eta: 0:07:14  lr: 0.000262  min_lr: 0.000262  loss: 0.4584 (0.4687)  class_acc: 0.9000 (0.9364)  weight_decay: 0.0500 (0.0500)  time: 2.0037  data: 1.8678  max mem: 2500\n",
      "Epoch: [20]  [ 20/227]  eta: 0:03:50  lr: 0.000261  min_lr: 0.000261  loss: 0.4082 (0.4660)  class_acc: 1.0000 (0.9429)  weight_decay: 0.0500 (0.0500)  time: 0.1351  data: 0.0002  max mem: 2500\n",
      "Epoch: [20]  [ 30/227]  eta: 0:02:37  lr: 0.000261  min_lr: 0.000261  loss: 0.4082 (0.4837)  class_acc: 1.0000 (0.9290)  weight_decay: 0.0500 (0.0500)  time: 0.1344  data: 0.0002  max mem: 2500\n",
      "Epoch: [20]  [ 40/227]  eta: 0:01:58  lr: 0.000260  min_lr: 0.000260  loss: 0.4219 (0.4781)  class_acc: 0.9000 (0.9317)  weight_decay: 0.0500 (0.0500)  time: 0.1340  data: 0.0003  max mem: 2500\n",
      "Epoch: [20]  [ 50/227]  eta: 0:01:35  lr: 0.000260  min_lr: 0.000260  loss: 0.3894 (0.4651)  class_acc: 1.0000 (0.9373)  weight_decay: 0.0500 (0.0500)  time: 0.1346  data: 0.0002  max mem: 2500\n",
      "Epoch: [20]  [ 60/227]  eta: 0:01:18  lr: 0.000259  min_lr: 0.000259  loss: 0.3727 (0.4644)  class_acc: 1.0000 (0.9377)  weight_decay: 0.0500 (0.0500)  time: 0.1352  data: 0.0002  max mem: 2500\n",
      "Epoch: [20]  [ 70/227]  eta: 0:01:06  lr: 0.000258  min_lr: 0.000258  loss: 0.3783 (0.4599)  class_acc: 1.0000 (0.9380)  weight_decay: 0.0500 (0.0500)  time: 0.1345  data: 0.0002  max mem: 2500\n",
      "Epoch: [20]  [ 80/227]  eta: 0:00:57  lr: 0.000258  min_lr: 0.000258  loss: 0.4075 (0.4555)  class_acc: 1.0000 (0.9407)  weight_decay: 0.0500 (0.0500)  time: 0.1337  data: 0.0002  max mem: 2500\n",
      "Epoch: [20]  [ 90/227]  eta: 0:00:49  lr: 0.000257  min_lr: 0.000257  loss: 0.3803 (0.4486)  class_acc: 1.0000 (0.9440)  weight_decay: 0.0500 (0.0500)  time: 0.1338  data: 0.0002  max mem: 2500\n",
      "Epoch: [20]  [100/227]  eta: 0:00:42  lr: 0.000257  min_lr: 0.000257  loss: 0.3954 (0.4534)  class_acc: 1.0000 (0.9416)  weight_decay: 0.0500 (0.0500)  time: 0.1336  data: 0.0001  max mem: 2500\n",
      "Epoch: [20]  [110/227]  eta: 0:00:37  lr: 0.000256  min_lr: 0.000256  loss: 0.4693 (0.4587)  class_acc: 0.9000 (0.9387)  weight_decay: 0.0500 (0.0500)  time: 0.1338  data: 0.0001  max mem: 2500\n",
      "Epoch: [20]  [120/227]  eta: 0:00:32  lr: 0.000256  min_lr: 0.000256  loss: 0.4693 (0.4641)  class_acc: 0.9000 (0.9364)  weight_decay: 0.0500 (0.0500)  time: 0.1337  data: 0.0001  max mem: 2500\n",
      "Epoch: [20]  [130/227]  eta: 0:00:28  lr: 0.000255  min_lr: 0.000255  loss: 0.4630 (0.4654)  class_acc: 0.9000 (0.9366)  weight_decay: 0.0500 (0.0500)  time: 0.1332  data: 0.0001  max mem: 2500\n",
      "Epoch: [20]  [140/227]  eta: 0:00:24  lr: 0.000255  min_lr: 0.000255  loss: 0.3956 (0.4632)  class_acc: 1.0000 (0.9390)  weight_decay: 0.0500 (0.0500)  time: 0.1325  data: 0.0001  max mem: 2500\n",
      "Epoch: [20]  [150/227]  eta: 0:00:20  lr: 0.000254  min_lr: 0.000254  loss: 0.3956 (0.4688)  class_acc: 1.0000 (0.9358)  weight_decay: 0.0500 (0.0500)  time: 0.1333  data: 0.0002  max mem: 2500\n",
      "Epoch: [20]  [160/227]  eta: 0:00:17  lr: 0.000254  min_lr: 0.000254  loss: 0.3839 (0.4662)  class_acc: 1.0000 (0.9379)  weight_decay: 0.0500 (0.0500)  time: 0.1330  data: 0.0002  max mem: 2500\n",
      "Epoch: [20]  [170/227]  eta: 0:00:14  lr: 0.000253  min_lr: 0.000253  loss: 0.4264 (0.4682)  class_acc: 1.0000 (0.9363)  weight_decay: 0.0500 (0.0500)  time: 0.1321  data: 0.0003  max mem: 2500\n",
      "Epoch: [20]  [180/227]  eta: 0:00:11  lr: 0.000253  min_lr: 0.000253  loss: 0.4550 (0.4698)  class_acc: 0.9000 (0.9359)  weight_decay: 0.0500 (0.0500)  time: 0.1330  data: 0.0002  max mem: 2500\n",
      "Epoch: [20]  [190/227]  eta: 0:00:08  lr: 0.000252  min_lr: 0.000252  loss: 0.4510 (0.4700)  class_acc: 0.9000 (0.9366)  weight_decay: 0.0500 (0.0500)  time: 0.1337  data: 0.0001  max mem: 2500\n",
      "Epoch: [20]  [200/227]  eta: 0:00:06  lr: 0.000252  min_lr: 0.000252  loss: 0.4224 (0.4691)  class_acc: 1.0000 (0.9373)  weight_decay: 0.0500 (0.0500)  time: 0.1353  data: 0.0002  max mem: 2500\n",
      "Epoch: [20]  [210/227]  eta: 0:00:03  lr: 0.000251  min_lr: 0.000251  loss: 0.4039 (0.4699)  class_acc: 1.0000 (0.9370)  weight_decay: 0.0500 (0.0500)  time: 0.1356  data: 0.0003  max mem: 2500\n",
      "Epoch: [20]  [220/227]  eta: 0:00:01  lr: 0.000250  min_lr: 0.000250  loss: 0.3648 (0.4671)  class_acc: 1.0000 (0.9389)  weight_decay: 0.0500 (0.0500)  time: 0.1345  data: 0.0003  max mem: 2500\n",
      "Epoch: [20]  [226/227]  eta: 0:00:00  lr: 0.000250  min_lr: 0.000250  loss: 0.3653 (0.4664)  class_acc: 1.0000 (0.9396)  weight_decay: 0.0500 (0.0500)  time: 0.1347  data: 0.0002  max mem: 2500\n",
      "Epoch: [20] Total time: 0:00:51 (0.2269 s / it)\n",
      "Averaged stats: lr: 0.000250  min_lr: 0.000250  loss: 0.3653 (0.4664)  class_acc: 1.0000 (0.9396)  weight_decay: 0.0500 (0.0500)\n",
      "Test:  [ 0/38]  eta: 0:13:05  loss: 0.0753 (0.0753)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 20.6759  data: 20.6188  max mem: 2500\n",
      "Test:  [10/38]  eta: 0:00:53  loss: 0.1146 (0.1217)  acc1: 100.0000 (96.9697)  acc5: 100.0000 (100.0000)  time: 1.9220  data: 1.8746  max mem: 2500\n",
      "Test:  [20/38]  eta: 0:00:18  loss: 0.1572 (0.3658)  acc1: 93.3333 (88.5714)  acc5: 100.0000 (100.0000)  time: 0.0466  data: 0.0002  max mem: 2500\n",
      "Test:  [30/38]  eta: 0:00:05  loss: 0.1127 (0.2800)  acc1: 100.0000 (92.0430)  acc5: 100.0000 (100.0000)  time: 0.0465  data: 0.0001  max mem: 2500\n",
      "Test:  [37/38]  eta: 0:00:00  loss: 0.0895 (0.2609)  acc1: 100.0000 (92.8571)  acc5: 100.0000 (100.0000)  time: 0.0450  data: 0.0001  max mem: 2500\n",
      "Test: Total time: 0:00:22 (0.6026 s / it)\n",
      "* Acc@1 92.857 Acc@5 100.000 loss 0.261\n",
      "[[136   2   0   2]\n",
      " [ 29 108   1   2]\n",
      " [  0   0 140   0]\n",
      " [  3   1   0 136]]\n",
      "(4, 4)\n",
      "Accuracy of the model on the 560 test images: 92.9%\n",
      "Max accuracy: 95.18%\n",
      "Epoch: [21]  [  0/227]  eta: 1:18:14  lr: 0.000250  min_lr: 0.000250  loss: 0.3553 (0.3553)  class_acc: 1.0000 (1.0000)  weight_decay: 0.0500 (0.0500)  time: 20.6826  data: 20.5376  max mem: 2500\n",
      "Epoch: [21]  [ 10/227]  eta: 0:07:14  lr: 0.000250  min_lr: 0.000250  loss: 0.4144 (0.4647)  class_acc: 0.9000 (0.9364)  weight_decay: 0.0500 (0.0500)  time: 2.0012  data: 1.8674  max mem: 2500\n",
      "Epoch: [21]  [ 20/227]  eta: 0:03:49  lr: 0.000249  min_lr: 0.000249  loss: 0.4446 (0.4628)  class_acc: 0.9000 (0.9429)  weight_decay: 0.0500 (0.0500)  time: 0.1325  data: 0.0002  max mem: 2500\n",
      "Epoch: [21]  [ 30/227]  eta: 0:02:36  lr: 0.000249  min_lr: 0.000249  loss: 0.4454 (0.4692)  class_acc: 0.9000 (0.9419)  weight_decay: 0.0500 (0.0500)  time: 0.1319  data: 0.0001  max mem: 2500\n",
      "Epoch: [21]  [ 40/227]  eta: 0:01:58  lr: 0.000248  min_lr: 0.000248  loss: 0.4224 (0.4602)  class_acc: 0.9000 (0.9439)  weight_decay: 0.0500 (0.0500)  time: 0.1336  data: 0.0001  max mem: 2500\n",
      "Epoch: [21]  [ 50/227]  eta: 0:01:34  lr: 0.000247  min_lr: 0.000247  loss: 0.3912 (0.4517)  class_acc: 1.0000 (0.9490)  weight_decay: 0.0500 (0.0500)  time: 0.1341  data: 0.0001  max mem: 2500\n",
      "Epoch: [21]  [ 60/227]  eta: 0:01:18  lr: 0.000247  min_lr: 0.000247  loss: 0.3721 (0.4431)  class_acc: 1.0000 (0.9525)  weight_decay: 0.0500 (0.0500)  time: 0.1328  data: 0.0002  max mem: 2500\n",
      "Epoch: [21]  [ 70/227]  eta: 0:01:06  lr: 0.000246  min_lr: 0.000246  loss: 0.3833 (0.4440)  class_acc: 1.0000 (0.9535)  weight_decay: 0.0500 (0.0500)  time: 0.1326  data: 0.0002  max mem: 2500\n",
      "Epoch: [21]  [ 80/227]  eta: 0:00:56  lr: 0.000246  min_lr: 0.000246  loss: 0.3909 (0.4395)  class_acc: 1.0000 (0.9568)  weight_decay: 0.0500 (0.0500)  time: 0.1325  data: 0.0001  max mem: 2500\n",
      "Epoch: [21]  [ 90/227]  eta: 0:00:49  lr: 0.000245  min_lr: 0.000245  loss: 0.3751 (0.4376)  class_acc: 1.0000 (0.9571)  weight_decay: 0.0500 (0.0500)  time: 0.1321  data: 0.0001  max mem: 2500\n",
      "Epoch: [21]  [100/227]  eta: 0:00:42  lr: 0.000245  min_lr: 0.000245  loss: 0.3826 (0.4402)  class_acc: 1.0000 (0.9554)  weight_decay: 0.0500 (0.0500)  time: 0.1343  data: 0.0001  max mem: 2500\n",
      "Epoch: [21]  [110/227]  eta: 0:00:37  lr: 0.000244  min_lr: 0.000244  loss: 0.3913 (0.4402)  class_acc: 1.0000 (0.9541)  weight_decay: 0.0500 (0.0500)  time: 0.1345  data: 0.0001  max mem: 2500\n",
      "Epoch: [21]  [120/227]  eta: 0:00:32  lr: 0.000244  min_lr: 0.000244  loss: 0.3997 (0.4460)  class_acc: 1.0000 (0.9512)  weight_decay: 0.0500 (0.0500)  time: 0.1329  data: 0.0001  max mem: 2500\n",
      "Epoch: [21]  [130/227]  eta: 0:00:28  lr: 0.000243  min_lr: 0.000243  loss: 0.4495 (0.4472)  class_acc: 0.9000 (0.9496)  weight_decay: 0.0500 (0.0500)  time: 0.1333  data: 0.0002  max mem: 2500\n",
      "Epoch: [21]  [140/227]  eta: 0:00:24  lr: 0.000243  min_lr: 0.000243  loss: 0.4495 (0.4529)  class_acc: 0.9000 (0.9475)  weight_decay: 0.0500 (0.0500)  time: 0.1349  data: 0.0002  max mem: 2500\n",
      "Epoch: [21]  [150/227]  eta: 0:00:20  lr: 0.000242  min_lr: 0.000242  loss: 0.3900 (0.4541)  class_acc: 1.0000 (0.9477)  weight_decay: 0.0500 (0.0500)  time: 0.1354  data: 0.0001  max mem: 2500\n",
      "Epoch: [21]  [160/227]  eta: 0:00:17  lr: 0.000242  min_lr: 0.000242  loss: 0.3882 (0.4526)  class_acc: 1.0000 (0.9484)  weight_decay: 0.0500 (0.0500)  time: 0.1350  data: 0.0002  max mem: 2500\n",
      "Epoch: [21]  [170/227]  eta: 0:00:14  lr: 0.000241  min_lr: 0.000241  loss: 0.4416 (0.4561)  class_acc: 0.9000 (0.9462)  weight_decay: 0.0500 (0.0500)  time: 0.1341  data: 0.0004  max mem: 2500\n",
      "Epoch: [21]  [180/227]  eta: 0:00:11  lr: 0.000240  min_lr: 0.000240  loss: 0.4386 (0.4545)  class_acc: 0.9000 (0.9470)  weight_decay: 0.0500 (0.0500)  time: 0.1325  data: 0.0002  max mem: 2500\n",
      "Epoch: [21]  [190/227]  eta: 0:00:08  lr: 0.000240  min_lr: 0.000240  loss: 0.4068 (0.4540)  class_acc: 1.0000 (0.9471)  weight_decay: 0.0500 (0.0500)  time: 0.1339  data: 0.0001  max mem: 2500\n",
      "Epoch: [21]  [200/227]  eta: 0:00:06  lr: 0.000239  min_lr: 0.000239  loss: 0.3829 (0.4532)  class_acc: 1.0000 (0.9478)  weight_decay: 0.0500 (0.0500)  time: 0.1339  data: 0.0002  max mem: 2500\n",
      "Epoch: [21]  [210/227]  eta: 0:00:03  lr: 0.000239  min_lr: 0.000239  loss: 0.3739 (0.4552)  class_acc: 1.0000 (0.9464)  weight_decay: 0.0500 (0.0500)  time: 0.1325  data: 0.0002  max mem: 2500\n",
      "Epoch: [21]  [220/227]  eta: 0:00:01  lr: 0.000238  min_lr: 0.000238  loss: 0.3782 (0.4528)  class_acc: 1.0000 (0.9480)  weight_decay: 0.0500 (0.0500)  time: 0.1345  data: 0.0001  max mem: 2500\n",
      "Epoch: [21]  [226/227]  eta: 0:00:00  lr: 0.000238  min_lr: 0.000238  loss: 0.3780 (0.4515)  class_acc: 1.0000 (0.9485)  weight_decay: 0.0500 (0.0500)  time: 0.1351  data: 0.0002  max mem: 2500\n",
      "Epoch: [21] Total time: 0:00:51 (0.2265 s / it)\n",
      "Averaged stats: lr: 0.000238  min_lr: 0.000238  loss: 0.3780 (0.4515)  class_acc: 1.0000 (0.9485)  weight_decay: 0.0500 (0.0500)\n",
      "Test:  [ 0/38]  eta: 0:13:08  loss: 0.0795 (0.0795)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 20.7496  data: 20.6875  max mem: 2500\n",
      "Test:  [10/38]  eta: 0:00:54  loss: 0.1454 (0.1481)  acc1: 93.3333 (96.3636)  acc5: 100.0000 (100.0000)  time: 1.9289  data: 1.8808  max mem: 2500\n",
      "Test:  [20/38]  eta: 0:00:18  loss: 0.1810 (0.3289)  acc1: 93.3333 (89.8413)  acc5: 100.0000 (100.0000)  time: 0.0467  data: 0.0002  max mem: 2500\n",
      "Test:  [30/38]  eta: 0:00:05  loss: 0.0804 (0.2554)  acc1: 100.0000 (92.6882)  acc5: 100.0000 (100.0000)  time: 0.0466  data: 0.0002  max mem: 2500\n",
      "Test:  [37/38]  eta: 0:00:00  loss: 0.0803 (0.2407)  acc1: 100.0000 (93.3929)  acc5: 100.0000 (100.0000)  time: 0.0451  data: 0.0003  max mem: 2500\n",
      "Test: Total time: 0:00:22 (0.6042 s / it)\n",
      "* Acc@1 93.393 Acc@5 100.000 loss 0.241\n",
      "[[135   3   0   2]\n",
      " [ 23 113   1   3]\n",
      " [  0   0 140   0]\n",
      " [  0   5   0 135]]\n",
      "(4, 4)\n",
      "Accuracy of the model on the 560 test images: 93.4%\n",
      "Max accuracy: 95.18%\n",
      "Epoch: [22]  [  0/227]  eta: 1:18:44  lr: 0.000238  min_lr: 0.000238  loss: 0.3525 (0.3525)  class_acc: 1.0000 (1.0000)  weight_decay: 0.0500 (0.0500)  time: 20.8147  data: 20.6707  max mem: 2500\n",
      "Epoch: [22]  [ 10/227]  eta: 0:07:17  lr: 0.000237  min_lr: 0.000237  loss: 0.3556 (0.4445)  class_acc: 1.0000 (0.9636)  weight_decay: 0.0500 (0.0500)  time: 2.0164  data: 1.8796  max mem: 2500\n",
      "Epoch: [22]  [ 20/227]  eta: 0:03:51  lr: 0.000237  min_lr: 0.000237  loss: 0.3576 (0.4492)  class_acc: 1.0000 (0.9476)  weight_decay: 0.0500 (0.0500)  time: 0.1354  data: 0.0003  max mem: 2500\n",
      "Epoch: [22]  [ 30/227]  eta: 0:02:37  lr: 0.000236  min_lr: 0.000236  loss: 0.4137 (0.4633)  class_acc: 0.9000 (0.9419)  weight_decay: 0.0500 (0.0500)  time: 0.1339  data: 0.0001  max mem: 2500\n",
      "Epoch: [22]  [ 40/227]  eta: 0:01:59  lr: 0.000236  min_lr: 0.000236  loss: 0.3764 (0.4427)  class_acc: 1.0000 (0.9537)  weight_decay: 0.0500 (0.0500)  time: 0.1340  data: 0.0000  max mem: 2500\n",
      "Epoch: [22]  [ 50/227]  eta: 0:01:35  lr: 0.000235  min_lr: 0.000235  loss: 0.3563 (0.4482)  class_acc: 1.0000 (0.9510)  weight_decay: 0.0500 (0.0500)  time: 0.1342  data: 0.0000  max mem: 2500\n",
      "Epoch: [22]  [ 60/227]  eta: 0:01:19  lr: 0.000235  min_lr: 0.000235  loss: 0.3785 (0.4444)  class_acc: 1.0000 (0.9492)  weight_decay: 0.0500 (0.0500)  time: 0.1342  data: 0.0000  max mem: 2500\n",
      "Epoch: [22]  [ 70/227]  eta: 0:01:06  lr: 0.000234  min_lr: 0.000234  loss: 0.3791 (0.4442)  class_acc: 1.0000 (0.9507)  weight_decay: 0.0500 (0.0500)  time: 0.1349  data: 0.0002  max mem: 2500\n",
      "Epoch: [22]  [ 80/227]  eta: 0:00:57  lr: 0.000234  min_lr: 0.000234  loss: 0.4209 (0.4490)  class_acc: 1.0000 (0.9457)  weight_decay: 0.0500 (0.0500)  time: 0.1343  data: 0.0002  max mem: 2500\n",
      "Epoch: [22]  [ 90/227]  eta: 0:00:49  lr: 0.000233  min_lr: 0.000233  loss: 0.3931 (0.4506)  class_acc: 1.0000 (0.9462)  weight_decay: 0.0500 (0.0500)  time: 0.1338  data: 0.0001  max mem: 2500\n",
      "Epoch: [22]  [100/227]  eta: 0:00:43  lr: 0.000232  min_lr: 0.000232  loss: 0.3886 (0.4476)  class_acc: 1.0000 (0.9465)  weight_decay: 0.0500 (0.0500)  time: 0.1340  data: 0.0001  max mem: 2500\n",
      "Epoch: [22]  [110/227]  eta: 0:00:37  lr: 0.000232  min_lr: 0.000232  loss: 0.4271 (0.4468)  class_acc: 1.0000 (0.9477)  weight_decay: 0.0500 (0.0500)  time: 0.1338  data: 0.0001  max mem: 2500\n",
      "Epoch: [22]  [120/227]  eta: 0:00:32  lr: 0.000231  min_lr: 0.000231  loss: 0.3907 (0.4427)  class_acc: 1.0000 (0.9496)  weight_decay: 0.0500 (0.0500)  time: 0.1331  data: 0.0001  max mem: 2500\n",
      "Epoch: [22]  [130/227]  eta: 0:00:28  lr: 0.000231  min_lr: 0.000231  loss: 0.3805 (0.4428)  class_acc: 1.0000 (0.9496)  weight_decay: 0.0500 (0.0500)  time: 0.1331  data: 0.0002  max mem: 2500\n",
      "Epoch: [22]  [140/227]  eta: 0:00:24  lr: 0.000230  min_lr: 0.000230  loss: 0.3854 (0.4423)  class_acc: 1.0000 (0.9518)  weight_decay: 0.0500 (0.0500)  time: 0.1348  data: 0.0003  max mem: 2500\n",
      "Epoch: [22]  [150/227]  eta: 0:00:20  lr: 0.000230  min_lr: 0.000230  loss: 0.4021 (0.4421)  class_acc: 1.0000 (0.9517)  weight_decay: 0.0500 (0.0500)  time: 0.1363  data: 0.0002  max mem: 2500\n",
      "Epoch: [22]  [160/227]  eta: 0:00:17  lr: 0.000229  min_lr: 0.000229  loss: 0.4226 (0.4427)  class_acc: 1.0000 (0.9516)  weight_decay: 0.0500 (0.0500)  time: 0.1359  data: 0.0001  max mem: 2500\n",
      "Epoch: [22]  [170/227]  eta: 0:00:14  lr: 0.000229  min_lr: 0.000229  loss: 0.4226 (0.4453)  class_acc: 1.0000 (0.9503)  weight_decay: 0.0500 (0.0500)  time: 0.1338  data: 0.0000  max mem: 2500\n",
      "Epoch: [22]  [180/227]  eta: 0:00:11  lr: 0.000228  min_lr: 0.000228  loss: 0.3861 (0.4437)  class_acc: 1.0000 (0.9514)  weight_decay: 0.0500 (0.0500)  time: 0.1334  data: 0.0002  max mem: 2500\n",
      "Epoch: [22]  [190/227]  eta: 0:00:08  lr: 0.000228  min_lr: 0.000228  loss: 0.3828 (0.4455)  class_acc: 1.0000 (0.9508)  weight_decay: 0.0500 (0.0500)  time: 0.1351  data: 0.0002  max mem: 2500\n",
      "Epoch: [22]  [200/227]  eta: 0:00:06  lr: 0.000227  min_lr: 0.000227  loss: 0.4323 (0.4456)  class_acc: 0.9000 (0.9502)  weight_decay: 0.0500 (0.0500)  time: 0.1342  data: 0.0000  max mem: 2500\n",
      "Epoch: [22]  [210/227]  eta: 0:00:03  lr: 0.000226  min_lr: 0.000226  loss: 0.4233 (0.4460)  class_acc: 1.0000 (0.9507)  weight_decay: 0.0500 (0.0500)  time: 0.1328  data: 0.0001  max mem: 2500\n",
      "Epoch: [22]  [220/227]  eta: 0:00:01  lr: 0.000226  min_lr: 0.000226  loss: 0.3892 (0.4450)  class_acc: 1.0000 (0.9507)  weight_decay: 0.0500 (0.0500)  time: 0.1328  data: 0.0001  max mem: 2500\n",
      "Epoch: [22]  [226/227]  eta: 0:00:00  lr: 0.000226  min_lr: 0.000226  loss: 0.4162 (0.4467)  class_acc: 0.9000 (0.9498)  weight_decay: 0.0500 (0.0500)  time: 0.1334  data: 0.0001  max mem: 2500\n",
      "Epoch: [22] Total time: 0:00:51 (0.2276 s / it)\n",
      "Averaged stats: lr: 0.000226  min_lr: 0.000226  loss: 0.4162 (0.4467)  class_acc: 0.9000 (0.9498)  weight_decay: 0.0500 (0.0500)\n",
      "Test:  [ 0/38]  eta: 0:13:03  loss: 0.1000 (0.1000)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 20.6189  data: 20.5609  max mem: 2500\n",
      "Test:  [10/38]  eta: 0:00:53  loss: 0.1858 (0.1961)  acc1: 93.3333 (94.5455)  acc5: 100.0000 (100.0000)  time: 1.9167  data: 1.8694  max mem: 2500\n",
      "Test:  [20/38]  eta: 0:00:18  loss: 0.2444 (0.2614)  acc1: 93.3333 (92.0635)  acc5: 100.0000 (100.0000)  time: 0.0466  data: 0.0002  max mem: 2500\n",
      "Test:  [30/38]  eta: 0:00:05  loss: 0.0894 (0.2083)  acc1: 100.0000 (94.1936)  acc5: 100.0000 (100.0000)  time: 0.0465  data: 0.0001  max mem: 2500\n",
      "Test:  [37/38]  eta: 0:00:00  loss: 0.0849 (0.2014)  acc1: 100.0000 (94.8214)  acc5: 100.0000 (100.0000)  time: 0.0449  data: 0.0001  max mem: 2500\n",
      "Test: Total time: 0:00:22 (0.6003 s / it)\n",
      "* Acc@1 94.821 Acc@5 100.000 loss 0.201\n",
      "[[132   6   0   2]\n",
      " [  9 123   5   3]\n",
      " [  0   0 140   0]\n",
      " [  0   4   0 136]]\n",
      "(4, 4)\n",
      "Accuracy of the model on the 560 test images: 94.8%\n",
      "Max accuracy: 95.18%\n",
      "Epoch: [23]  [  0/227]  eta: 1:18:43  lr: 0.000226  min_lr: 0.000226  loss: 0.4665 (0.4665)  class_acc: 0.9000 (0.9000)  weight_decay: 0.0500 (0.0500)  time: 20.8071  data: 20.6621  max mem: 2500\n",
      "Epoch: [23]  [ 10/227]  eta: 0:07:16  lr: 0.000225  min_lr: 0.000225  loss: 0.4461 (0.4738)  class_acc: 0.9000 (0.9182)  weight_decay: 0.0500 (0.0500)  time: 2.0121  data: 1.8786  max mem: 2500\n",
      "Epoch: [23]  [ 20/227]  eta: 0:03:51  lr: 0.000224  min_lr: 0.000224  loss: 0.3939 (0.4638)  class_acc: 1.0000 (0.9333)  weight_decay: 0.0500 (0.0500)  time: 0.1326  data: 0.0002  max mem: 2500\n",
      "Epoch: [23]  [ 30/227]  eta: 0:02:37  lr: 0.000224  min_lr: 0.000224  loss: 0.3827 (0.4551)  class_acc: 1.0000 (0.9355)  weight_decay: 0.0500 (0.0500)  time: 0.1329  data: 0.0001  max mem: 2500\n",
      "Epoch: [23]  [ 40/227]  eta: 0:01:59  lr: 0.000223  min_lr: 0.000223  loss: 0.3722 (0.4436)  class_acc: 1.0000 (0.9439)  weight_decay: 0.0500 (0.0500)  time: 0.1332  data: 0.0001  max mem: 2500\n",
      "Epoch: [23]  [ 50/227]  eta: 0:01:35  lr: 0.000223  min_lr: 0.000223  loss: 0.3676 (0.4387)  class_acc: 1.0000 (0.9471)  weight_decay: 0.0500 (0.0500)  time: 0.1328  data: 0.0001  max mem: 2500\n",
      "Epoch: [23]  [ 60/227]  eta: 0:01:18  lr: 0.000222  min_lr: 0.000222  loss: 0.3831 (0.4429)  class_acc: 1.0000 (0.9459)  weight_decay: 0.0500 (0.0500)  time: 0.1332  data: 0.0001  max mem: 2500\n",
      "Epoch: [23]  [ 70/227]  eta: 0:01:06  lr: 0.000222  min_lr: 0.000222  loss: 0.4069 (0.4455)  class_acc: 1.0000 (0.9451)  weight_decay: 0.0500 (0.0500)  time: 0.1349  data: 0.0000  max mem: 2500\n",
      "Epoch: [23]  [ 80/227]  eta: 0:00:57  lr: 0.000221  min_lr: 0.000221  loss: 0.4010 (0.4430)  class_acc: 1.0000 (0.9494)  weight_decay: 0.0500 (0.0500)  time: 0.1357  data: 0.0001  max mem: 2500\n",
      "Epoch: [23]  [ 90/227]  eta: 0:00:49  lr: 0.000221  min_lr: 0.000221  loss: 0.4042 (0.4431)  class_acc: 1.0000 (0.9495)  weight_decay: 0.0500 (0.0500)  time: 0.1349  data: 0.0001  max mem: 2500\n",
      "Epoch: [23]  [100/227]  eta: 0:00:43  lr: 0.000220  min_lr: 0.000220  loss: 0.3789 (0.4451)  class_acc: 1.0000 (0.9485)  weight_decay: 0.0500 (0.0500)  time: 0.1352  data: 0.0001  max mem: 2500\n",
      "Epoch: [23]  [110/227]  eta: 0:00:37  lr: 0.000219  min_lr: 0.000219  loss: 0.3754 (0.4458)  class_acc: 1.0000 (0.9495)  weight_decay: 0.0500 (0.0500)  time: 0.1358  data: 0.0002  max mem: 2500\n",
      "Epoch: [23]  [120/227]  eta: 0:00:32  lr: 0.000219  min_lr: 0.000219  loss: 0.4070 (0.4490)  class_acc: 1.0000 (0.9479)  weight_decay: 0.0500 (0.0500)  time: 0.1340  data: 0.0002  max mem: 2500\n",
      "Epoch: [23]  [130/227]  eta: 0:00:28  lr: 0.000218  min_lr: 0.000218  loss: 0.3864 (0.4487)  class_acc: 0.9000 (0.9481)  weight_decay: 0.0500 (0.0500)  time: 0.1337  data: 0.0002  max mem: 2500\n",
      "Epoch: [23]  [140/227]  eta: 0:00:24  lr: 0.000218  min_lr: 0.000218  loss: 0.3779 (0.4472)  class_acc: 1.0000 (0.9489)  weight_decay: 0.0500 (0.0500)  time: 0.1350  data: 0.0001  max mem: 2500\n",
      "Epoch: [23]  [150/227]  eta: 0:00:20  lr: 0.000217  min_lr: 0.000217  loss: 0.4450 (0.4524)  class_acc: 0.9000 (0.9444)  weight_decay: 0.0500 (0.0500)  time: 0.1350  data: 0.0002  max mem: 2500\n",
      "Epoch: [23]  [160/227]  eta: 0:00:17  lr: 0.000217  min_lr: 0.000217  loss: 0.4480 (0.4521)  class_acc: 0.9000 (0.9447)  weight_decay: 0.0500 (0.0500)  time: 0.1345  data: 0.0002  max mem: 2500\n",
      "Epoch: [23]  [170/227]  eta: 0:00:14  lr: 0.000216  min_lr: 0.000216  loss: 0.3998 (0.4509)  class_acc: 1.0000 (0.9468)  weight_decay: 0.0500 (0.0500)  time: 0.1336  data: 0.0001  max mem: 2500\n",
      "Epoch: [23]  [180/227]  eta: 0:00:11  lr: 0.000216  min_lr: 0.000216  loss: 0.3765 (0.4465)  class_acc: 1.0000 (0.9497)  weight_decay: 0.0500 (0.0500)  time: 0.1327  data: 0.0002  max mem: 2500\n",
      "Epoch: [23]  [190/227]  eta: 0:00:08  lr: 0.000215  min_lr: 0.000215  loss: 0.3911 (0.4493)  class_acc: 1.0000 (0.9482)  weight_decay: 0.0500 (0.0500)  time: 0.1325  data: 0.0002  max mem: 2500\n",
      "Epoch: [23]  [200/227]  eta: 0:00:06  lr: 0.000215  min_lr: 0.000215  loss: 0.3911 (0.4478)  class_acc: 1.0000 (0.9488)  weight_decay: 0.0500 (0.0500)  time: 0.1342  data: 0.0001  max mem: 2500\n",
      "Epoch: [23]  [210/227]  eta: 0:00:03  lr: 0.000214  min_lr: 0.000214  loss: 0.3732 (0.4471)  class_acc: 1.0000 (0.9498)  weight_decay: 0.0500 (0.0500)  time: 0.1342  data: 0.0001  max mem: 2500\n",
      "Epoch: [23]  [220/227]  eta: 0:00:01  lr: 0.000213  min_lr: 0.000213  loss: 0.3881 (0.4471)  class_acc: 1.0000 (0.9498)  weight_decay: 0.0500 (0.0500)  time: 0.1322  data: 0.0001  max mem: 2500\n",
      "Epoch: [23]  [226/227]  eta: 0:00:00  lr: 0.000213  min_lr: 0.000213  loss: 0.3996 (0.4463)  class_acc: 1.0000 (0.9498)  weight_decay: 0.0500 (0.0500)  time: 0.1327  data: 0.0002  max mem: 2500\n",
      "Epoch: [23] Total time: 0:00:51 (0.2272 s / it)\n",
      "Averaged stats: lr: 0.000213  min_lr: 0.000213  loss: 0.3996 (0.4463)  class_acc: 1.0000 (0.9498)  weight_decay: 0.0500 (0.0500)\n",
      "Test:  [ 0/38]  eta: 0:13:08  loss: 0.0723 (0.0723)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 20.7562  data: 20.7002  max mem: 2500\n",
      "Test:  [10/38]  eta: 0:00:54  loss: 0.1019 (0.1206)  acc1: 100.0000 (97.5758)  acc5: 100.0000 (100.0000)  time: 1.9294  data: 1.8818  max mem: 2500\n",
      "Test:  [20/38]  eta: 0:00:18  loss: 0.1397 (0.2871)  acc1: 93.3333 (90.4762)  acc5: 100.0000 (100.0000)  time: 0.0467  data: 0.0001  max mem: 2500\n",
      "Test:  [30/38]  eta: 0:00:05  loss: 0.1035 (0.2271)  acc1: 100.0000 (93.1183)  acc5: 100.0000 (100.0000)  time: 0.0465  data: 0.0001  max mem: 2500\n",
      "Test:  [37/38]  eta: 0:00:00  loss: 0.0917 (0.2166)  acc1: 100.0000 (94.1071)  acc5: 100.0000 (100.0000)  time: 0.0450  data: 0.0001  max mem: 2500\n",
      "Test: Total time: 0:00:22 (0.6039 s / it)\n",
      "* Acc@1 94.107 Acc@5 100.000 loss 0.217\n",
      "[[137   2   0   1]\n",
      " [ 24 113   1   2]\n",
      " [  0   0 140   0]\n",
      " [  3   0   0 137]]\n",
      "(4, 4)\n",
      "Accuracy of the model on the 560 test images: 94.1%\n",
      "Max accuracy: 95.18%\n",
      "Epoch: [24]  [  0/227]  eta: 1:18:53  lr: 0.000213  min_lr: 0.000213  loss: 0.3515 (0.3515)  class_acc: 1.0000 (1.0000)  weight_decay: 0.0500 (0.0500)  time: 20.8540  data: 20.7020  max mem: 2500\n",
      "Epoch: [24]  [ 10/227]  eta: 0:07:17  lr: 0.000212  min_lr: 0.000212  loss: 0.3589 (0.4288)  class_acc: 1.0000 (0.9727)  weight_decay: 0.0500 (0.0500)  time: 2.0161  data: 1.8822  max mem: 2500\n",
      "Epoch: [24]  [ 20/227]  eta: 0:03:51  lr: 0.000212  min_lr: 0.000212  loss: 0.3692 (0.4279)  class_acc: 1.0000 (0.9667)  weight_decay: 0.0500 (0.0500)  time: 0.1325  data: 0.0002  max mem: 2500\n",
      "Epoch: [24]  [ 30/227]  eta: 0:02:37  lr: 0.000211  min_lr: 0.000211  loss: 0.3883 (0.4387)  class_acc: 1.0000 (0.9581)  weight_decay: 0.0500 (0.0500)  time: 0.1322  data: 0.0002  max mem: 2500\n",
      "Epoch: [24]  [ 40/227]  eta: 0:01:59  lr: 0.000211  min_lr: 0.000211  loss: 0.4003 (0.4445)  class_acc: 0.9000 (0.9537)  weight_decay: 0.0500 (0.0500)  time: 0.1325  data: 0.0002  max mem: 2500\n",
      "Epoch: [24]  [ 50/227]  eta: 0:01:35  lr: 0.000210  min_lr: 0.000210  loss: 0.3695 (0.4310)  class_acc: 1.0000 (0.9608)  weight_decay: 0.0500 (0.0500)  time: 0.1340  data: 0.0003  max mem: 2500\n",
      "Epoch: [24]  [ 60/227]  eta: 0:01:18  lr: 0.000210  min_lr: 0.000210  loss: 0.3610 (0.4315)  class_acc: 1.0000 (0.9623)  weight_decay: 0.0500 (0.0500)  time: 0.1350  data: 0.0003  max mem: 2500\n",
      "Epoch: [24]  [ 70/227]  eta: 0:01:06  lr: 0.000209  min_lr: 0.000209  loss: 0.4047 (0.4420)  class_acc: 1.0000 (0.9577)  weight_decay: 0.0500 (0.0500)  time: 0.1347  data: 0.0001  max mem: 2500\n",
      "Epoch: [24]  [ 80/227]  eta: 0:00:57  lr: 0.000209  min_lr: 0.000209  loss: 0.4001 (0.4441)  class_acc: 1.0000 (0.9580)  weight_decay: 0.0500 (0.0500)  time: 0.1356  data: 0.0000  max mem: 2500\n",
      "Epoch: [24]  [ 90/227]  eta: 0:00:49  lr: 0.000208  min_lr: 0.000208  loss: 0.3866 (0.4445)  class_acc: 1.0000 (0.9582)  weight_decay: 0.0500 (0.0500)  time: 0.1355  data: 0.0001  max mem: 2500\n",
      "Epoch: [24]  [100/227]  eta: 0:00:43  lr: 0.000208  min_lr: 0.000208  loss: 0.3857 (0.4460)  class_acc: 1.0000 (0.9574)  weight_decay: 0.0500 (0.0500)  time: 0.1334  data: 0.0002  max mem: 2500\n",
      "Epoch: [24]  [110/227]  eta: 0:00:37  lr: 0.000207  min_lr: 0.000207  loss: 0.3908 (0.4445)  class_acc: 1.0000 (0.9586)  weight_decay: 0.0500 (0.0500)  time: 0.1333  data: 0.0002  max mem: 2500\n",
      "Epoch: [24]  [120/227]  eta: 0:00:32  lr: 0.000206  min_lr: 0.000206  loss: 0.3993 (0.4469)  class_acc: 1.0000 (0.9570)  weight_decay: 0.0500 (0.0500)  time: 0.1341  data: 0.0002  max mem: 2500\n",
      "Epoch: [24]  [130/227]  eta: 0:00:28  lr: 0.000206  min_lr: 0.000206  loss: 0.4020 (0.4471)  class_acc: 1.0000 (0.9550)  weight_decay: 0.0500 (0.0500)  time: 0.1332  data: 0.0002  max mem: 2500\n",
      "Epoch: [24]  [140/227]  eta: 0:00:24  lr: 0.000205  min_lr: 0.000205  loss: 0.4053 (0.4502)  class_acc: 0.9000 (0.9539)  weight_decay: 0.0500 (0.0500)  time: 0.1336  data: 0.0002  max mem: 2500\n",
      "Epoch: [24]  [150/227]  eta: 0:00:20  lr: 0.000205  min_lr: 0.000205  loss: 0.4257 (0.4504)  class_acc: 0.9000 (0.9523)  weight_decay: 0.0500 (0.0500)  time: 0.1350  data: 0.0002  max mem: 2500\n",
      "Epoch: [24]  [160/227]  eta: 0:00:17  lr: 0.000204  min_lr: 0.000204  loss: 0.4361 (0.4506)  class_acc: 0.9000 (0.9509)  weight_decay: 0.0500 (0.0500)  time: 0.1356  data: 0.0001  max mem: 2500\n",
      "Epoch: [24]  [170/227]  eta: 0:00:14  lr: 0.000204  min_lr: 0.000204  loss: 0.4436 (0.4531)  class_acc: 0.9000 (0.9491)  weight_decay: 0.0500 (0.0500)  time: 0.1349  data: 0.0000  max mem: 2500\n",
      "Epoch: [24]  [180/227]  eta: 0:00:11  lr: 0.000203  min_lr: 0.000203  loss: 0.3719 (0.4526)  class_acc: 1.0000 (0.9497)  weight_decay: 0.0500 (0.0500)  time: 0.1331  data: 0.0001  max mem: 2500\n",
      "Epoch: [24]  [190/227]  eta: 0:00:08  lr: 0.000203  min_lr: 0.000203  loss: 0.3850 (0.4541)  class_acc: 1.0000 (0.9482)  weight_decay: 0.0500 (0.0500)  time: 0.1334  data: 0.0002  max mem: 2500\n",
      "Epoch: [24]  [200/227]  eta: 0:00:06  lr: 0.000202  min_lr: 0.000202  loss: 0.3866 (0.4522)  class_acc: 1.0000 (0.9493)  weight_decay: 0.0500 (0.0500)  time: 0.1334  data: 0.0004  max mem: 2500\n",
      "Epoch: [24]  [210/227]  eta: 0:00:03  lr: 0.000201  min_lr: 0.000201  loss: 0.3948 (0.4524)  class_acc: 1.0000 (0.9483)  weight_decay: 0.0500 (0.0500)  time: 0.1340  data: 0.0003  max mem: 2500\n",
      "Epoch: [24]  [220/227]  eta: 0:00:01  lr: 0.000201  min_lr: 0.000201  loss: 0.3787 (0.4486)  class_acc: 1.0000 (0.9507)  weight_decay: 0.0500 (0.0500)  time: 0.1337  data: 0.0002  max mem: 2500\n",
      "Epoch: [24]  [226/227]  eta: 0:00:00  lr: 0.000201  min_lr: 0.000201  loss: 0.3856 (0.4494)  class_acc: 1.0000 (0.9498)  weight_decay: 0.0500 (0.0500)  time: 0.1338  data: 0.0002  max mem: 2500\n",
      "Epoch: [24] Total time: 0:00:51 (0.2274 s / it)\n",
      "Averaged stats: lr: 0.000201  min_lr: 0.000201  loss: 0.3856 (0.4494)  class_acc: 1.0000 (0.9498)  weight_decay: 0.0500 (0.0500)\n",
      "Test:  [ 0/38]  eta: 0:13:04  loss: 0.0784 (0.0784)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 20.6519  data: 20.5939  max mem: 2500\n",
      "Test:  [10/38]  eta: 0:00:53  loss: 0.1109 (0.1265)  acc1: 100.0000 (96.9697)  acc5: 100.0000 (100.0000)  time: 1.9199  data: 1.8724  max mem: 2500\n",
      "Test:  [20/38]  eta: 0:00:18  loss: 0.1307 (0.3334)  acc1: 93.3333 (88.5714)  acc5: 100.0000 (100.0000)  time: 0.0467  data: 0.0002  max mem: 2500\n",
      "Test:  [30/38]  eta: 0:00:05  loss: 0.0820 (0.2519)  acc1: 100.0000 (92.2581)  acc5: 100.0000 (100.0000)  time: 0.0465  data: 0.0001  max mem: 2500\n",
      "Test:  [37/38]  eta: 0:00:00  loss: 0.0815 (0.2274)  acc1: 100.0000 (93.3929)  acc5: 100.0000 (100.0000)  time: 0.0448  data: 0.0000  max mem: 2500\n",
      "Test: Total time: 0:00:22 (0.6012 s / it)\n",
      "* Acc@1 93.393 Acc@5 100.000 loss 0.227\n",
      "[[135   2   0   3]\n",
      " [ 27 109   0   4]\n",
      " [  0   0 140   0]\n",
      " [  1   0   0 139]]\n",
      "(4, 4)\n",
      "Accuracy of the model on the 560 test images: 93.4%\n",
      "Max accuracy: 95.18%\n",
      "Epoch: [25]  [  0/227]  eta: 1:18:57  lr: 0.000200  min_lr: 0.000200  loss: 0.3550 (0.3550)  class_acc: 1.0000 (1.0000)  weight_decay: 0.0500 (0.0500)  time: 20.8702  data: 20.7212  max mem: 2500\n",
      "Epoch: [25]  [ 10/227]  eta: 0:07:17  lr: 0.000200  min_lr: 0.000200  loss: 0.3958 (0.4941)  class_acc: 1.0000 (0.9273)  weight_decay: 0.0500 (0.0500)  time: 2.0176  data: 1.8838  max mem: 2500\n",
      "Epoch: [25]  [ 20/227]  eta: 0:03:51  lr: 0.000199  min_lr: 0.000199  loss: 0.4220 (0.4976)  class_acc: 0.9000 (0.9190)  weight_decay: 0.0500 (0.0500)  time: 0.1332  data: 0.0002  max mem: 2500\n",
      "Epoch: [25]  [ 30/227]  eta: 0:02:37  lr: 0.000199  min_lr: 0.000199  loss: 0.4575 (0.5066)  class_acc: 0.9000 (0.9129)  weight_decay: 0.0500 (0.0500)  time: 0.1329  data: 0.0002  max mem: 2500\n",
      "Epoch: [25]  [ 40/227]  eta: 0:01:59  lr: 0.000198  min_lr: 0.000198  loss: 0.3948 (0.4825)  class_acc: 1.0000 (0.9268)  weight_decay: 0.0500 (0.0500)  time: 0.1330  data: 0.0001  max mem: 2500\n",
      "Epoch: [25]  [ 50/227]  eta: 0:01:35  lr: 0.000198  min_lr: 0.000198  loss: 0.3818 (0.4757)  class_acc: 1.0000 (0.9333)  weight_decay: 0.0500 (0.0500)  time: 0.1347  data: 0.0002  max mem: 2500\n",
      "Epoch: [25]  [ 60/227]  eta: 0:01:19  lr: 0.000197  min_lr: 0.000197  loss: 0.3730 (0.4698)  class_acc: 1.0000 (0.9361)  weight_decay: 0.0500 (0.0500)  time: 0.1344  data: 0.0003  max mem: 2500\n",
      "Epoch: [25]  [ 70/227]  eta: 0:01:06  lr: 0.000197  min_lr: 0.000197  loss: 0.3728 (0.4631)  class_acc: 1.0000 (0.9394)  weight_decay: 0.0500 (0.0500)  time: 0.1340  data: 0.0002  max mem: 2500\n",
      "Epoch: [25]  [ 80/227]  eta: 0:00:57  lr: 0.000196  min_lr: 0.000196  loss: 0.3737 (0.4531)  class_acc: 1.0000 (0.9444)  weight_decay: 0.0500 (0.0500)  time: 0.1356  data: 0.0002  max mem: 2500\n",
      "Epoch: [25]  [ 90/227]  eta: 0:00:49  lr: 0.000196  min_lr: 0.000196  loss: 0.3868 (0.4490)  class_acc: 1.0000 (0.9473)  weight_decay: 0.0500 (0.0500)  time: 0.1352  data: 0.0001  max mem: 2500\n",
      "Epoch: [25]  [100/227]  eta: 0:00:43  lr: 0.000195  min_lr: 0.000195  loss: 0.3868 (0.4462)  class_acc: 1.0000 (0.9505)  weight_decay: 0.0500 (0.0500)  time: 0.1335  data: 0.0001  max mem: 2500\n",
      "Epoch: [25]  [110/227]  eta: 0:00:37  lr: 0.000194  min_lr: 0.000194  loss: 0.3629 (0.4427)  class_acc: 1.0000 (0.9523)  weight_decay: 0.0500 (0.0500)  time: 0.1343  data: 0.0001  max mem: 2500\n",
      "Epoch: [25]  [120/227]  eta: 0:00:32  lr: 0.000194  min_lr: 0.000194  loss: 0.3670 (0.4429)  class_acc: 1.0000 (0.9504)  weight_decay: 0.0500 (0.0500)  time: 0.1342  data: 0.0000  max mem: 2500\n",
      "Epoch: [25]  [130/227]  eta: 0:00:28  lr: 0.000193  min_lr: 0.000193  loss: 0.4728 (0.4462)  class_acc: 0.9000 (0.9489)  weight_decay: 0.0500 (0.0500)  time: 0.1342  data: 0.0001  max mem: 2500\n",
      "Epoch: [25]  [140/227]  eta: 0:00:24  lr: 0.000193  min_lr: 0.000193  loss: 0.4216 (0.4454)  class_acc: 0.9000 (0.9496)  weight_decay: 0.0500 (0.0500)  time: 0.1338  data: 0.0001  max mem: 2500\n",
      "Epoch: [25]  [150/227]  eta: 0:00:20  lr: 0.000192  min_lr: 0.000192  loss: 0.3734 (0.4463)  class_acc: 1.0000 (0.9497)  weight_decay: 0.0500 (0.0500)  time: 0.1333  data: 0.0001  max mem: 2500\n",
      "Epoch: [25]  [160/227]  eta: 0:00:17  lr: 0.000192  min_lr: 0.000192  loss: 0.3671 (0.4436)  class_acc: 1.0000 (0.9516)  weight_decay: 0.0500 (0.0500)  time: 0.1336  data: 0.0002  max mem: 2500\n",
      "Epoch: [25]  [170/227]  eta: 0:00:14  lr: 0.000191  min_lr: 0.000191  loss: 0.4096 (0.4457)  class_acc: 1.0000 (0.9497)  weight_decay: 0.0500 (0.0500)  time: 0.1330  data: 0.0001  max mem: 2500\n",
      "Epoch: [25]  [180/227]  eta: 0:00:11  lr: 0.000191  min_lr: 0.000191  loss: 0.3946 (0.4434)  class_acc: 1.0000 (0.9519)  weight_decay: 0.0500 (0.0500)  time: 0.1331  data: 0.0001  max mem: 2500\n",
      "Epoch: [25]  [190/227]  eta: 0:00:08  lr: 0.000190  min_lr: 0.000190  loss: 0.3670 (0.4434)  class_acc: 1.0000 (0.9508)  weight_decay: 0.0500 (0.0500)  time: 0.1339  data: 0.0002  max mem: 2500\n",
      "Epoch: [25]  [200/227]  eta: 0:00:06  lr: 0.000189  min_lr: 0.000189  loss: 0.3733 (0.4413)  class_acc: 1.0000 (0.9517)  weight_decay: 0.0500 (0.0500)  time: 0.1339  data: 0.0003  max mem: 2500\n",
      "Epoch: [25]  [210/227]  eta: 0:00:03  lr: 0.000189  min_lr: 0.000189  loss: 0.4053 (0.4412)  class_acc: 1.0000 (0.9521)  weight_decay: 0.0500 (0.0500)  time: 0.1337  data: 0.0003  max mem: 2500\n",
      "Epoch: [25]  [220/227]  eta: 0:00:01  lr: 0.000188  min_lr: 0.000188  loss: 0.4053 (0.4395)  class_acc: 1.0000 (0.9525)  weight_decay: 0.0500 (0.0500)  time: 0.1331  data: 0.0002  max mem: 2500\n",
      "Epoch: [25]  [226/227]  eta: 0:00:00  lr: 0.000188  min_lr: 0.000188  loss: 0.3860 (0.4390)  class_acc: 1.0000 (0.9529)  weight_decay: 0.0500 (0.0500)  time: 0.1339  data: 0.0002  max mem: 2500\n",
      "Epoch: [25] Total time: 0:00:51 (0.2274 s / it)\n",
      "Averaged stats: lr: 0.000188  min_lr: 0.000188  loss: 0.3860 (0.4390)  class_acc: 1.0000 (0.9529)  weight_decay: 0.0500 (0.0500)\n",
      "Test:  [ 0/38]  eta: 0:13:05  loss: 0.0884 (0.0884)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 20.6595  data: 20.6065  max mem: 2500\n",
      "Test:  [10/38]  eta: 0:00:53  loss: 0.1471 (0.1487)  acc1: 100.0000 (96.9697)  acc5: 100.0000 (100.0000)  time: 1.9205  data: 1.8736  max mem: 2500\n",
      "Test:  [20/38]  eta: 0:00:18  loss: 0.1621 (0.2587)  acc1: 93.3333 (92.6984)  acc5: 100.0000 (100.0000)  time: 0.0467  data: 0.0002  max mem: 2500\n",
      "Test:  [30/38]  eta: 0:00:05  loss: 0.0814 (0.2042)  acc1: 100.0000 (94.8387)  acc5: 100.0000 (100.0000)  time: 0.0465  data: 0.0001  max mem: 2500\n",
      "Test:  [37/38]  eta: 0:00:00  loss: 0.0771 (0.1864)  acc1: 100.0000 (95.3571)  acc5: 100.0000 (100.0000)  time: 0.0450  data: 0.0001  max mem: 2500\n",
      "Test: Total time: 0:00:22 (0.6012 s / it)\n",
      "* Acc@1 95.357 Acc@5 100.000 loss 0.186\n",
      "[[136   2   0   2]\n",
      " [ 16 121   1   2]\n",
      " [  0   0 140   0]\n",
      " [  1   2   0 137]]\n",
      "(4, 4)\n",
      "Accuracy of the model on the 560 test images: 95.4%\n",
      "Max accuracy: 95.36%\n",
      "Epoch: [26]  [  0/227]  eta: 1:18:43  lr: 0.000188  min_lr: 0.000188  loss: 0.3553 (0.3553)  class_acc: 1.0000 (1.0000)  weight_decay: 0.0500 (0.0500)  time: 20.8101  data: 20.6610  max mem: 2500\n",
      "Epoch: [26]  [ 10/227]  eta: 0:07:16  lr: 0.000187  min_lr: 0.000187  loss: 0.4249 (0.4582)  class_acc: 1.0000 (0.9455)  weight_decay: 0.0500 (0.0500)  time: 2.0133  data: 1.8785  max mem: 2500\n",
      "Epoch: [26]  [ 20/227]  eta: 0:03:51  lr: 0.000187  min_lr: 0.000187  loss: 0.4249 (0.4459)  class_acc: 1.0000 (0.9619)  weight_decay: 0.0500 (0.0500)  time: 0.1335  data: 0.0002  max mem: 2500\n",
      "Epoch: [26]  [ 30/227]  eta: 0:02:37  lr: 0.000186  min_lr: 0.000186  loss: 0.4353 (0.4720)  class_acc: 1.0000 (0.9452)  weight_decay: 0.0500 (0.0500)  time: 0.1338  data: 0.0002  max mem: 2500\n",
      "Epoch: [26]  [ 40/227]  eta: 0:01:59  lr: 0.000186  min_lr: 0.000186  loss: 0.4596 (0.4680)  class_acc: 0.9000 (0.9463)  weight_decay: 0.0500 (0.0500)  time: 0.1332  data: 0.0002  max mem: 2500\n",
      "Epoch: [26]  [ 50/227]  eta: 0:01:35  lr: 0.000185  min_lr: 0.000185  loss: 0.3986 (0.4536)  class_acc: 1.0000 (0.9549)  weight_decay: 0.0500 (0.0500)  time: 0.1337  data: 0.0002  max mem: 2500\n",
      "Epoch: [26]  [ 60/227]  eta: 0:01:18  lr: 0.000185  min_lr: 0.000185  loss: 0.3757 (0.4570)  class_acc: 1.0000 (0.9492)  weight_decay: 0.0500 (0.0500)  time: 0.1352  data: 0.0002  max mem: 2500\n",
      "Epoch: [26]  [ 70/227]  eta: 0:01:06  lr: 0.000184  min_lr: 0.000184  loss: 0.3757 (0.4510)  class_acc: 1.0000 (0.9535)  weight_decay: 0.0500 (0.0500)  time: 0.1339  data: 0.0000  max mem: 2500\n",
      "Epoch: [26]  [ 80/227]  eta: 0:00:57  lr: 0.000184  min_lr: 0.000184  loss: 0.3904 (0.4536)  class_acc: 1.0000 (0.9519)  weight_decay: 0.0500 (0.0500)  time: 0.1333  data: 0.0001  max mem: 2500\n",
      "Epoch: [26]  [ 90/227]  eta: 0:00:49  lr: 0.000183  min_lr: 0.000183  loss: 0.4110 (0.4488)  class_acc: 1.0000 (0.9538)  weight_decay: 0.0500 (0.0500)  time: 0.1340  data: 0.0001  max mem: 2500\n",
      "Epoch: [26]  [100/227]  eta: 0:00:42  lr: 0.000182  min_lr: 0.000182  loss: 0.3572 (0.4445)  class_acc: 1.0000 (0.9554)  weight_decay: 0.0500 (0.0500)  time: 0.1339  data: 0.0001  max mem: 2500\n",
      "Epoch: [26]  [110/227]  eta: 0:00:37  lr: 0.000182  min_lr: 0.000182  loss: 0.4140 (0.4502)  class_acc: 1.0000 (0.9523)  weight_decay: 0.0500 (0.0500)  time: 0.1335  data: 0.0002  max mem: 2500\n",
      "Epoch: [26]  [120/227]  eta: 0:00:32  lr: 0.000181  min_lr: 0.000181  loss: 0.4169 (0.4480)  class_acc: 1.0000 (0.9529)  weight_decay: 0.0500 (0.0500)  time: 0.1330  data: 0.0003  max mem: 2500\n",
      "Epoch: [26]  [130/227]  eta: 0:00:28  lr: 0.000181  min_lr: 0.000181  loss: 0.3971 (0.4486)  class_acc: 1.0000 (0.9534)  weight_decay: 0.0500 (0.0500)  time: 0.1328  data: 0.0002  max mem: 2500\n",
      "Epoch: [26]  [140/227]  eta: 0:00:24  lr: 0.000180  min_lr: 0.000180  loss: 0.3915 (0.4462)  class_acc: 1.0000 (0.9546)  weight_decay: 0.0500 (0.0500)  time: 0.1372  data: 0.0002  max mem: 2500\n",
      "Epoch: [26]  [150/227]  eta: 0:00:20  lr: 0.000180  min_lr: 0.000180  loss: 0.4095 (0.4475)  class_acc: 1.0000 (0.9530)  weight_decay: 0.0500 (0.0500)  time: 0.1460  data: 0.0002  max mem: 2500\n",
      "Epoch: [26]  [160/227]  eta: 0:00:17  lr: 0.000179  min_lr: 0.000179  loss: 0.3749 (0.4426)  class_acc: 1.0000 (0.9559)  weight_decay: 0.0500 (0.0500)  time: 0.1428  data: 0.0002  max mem: 2500\n",
      "Epoch: [26]  [170/227]  eta: 0:00:14  lr: 0.000179  min_lr: 0.000179  loss: 0.3807 (0.4479)  class_acc: 1.0000 (0.9520)  weight_decay: 0.0500 (0.0500)  time: 0.1363  data: 0.0002  max mem: 2500\n",
      "Epoch: [26]  [180/227]  eta: 0:00:11  lr: 0.000178  min_lr: 0.000178  loss: 0.4230 (0.4469)  class_acc: 0.9000 (0.9519)  weight_decay: 0.0500 (0.0500)  time: 0.1360  data: 0.0002  max mem: 2500\n",
      "Epoch: [26]  [190/227]  eta: 0:00:09  lr: 0.000178  min_lr: 0.000178  loss: 0.3716 (0.4466)  class_acc: 1.0000 (0.9524)  weight_decay: 0.0500 (0.0500)  time: 0.1344  data: 0.0002  max mem: 2500\n",
      "Epoch: [26]  [200/227]  eta: 0:00:06  lr: 0.000177  min_lr: 0.000177  loss: 0.3798 (0.4486)  class_acc: 1.0000 (0.9517)  weight_decay: 0.0500 (0.0500)  time: 0.1331  data: 0.0001  max mem: 2500\n",
      "Epoch: [26]  [210/227]  eta: 0:00:03  lr: 0.000176  min_lr: 0.000176  loss: 0.4189 (0.4482)  class_acc: 0.9000 (0.9512)  weight_decay: 0.0500 (0.0500)  time: 0.1337  data: 0.0001  max mem: 2500\n",
      "Epoch: [26]  [220/227]  eta: 0:00:01  lr: 0.000176  min_lr: 0.000176  loss: 0.3803 (0.4453)  class_acc: 1.0000 (0.9529)  weight_decay: 0.0500 (0.0500)  time: 0.1348  data: 0.0002  max mem: 2500\n",
      "Epoch: [26]  [226/227]  eta: 0:00:00  lr: 0.000176  min_lr: 0.000176  loss: 0.3801 (0.4456)  class_acc: 1.0000 (0.9529)  weight_decay: 0.0500 (0.0500)  time: 0.1354  data: 0.0002  max mem: 2500\n",
      "Epoch: [26] Total time: 0:00:51 (0.2284 s / it)\n",
      "Averaged stats: lr: 0.000176  min_lr: 0.000176  loss: 0.3801 (0.4456)  class_acc: 1.0000 (0.9529)  weight_decay: 0.0500 (0.0500)\n",
      "Test:  [ 0/38]  eta: 0:13:21  loss: 0.0772 (0.0772)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 21.0840  data: 21.0330  max mem: 2500\n",
      "Test:  [10/38]  eta: 0:00:54  loss: 0.1124 (0.1129)  acc1: 100.0000 (98.1818)  acc5: 100.0000 (100.0000)  time: 1.9594  data: 1.9121  max mem: 2500\n",
      "Test:  [20/38]  eta: 0:00:18  loss: 0.1181 (0.3457)  acc1: 100.0000 (88.5714)  acc5: 100.0000 (100.0000)  time: 0.0469  data: 0.0000  max mem: 2500\n",
      "Test:  [30/38]  eta: 0:00:05  loss: 0.0792 (0.2631)  acc1: 100.0000 (92.0430)  acc5: 100.0000 (100.0000)  time: 0.0468  data: 0.0000  max mem: 2500\n",
      "Test:  [37/38]  eta: 0:00:00  loss: 0.0792 (0.2363)  acc1: 100.0000 (93.2143)  acc5: 100.0000 (100.0000)  time: 0.0453  data: 0.0000  max mem: 2500\n",
      "Test: Total time: 0:00:23 (0.6136 s / it)\n",
      "* Acc@1 93.214 Acc@5 100.000 loss 0.236\n",
      "[[137   1   0   2]\n",
      " [ 29 107   0   4]\n",
      " [  0   0 140   0]\n",
      " [  2   0   0 138]]\n",
      "(4, 4)\n",
      "Accuracy of the model on the 560 test images: 93.2%\n",
      "Max accuracy: 95.36%\n",
      "Epoch: [27]  [  0/227]  eta: 1:21:49  lr: 0.000175  min_lr: 0.000175  loss: 0.4184 (0.4184)  class_acc: 1.0000 (1.0000)  weight_decay: 0.0500 (0.0500)  time: 21.6283  data: 21.4823  max mem: 2500\n",
      "Epoch: [27]  [ 10/227]  eta: 0:07:34  lr: 0.000175  min_lr: 0.000175  loss: 0.3560 (0.4245)  class_acc: 1.0000 (0.9818)  weight_decay: 0.0500 (0.0500)  time: 2.0927  data: 1.9532  max mem: 2500\n",
      "Epoch: [27]  [ 20/227]  eta: 0:04:00  lr: 0.000174  min_lr: 0.000174  loss: 0.3593 (0.4265)  class_acc: 1.0000 (0.9762)  weight_decay: 0.0500 (0.0500)  time: 0.1391  data: 0.0004  max mem: 2500\n",
      "Epoch: [27]  [ 30/227]  eta: 0:02:44  lr: 0.000174  min_lr: 0.000174  loss: 0.4200 (0.4380)  class_acc: 1.0000 (0.9613)  weight_decay: 0.0500 (0.0500)  time: 0.1412  data: 0.0004  max mem: 2500\n",
      "Epoch: [27]  [ 40/227]  eta: 0:02:04  lr: 0.000173  min_lr: 0.000173  loss: 0.4154 (0.4284)  class_acc: 0.9000 (0.9610)  weight_decay: 0.0500 (0.0500)  time: 0.1418  data: 0.0003  max mem: 2500\n",
      "Epoch: [27]  [ 50/227]  eta: 0:01:39  lr: 0.000173  min_lr: 0.000173  loss: 0.3670 (0.4191)  class_acc: 1.0000 (0.9627)  weight_decay: 0.0500 (0.0500)  time: 0.1421  data: 0.0001  max mem: 2500\n",
      "Epoch: [27]  [ 60/227]  eta: 0:01:22  lr: 0.000172  min_lr: 0.000172  loss: 0.3539 (0.4172)  class_acc: 1.0000 (0.9623)  weight_decay: 0.0500 (0.0500)  time: 0.1399  data: 0.0002  max mem: 2500\n",
      "Epoch: [27]  [ 70/227]  eta: 0:01:09  lr: 0.000172  min_lr: 0.000172  loss: 0.3893 (0.4178)  class_acc: 1.0000 (0.9648)  weight_decay: 0.0500 (0.0500)  time: 0.1347  data: 0.0002  max mem: 2500\n",
      "Epoch: [27]  [ 80/227]  eta: 0:00:59  lr: 0.000171  min_lr: 0.000171  loss: 0.3869 (0.4168)  class_acc: 1.0000 (0.9654)  weight_decay: 0.0500 (0.0500)  time: 0.1349  data: 0.0002  max mem: 2500\n",
      "Epoch: [27]  [ 90/227]  eta: 0:00:51  lr: 0.000171  min_lr: 0.000171  loss: 0.3791 (0.4132)  class_acc: 1.0000 (0.9681)  weight_decay: 0.0500 (0.0500)  time: 0.1381  data: 0.0002  max mem: 2500\n",
      "Epoch: [27]  [100/227]  eta: 0:00:44  lr: 0.000170  min_lr: 0.000170  loss: 0.3689 (0.4157)  class_acc: 1.0000 (0.9653)  weight_decay: 0.0500 (0.0500)  time: 0.1370  data: 0.0001  max mem: 2500\n",
      "Epoch: [27]  [110/227]  eta: 0:00:38  lr: 0.000169  min_lr: 0.000169  loss: 0.3618 (0.4150)  class_acc: 1.0000 (0.9649)  weight_decay: 0.0500 (0.0500)  time: 0.1392  data: 0.0001  max mem: 2500\n",
      "Epoch: [27]  [120/227]  eta: 0:00:33  lr: 0.000169  min_lr: 0.000169  loss: 0.3648 (0.4161)  class_acc: 1.0000 (0.9653)  weight_decay: 0.0500 (0.0500)  time: 0.1416  data: 0.0001  max mem: 2500\n",
      "Epoch: [27]  [130/227]  eta: 0:00:29  lr: 0.000168  min_lr: 0.000168  loss: 0.3635 (0.4156)  class_acc: 1.0000 (0.9656)  weight_decay: 0.0500 (0.0500)  time: 0.1392  data: 0.0001  max mem: 2500\n",
      "Epoch: [27]  [140/227]  eta: 0:00:25  lr: 0.000168  min_lr: 0.000168  loss: 0.3590 (0.4156)  class_acc: 1.0000 (0.9660)  weight_decay: 0.0500 (0.0500)  time: 0.1389  data: 0.0001  max mem: 2500\n",
      "Epoch: [27]  [150/227]  eta: 0:00:21  lr: 0.000167  min_lr: 0.000167  loss: 0.3638 (0.4220)  class_acc: 1.0000 (0.9623)  weight_decay: 0.0500 (0.0500)  time: 0.1360  data: 0.0002  max mem: 2500\n",
      "Epoch: [27]  [160/227]  eta: 0:00:18  lr: 0.000167  min_lr: 0.000167  loss: 0.4115 (0.4257)  class_acc: 0.9000 (0.9602)  weight_decay: 0.0500 (0.0500)  time: 0.1331  data: 0.0003  max mem: 2500\n",
      "Epoch: [27]  [170/227]  eta: 0:00:15  lr: 0.000166  min_lr: 0.000166  loss: 0.3820 (0.4267)  class_acc: 1.0000 (0.9596)  weight_decay: 0.0500 (0.0500)  time: 0.1330  data: 0.0002  max mem: 2500\n",
      "Epoch: [27]  [180/227]  eta: 0:00:12  lr: 0.000166  min_lr: 0.000166  loss: 0.3633 (0.4257)  class_acc: 1.0000 (0.9602)  weight_decay: 0.0500 (0.0500)  time: 0.1333  data: 0.0002  max mem: 2500\n",
      "Epoch: [27]  [190/227]  eta: 0:00:09  lr: 0.000165  min_lr: 0.000165  loss: 0.3734 (0.4280)  class_acc: 1.0000 (0.9592)  weight_decay: 0.0500 (0.0500)  time: 0.1337  data: 0.0003  max mem: 2500\n",
      "Epoch: [27]  [200/227]  eta: 0:00:06  lr: 0.000165  min_lr: 0.000165  loss: 0.3689 (0.4277)  class_acc: 1.0000 (0.9592)  weight_decay: 0.0500 (0.0500)  time: 0.1350  data: 0.0002  max mem: 2500\n",
      "Epoch: [27]  [210/227]  eta: 0:00:04  lr: 0.000164  min_lr: 0.000164  loss: 0.3689 (0.4282)  class_acc: 1.0000 (0.9583)  weight_decay: 0.0500 (0.0500)  time: 0.1342  data: 0.0002  max mem: 2500\n",
      "Epoch: [27]  [220/227]  eta: 0:00:01  lr: 0.000163  min_lr: 0.000163  loss: 0.3707 (0.4266)  class_acc: 1.0000 (0.9593)  weight_decay: 0.0500 (0.0500)  time: 0.1407  data: 0.0003  max mem: 2500\n",
      "Epoch: [27]  [226/227]  eta: 0:00:00  lr: 0.000163  min_lr: 0.000163  loss: 0.3552 (0.4251)  class_acc: 1.0000 (0.9599)  weight_decay: 0.0500 (0.0500)  time: 0.1456  data: 0.0002  max mem: 2500\n",
      "Epoch: [27] Total time: 0:00:53 (0.2353 s / it)\n",
      "Averaged stats: lr: 0.000163  min_lr: 0.000163  loss: 0.3552 (0.4251)  class_acc: 1.0000 (0.9599)  weight_decay: 0.0500 (0.0500)\n",
      "Test:  [ 0/38]  eta: 0:13:30  loss: 0.0754 (0.0754)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 21.3236  data: 21.2676  max mem: 2500\n",
      "Test:  [10/38]  eta: 0:00:55  loss: 0.1031 (0.1081)  acc1: 100.0000 (98.1818)  acc5: 100.0000 (100.0000)  time: 1.9811  data: 1.9336  max mem: 2500\n",
      "Test:  [20/38]  eta: 0:00:19  loss: 0.1298 (0.3440)  acc1: 93.3333 (88.8889)  acc5: 100.0000 (100.0000)  time: 0.0468  data: 0.0002  max mem: 2500\n",
      "Test:  [30/38]  eta: 0:00:05  loss: 0.0733 (0.2606)  acc1: 100.0000 (92.2581)  acc5: 100.0000 (100.0000)  time: 0.0466  data: 0.0001  max mem: 2500\n",
      "Test:  [37/38]  eta: 0:00:00  loss: 0.0733 (0.2293)  acc1: 100.0000 (93.3929)  acc5: 100.0000 (100.0000)  time: 0.0450  data: 0.0001  max mem: 2500\n",
      "Test: Total time: 0:00:23 (0.6194 s / it)\n",
      "* Acc@1 93.393 Acc@5 100.000 loss 0.229\n",
      "[[138   0   0   2]\n",
      " [ 26 107   1   6]\n",
      " [  0   0 140   0]\n",
      " [  2   0   0 138]]\n",
      "(4, 4)\n",
      "Accuracy of the model on the 560 test images: 93.4%\n",
      "Max accuracy: 95.36%\n",
      "Epoch: [28]  [  0/227]  eta: 1:18:59  lr: 0.000163  min_lr: 0.000163  loss: 0.3505 (0.3505)  class_acc: 1.0000 (1.0000)  weight_decay: 0.0500 (0.0500)  time: 20.8769  data: 20.7098  max mem: 2500\n",
      "Epoch: [28]  [ 10/227]  eta: 0:07:20  lr: 0.000163  min_lr: 0.000163  loss: 0.3669 (0.4196)  class_acc: 1.0000 (0.9727)  weight_decay: 0.0500 (0.0500)  time: 2.0289  data: 1.8830  max mem: 2500\n",
      "Epoch: [28]  [ 20/227]  eta: 0:03:53  lr: 0.000162  min_lr: 0.000162  loss: 0.3728 (0.4301)  class_acc: 1.0000 (0.9524)  weight_decay: 0.0500 (0.0500)  time: 0.1426  data: 0.0004  max mem: 2500\n",
      "Epoch: [28]  [ 30/227]  eta: 0:02:40  lr: 0.000161  min_lr: 0.000161  loss: 0.4369 (0.4349)  class_acc: 0.9000 (0.9516)  weight_decay: 0.0500 (0.0500)  time: 0.1454  data: 0.0003  max mem: 2500\n",
      "Epoch: [28]  [ 40/227]  eta: 0:02:01  lr: 0.000161  min_lr: 0.000161  loss: 0.3989 (0.4288)  class_acc: 1.0000 (0.9561)  weight_decay: 0.0500 (0.0500)  time: 0.1430  data: 0.0003  max mem: 2500\n",
      "Epoch: [28]  [ 50/227]  eta: 0:01:36  lr: 0.000160  min_lr: 0.000160  loss: 0.3608 (0.4172)  class_acc: 1.0000 (0.9647)  weight_decay: 0.0500 (0.0500)  time: 0.1351  data: 0.0004  max mem: 2500\n",
      "Epoch: [28]  [ 60/227]  eta: 0:01:20  lr: 0.000160  min_lr: 0.000160  loss: 0.3798 (0.4259)  class_acc: 1.0000 (0.9574)  weight_decay: 0.0500 (0.0500)  time: 0.1344  data: 0.0003  max mem: 2500\n",
      "Epoch: [28]  [ 70/227]  eta: 0:01:07  lr: 0.000159  min_lr: 0.000159  loss: 0.4395 (0.4332)  class_acc: 0.9000 (0.9507)  weight_decay: 0.0500 (0.0500)  time: 0.1367  data: 0.0002  max mem: 2500\n",
      "Epoch: [28]  [ 80/227]  eta: 0:00:58  lr: 0.000159  min_lr: 0.000159  loss: 0.4315 (0.4311)  class_acc: 0.9000 (0.9519)  weight_decay: 0.0500 (0.0500)  time: 0.1378  data: 0.0001  max mem: 2500\n",
      "Epoch: [28]  [ 90/227]  eta: 0:00:50  lr: 0.000158  min_lr: 0.000158  loss: 0.4012 (0.4301)  class_acc: 1.0000 (0.9538)  weight_decay: 0.0500 (0.0500)  time: 0.1359  data: 0.0001  max mem: 2500\n",
      "Epoch: [28]  [100/227]  eta: 0:00:43  lr: 0.000158  min_lr: 0.000158  loss: 0.3701 (0.4281)  class_acc: 1.0000 (0.9554)  weight_decay: 0.0500 (0.0500)  time: 0.1349  data: 0.0002  max mem: 2500\n",
      "Epoch: [28]  [110/227]  eta: 0:00:38  lr: 0.000157  min_lr: 0.000157  loss: 0.3701 (0.4275)  class_acc: 1.0000 (0.9568)  weight_decay: 0.0500 (0.0500)  time: 0.1344  data: 0.0003  max mem: 2500\n",
      "Epoch: [28]  [120/227]  eta: 0:00:33  lr: 0.000157  min_lr: 0.000157  loss: 0.3697 (0.4243)  class_acc: 1.0000 (0.9587)  weight_decay: 0.0500 (0.0500)  time: 0.1343  data: 0.0003  max mem: 2500\n",
      "Epoch: [28]  [130/227]  eta: 0:00:28  lr: 0.000156  min_lr: 0.000156  loss: 0.3535 (0.4210)  class_acc: 1.0000 (0.9603)  weight_decay: 0.0500 (0.0500)  time: 0.1355  data: 0.0003  max mem: 2500\n",
      "Epoch: [28]  [140/227]  eta: 0:00:24  lr: 0.000156  min_lr: 0.000156  loss: 0.3652 (0.4215)  class_acc: 1.0000 (0.9610)  weight_decay: 0.0500 (0.0500)  time: 0.1343  data: 0.0003  max mem: 2500\n",
      "Epoch: [28]  [150/227]  eta: 0:00:21  lr: 0.000155  min_lr: 0.000155  loss: 0.3705 (0.4241)  class_acc: 1.0000 (0.9596)  weight_decay: 0.0500 (0.0500)  time: 0.1345  data: 0.0003  max mem: 2500\n",
      "Epoch: [28]  [160/227]  eta: 0:00:17  lr: 0.000154  min_lr: 0.000154  loss: 0.3682 (0.4238)  class_acc: 1.0000 (0.9609)  weight_decay: 0.0500 (0.0500)  time: 0.1354  data: 0.0003  max mem: 2500\n",
      "Epoch: [28]  [170/227]  eta: 0:00:14  lr: 0.000154  min_lr: 0.000154  loss: 0.3747 (0.4256)  class_acc: 1.0000 (0.9608)  weight_decay: 0.0500 (0.0500)  time: 0.1352  data: 0.0002  max mem: 2500\n",
      "Epoch: [28]  [180/227]  eta: 0:00:11  lr: 0.000153  min_lr: 0.000153  loss: 0.3692 (0.4225)  class_acc: 1.0000 (0.9624)  weight_decay: 0.0500 (0.0500)  time: 0.1353  data: 0.0002  max mem: 2500\n",
      "Epoch: [28]  [190/227]  eta: 0:00:09  lr: 0.000153  min_lr: 0.000153  loss: 0.3702 (0.4241)  class_acc: 1.0000 (0.9618)  weight_decay: 0.0500 (0.0500)  time: 0.1341  data: 0.0002  max mem: 2500\n",
      "Epoch: [28]  [200/227]  eta: 0:00:06  lr: 0.000152  min_lr: 0.000152  loss: 0.3997 (0.4242)  class_acc: 1.0000 (0.9622)  weight_decay: 0.0500 (0.0500)  time: 0.1333  data: 0.0002  max mem: 2500\n",
      "Epoch: [28]  [210/227]  eta: 0:00:03  lr: 0.000152  min_lr: 0.000152  loss: 0.3786 (0.4238)  class_acc: 1.0000 (0.9616)  weight_decay: 0.0500 (0.0500)  time: 0.1338  data: 0.0001  max mem: 2500\n",
      "Epoch: [28]  [220/227]  eta: 0:00:01  lr: 0.000151  min_lr: 0.000151  loss: 0.3557 (0.4236)  class_acc: 1.0000 (0.9620)  weight_decay: 0.0500 (0.0500)  time: 0.1337  data: 0.0002  max mem: 2500\n",
      "Epoch: [28]  [226/227]  eta: 0:00:00  lr: 0.000151  min_lr: 0.000151  loss: 0.3661 (0.4243)  class_acc: 1.0000 (0.9617)  weight_decay: 0.0500 (0.0500)  time: 0.1333  data: 0.0002  max mem: 2500\n",
      "Epoch: [28] Total time: 0:00:52 (0.2301 s / it)\n",
      "Averaged stats: lr: 0.000151  min_lr: 0.000151  loss: 0.3661 (0.4243)  class_acc: 1.0000 (0.9617)  weight_decay: 0.0500 (0.0500)\n",
      "Test:  [ 0/38]  eta: 0:13:51  loss: 0.0890 (0.0890)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 21.8845  data: 21.8245  max mem: 2500\n",
      "Test:  [10/38]  eta: 0:00:56  loss: 0.1232 (0.1513)  acc1: 100.0000 (96.9697)  acc5: 100.0000 (100.0000)  time: 2.0337  data: 1.9842  max mem: 2500\n",
      "Test:  [20/38]  eta: 0:00:19  loss: 0.1232 (0.2217)  acc1: 93.3333 (93.9683)  acc5: 100.0000 (100.0000)  time: 0.0489  data: 0.0002  max mem: 2500\n",
      "Test:  [30/38]  eta: 0:00:06  loss: 0.0915 (0.1783)  acc1: 100.0000 (95.6989)  acc5: 100.0000 (100.0000)  time: 0.0494  data: 0.0001  max mem: 2500\n",
      "Test:  [37/38]  eta: 0:00:00  loss: 0.0783 (0.1681)  acc1: 100.0000 (96.2500)  acc5: 100.0000 (100.0000)  time: 0.0479  data: 0.0001  max mem: 2500\n",
      "Test: Total time: 0:00:24 (0.6381 s / it)\n",
      "* Acc@1 96.250 Acc@5 100.000 loss 0.168\n",
      "[[135   4   0   1]\n",
      " [ 12 126   0   2]\n",
      " [  0   0 140   0]\n",
      " [  0   2   0 138]]\n",
      "(4, 4)\n",
      "Accuracy of the model on the 560 test images: 96.3%\n",
      "Max accuracy: 96.25%\n",
      "Epoch: [29]  [  0/227]  eta: 1:24:09  lr: 0.000151  min_lr: 0.000151  loss: 0.3525 (0.3525)  class_acc: 1.0000 (1.0000)  weight_decay: 0.0500 (0.0500)  time: 22.2433  data: 22.0863  max mem: 2500\n",
      "Epoch: [29]  [ 10/227]  eta: 0:07:46  lr: 0.000150  min_lr: 0.000150  loss: 0.3525 (0.3545)  class_acc: 1.0000 (1.0000)  weight_decay: 0.0500 (0.0500)  time: 2.1507  data: 2.0082  max mem: 2500\n",
      "Epoch: [29]  [ 20/227]  eta: 0:04:06  lr: 0.000150  min_lr: 0.000150  loss: 0.3529 (0.4103)  class_acc: 1.0000 (0.9619)  weight_decay: 0.0500 (0.0500)  time: 0.1380  data: 0.0002  max mem: 2500\n",
      "Epoch: [29]  [ 30/227]  eta: 0:02:47  lr: 0.000149  min_lr: 0.000149  loss: 0.3597 (0.4207)  class_acc: 1.0000 (0.9613)  weight_decay: 0.0500 (0.0500)  time: 0.1346  data: 0.0001  max mem: 2500\n",
      "Epoch: [29]  [ 40/227]  eta: 0:02:06  lr: 0.000149  min_lr: 0.000149  loss: 0.3746 (0.4187)  class_acc: 1.0000 (0.9659)  weight_decay: 0.0500 (0.0500)  time: 0.1346  data: 0.0002  max mem: 2500\n",
      "Epoch: [29]  [ 50/227]  eta: 0:01:41  lr: 0.000148  min_lr: 0.000148  loss: 0.3636 (0.4094)  class_acc: 1.0000 (0.9706)  weight_decay: 0.0500 (0.0500)  time: 0.1396  data: 0.0002  max mem: 2500\n",
      "Epoch: [29]  [ 60/227]  eta: 0:01:23  lr: 0.000148  min_lr: 0.000148  loss: 0.3619 (0.4096)  class_acc: 1.0000 (0.9689)  weight_decay: 0.0500 (0.0500)  time: 0.1415  data: 0.0002  max mem: 2500\n",
      "Epoch: [29]  [ 70/227]  eta: 0:01:10  lr: 0.000147  min_lr: 0.000147  loss: 0.3682 (0.4101)  class_acc: 1.0000 (0.9676)  weight_decay: 0.0500 (0.0500)  time: 0.1371  data: 0.0003  max mem: 2500\n",
      "Epoch: [29]  [ 80/227]  eta: 0:01:00  lr: 0.000147  min_lr: 0.000147  loss: 0.3592 (0.4095)  class_acc: 1.0000 (0.9679)  weight_decay: 0.0500 (0.0500)  time: 0.1360  data: 0.0003  max mem: 2500\n",
      "Epoch: [29]  [ 90/227]  eta: 0:00:52  lr: 0.000146  min_lr: 0.000146  loss: 0.3763 (0.4152)  class_acc: 1.0000 (0.9637)  weight_decay: 0.0500 (0.0500)  time: 0.1374  data: 0.0003  max mem: 2500\n",
      "Epoch: [29]  [100/227]  eta: 0:00:45  lr: 0.000146  min_lr: 0.000146  loss: 0.3724 (0.4145)  class_acc: 1.0000 (0.9653)  weight_decay: 0.0500 (0.0500)  time: 0.1395  data: 0.0003  max mem: 2500\n",
      "Epoch: [29]  [110/227]  eta: 0:00:39  lr: 0.000145  min_lr: 0.000145  loss: 0.3702 (0.4166)  class_acc: 1.0000 (0.9640)  weight_decay: 0.0500 (0.0500)  time: 0.1463  data: 0.0002  max mem: 2500\n",
      "Epoch: [29]  [120/227]  eta: 0:00:34  lr: 0.000144  min_lr: 0.000144  loss: 0.3702 (0.4147)  class_acc: 1.0000 (0.9645)  weight_decay: 0.0500 (0.0500)  time: 0.1468  data: 0.0002  max mem: 2500\n",
      "Epoch: [29]  [130/227]  eta: 0:00:29  lr: 0.000144  min_lr: 0.000144  loss: 0.3856 (0.4179)  class_acc: 0.9000 (0.9611)  weight_decay: 0.0500 (0.0500)  time: 0.1399  data: 0.0002  max mem: 2500\n",
      "Epoch: [29]  [140/227]  eta: 0:00:25  lr: 0.000143  min_lr: 0.000143  loss: 0.4208 (0.4184)  class_acc: 0.9000 (0.9596)  weight_decay: 0.0500 (0.0500)  time: 0.1390  data: 0.0001  max mem: 2500\n",
      "Epoch: [29]  [150/227]  eta: 0:00:22  lr: 0.000143  min_lr: 0.000143  loss: 0.3907 (0.4206)  class_acc: 1.0000 (0.9583)  weight_decay: 0.0500 (0.0500)  time: 0.1415  data: 0.0002  max mem: 2500\n",
      "Epoch: [29]  [160/227]  eta: 0:00:18  lr: 0.000142  min_lr: 0.000142  loss: 0.3682 (0.4183)  class_acc: 1.0000 (0.9596)  weight_decay: 0.0500 (0.0500)  time: 0.1401  data: 0.0004  max mem: 2500\n",
      "Epoch: [29]  [170/227]  eta: 0:00:15  lr: 0.000142  min_lr: 0.000142  loss: 0.3682 (0.4214)  class_acc: 1.0000 (0.9591)  weight_decay: 0.0500 (0.0500)  time: 0.1367  data: 0.0004  max mem: 2500\n",
      "Epoch: [29]  [180/227]  eta: 0:00:12  lr: 0.000141  min_lr: 0.000141  loss: 0.3769 (0.4188)  class_acc: 1.0000 (0.9608)  weight_decay: 0.0500 (0.0500)  time: 0.1364  data: 0.0002  max mem: 2500\n",
      "Epoch: [29]  [190/227]  eta: 0:00:09  lr: 0.000141  min_lr: 0.000141  loss: 0.3652 (0.4231)  class_acc: 1.0000 (0.9592)  weight_decay: 0.0500 (0.0500)  time: 0.1361  data: 0.0001  max mem: 2500\n",
      "Epoch: [29]  [200/227]  eta: 0:00:06  lr: 0.000140  min_lr: 0.000140  loss: 0.3613 (0.4226)  class_acc: 1.0000 (0.9597)  weight_decay: 0.0500 (0.0500)  time: 0.1379  data: 0.0001  max mem: 2500\n",
      "Epoch: [29]  [210/227]  eta: 0:00:04  lr: 0.000140  min_lr: 0.000140  loss: 0.3774 (0.4224)  class_acc: 1.0000 (0.9602)  weight_decay: 0.0500 (0.0500)  time: 0.1404  data: 0.0002  max mem: 2500\n",
      "Epoch: [29]  [220/227]  eta: 0:00:01  lr: 0.000139  min_lr: 0.000139  loss: 0.3774 (0.4218)  class_acc: 1.0000 (0.9606)  weight_decay: 0.0500 (0.0500)  time: 0.1377  data: 0.0001  max mem: 2500\n",
      "Epoch: [29]  [226/227]  eta: 0:00:00  lr: 0.000139  min_lr: 0.000139  loss: 0.3644 (0.4214)  class_acc: 1.0000 (0.9608)  weight_decay: 0.0500 (0.0500)  time: 0.1356  data: 0.0001  max mem: 2500\n",
      "Epoch: [29] Total time: 0:00:54 (0.2386 s / it)\n",
      "Averaged stats: lr: 0.000139  min_lr: 0.000139  loss: 0.3644 (0.4214)  class_acc: 1.0000 (0.9608)  weight_decay: 0.0500 (0.0500)\n",
      "Test:  [ 0/38]  eta: 0:13:19  loss: 0.0769 (0.0769)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 21.0446  data: 20.9876  max mem: 2500\n",
      "Test:  [10/38]  eta: 0:00:54  loss: 0.1287 (0.1372)  acc1: 93.3333 (96.3636)  acc5: 100.0000 (100.0000)  time: 1.9556  data: 1.9081  max mem: 2500\n",
      "Test:  [20/38]  eta: 0:00:18  loss: 0.1570 (0.3511)  acc1: 93.3333 (88.5714)  acc5: 100.0000 (100.0000)  time: 0.0468  data: 0.0002  max mem: 2500\n",
      "Test:  [30/38]  eta: 0:00:05  loss: 0.0765 (0.2622)  acc1: 100.0000 (92.2581)  acc5: 100.0000 (100.0000)  time: 0.0467  data: 0.0001  max mem: 2500\n",
      "Test:  [37/38]  eta: 0:00:00  loss: 0.0751 (0.2289)  acc1: 100.0000 (93.5714)  acc5: 100.0000 (100.0000)  time: 0.0451  data: 0.0000  max mem: 2500\n",
      "Test: Total time: 0:00:23 (0.6117 s / it)\n",
      "* Acc@1 93.571 Acc@5 100.000 loss 0.229\n",
      "[[135   2   0   3]\n",
      " [ 24 109   0   7]\n",
      " [  0   0 140   0]\n",
      " [  0   0   0 140]]\n",
      "(4, 4)\n",
      "Accuracy of the model on the 560 test images: 93.6%\n",
      "Max accuracy: 96.25%\n",
      "Epoch: [30]  [  0/227]  eta: 1:18:57  lr: 0.000139  min_lr: 0.000139  loss: 0.3511 (0.3511)  class_acc: 1.0000 (1.0000)  weight_decay: 0.0500 (0.0500)  time: 20.8705  data: 20.7185  max mem: 2500\n",
      "Epoch: [30]  [ 10/227]  eta: 0:07:18  lr: 0.000138  min_lr: 0.000138  loss: 0.3519 (0.3835)  class_acc: 1.0000 (0.9818)  weight_decay: 0.0500 (0.0500)  time: 2.0186  data: 1.8837  max mem: 2500\n",
      "Epoch: [30]  [ 20/227]  eta: 0:03:52  lr: 0.000138  min_lr: 0.000138  loss: 0.3597 (0.4131)  class_acc: 1.0000 (0.9571)  weight_decay: 0.0500 (0.0500)  time: 0.1351  data: 0.0002  max mem: 2500\n",
      "Epoch: [30]  [ 30/227]  eta: 0:02:38  lr: 0.000137  min_lr: 0.000137  loss: 0.4667 (0.4241)  class_acc: 0.9000 (0.9484)  weight_decay: 0.0500 (0.0500)  time: 0.1359  data: 0.0002  max mem: 2500\n",
      "Epoch: [30]  [ 40/227]  eta: 0:01:59  lr: 0.000137  min_lr: 0.000137  loss: 0.3856 (0.4182)  class_acc: 0.9000 (0.9512)  weight_decay: 0.0500 (0.0500)  time: 0.1344  data: 0.0001  max mem: 2500\n",
      "Epoch: [30]  [ 50/227]  eta: 0:01:35  lr: 0.000136  min_lr: 0.000136  loss: 0.3643 (0.4110)  class_acc: 1.0000 (0.9549)  weight_decay: 0.0500 (0.0500)  time: 0.1335  data: 0.0001  max mem: 2500\n",
      "Epoch: [30]  [ 60/227]  eta: 0:01:19  lr: 0.000136  min_lr: 0.000136  loss: 0.3565 (0.4092)  class_acc: 1.0000 (0.9574)  weight_decay: 0.0500 (0.0500)  time: 0.1336  data: 0.0002  max mem: 2500\n",
      "Epoch: [30]  [ 70/227]  eta: 0:01:06  lr: 0.000135  min_lr: 0.000135  loss: 0.3596 (0.4107)  class_acc: 1.0000 (0.9577)  weight_decay: 0.0500 (0.0500)  time: 0.1329  data: 0.0002  max mem: 2500\n",
      "Epoch: [30]  [ 80/227]  eta: 0:00:57  lr: 0.000135  min_lr: 0.000135  loss: 0.4053 (0.4138)  class_acc: 1.0000 (0.9580)  weight_decay: 0.0500 (0.0500)  time: 0.1331  data: 0.0003  max mem: 2500\n",
      "Epoch: [30]  [ 90/227]  eta: 0:00:49  lr: 0.000134  min_lr: 0.000134  loss: 0.3871 (0.4139)  class_acc: 1.0000 (0.9593)  weight_decay: 0.0500 (0.0500)  time: 0.1357  data: 0.0003  max mem: 2500\n",
      "Epoch: [30]  [100/227]  eta: 0:00:43  lr: 0.000134  min_lr: 0.000134  loss: 0.3871 (0.4162)  class_acc: 1.0000 (0.9574)  weight_decay: 0.0500 (0.0500)  time: 0.1346  data: 0.0001  max mem: 2500\n",
      "Epoch: [30]  [110/227]  eta: 0:00:37  lr: 0.000133  min_lr: 0.000133  loss: 0.3608 (0.4158)  class_acc: 1.0000 (0.9595)  weight_decay: 0.0500 (0.0500)  time: 0.1333  data: 0.0000  max mem: 2500\n",
      "Epoch: [30]  [120/227]  eta: 0:00:32  lr: 0.000133  min_lr: 0.000133  loss: 0.3564 (0.4174)  class_acc: 1.0000 (0.9595)  weight_decay: 0.0500 (0.0500)  time: 0.1340  data: 0.0000  max mem: 2500\n",
      "Epoch: [30]  [130/227]  eta: 0:00:28  lr: 0.000132  min_lr: 0.000132  loss: 0.4030 (0.4176)  class_acc: 1.0000 (0.9603)  weight_decay: 0.0500 (0.0500)  time: 0.1343  data: 0.0001  max mem: 2500\n",
      "Epoch: [30]  [140/227]  eta: 0:00:24  lr: 0.000132  min_lr: 0.000132  loss: 0.3688 (0.4158)  class_acc: 1.0000 (0.9624)  weight_decay: 0.0500 (0.0500)  time: 0.1338  data: 0.0002  max mem: 2500\n",
      "Epoch: [30]  [150/227]  eta: 0:00:20  lr: 0.000131  min_lr: 0.000131  loss: 0.3729 (0.4207)  class_acc: 1.0000 (0.9596)  weight_decay: 0.0500 (0.0500)  time: 0.1335  data: 0.0002  max mem: 2500\n",
      "Epoch: [30]  [160/227]  eta: 0:00:17  lr: 0.000131  min_lr: 0.000131  loss: 0.3738 (0.4200)  class_acc: 1.0000 (0.9596)  weight_decay: 0.0500 (0.0500)  time: 0.1339  data: 0.0002  max mem: 2500\n",
      "Epoch: [30]  [170/227]  eta: 0:00:14  lr: 0.000130  min_lr: 0.000130  loss: 0.3626 (0.4201)  class_acc: 1.0000 (0.9602)  weight_decay: 0.0500 (0.0500)  time: 0.1339  data: 0.0002  max mem: 2500\n",
      "Epoch: [30]  [180/227]  eta: 0:00:11  lr: 0.000129  min_lr: 0.000129  loss: 0.3621 (0.4179)  class_acc: 1.0000 (0.9613)  weight_decay: 0.0500 (0.0500)  time: 0.1348  data: 0.0001  max mem: 2500\n",
      "Epoch: [30]  [190/227]  eta: 0:00:08  lr: 0.000129  min_lr: 0.000129  loss: 0.3865 (0.4218)  class_acc: 1.0000 (0.9592)  weight_decay: 0.0500 (0.0500)  time: 0.1337  data: 0.0002  max mem: 2500\n",
      "Epoch: [30]  [200/227]  eta: 0:00:06  lr: 0.000128  min_lr: 0.000128  loss: 0.4336 (0.4239)  class_acc: 0.9000 (0.9587)  weight_decay: 0.0500 (0.0500)  time: 0.1330  data: 0.0003  max mem: 2500\n",
      "Epoch: [30]  [210/227]  eta: 0:00:03  lr: 0.000128  min_lr: 0.000128  loss: 0.4336 (0.4256)  class_acc: 1.0000 (0.9578)  weight_decay: 0.0500 (0.0500)  time: 0.1335  data: 0.0001  max mem: 2500\n",
      "Epoch: [30]  [220/227]  eta: 0:00:01  lr: 0.000127  min_lr: 0.000127  loss: 0.3870 (0.4254)  class_acc: 1.0000 (0.9579)  weight_decay: 0.0500 (0.0500)  time: 0.1334  data: 0.0001  max mem: 2500\n",
      "Epoch: [30]  [226/227]  eta: 0:00:00  lr: 0.000127  min_lr: 0.000127  loss: 0.3772 (0.4248)  class_acc: 1.0000 (0.9581)  weight_decay: 0.0500 (0.0500)  time: 0.1339  data: 0.0001  max mem: 2500\n",
      "Epoch: [30] Total time: 0:00:51 (0.2278 s / it)\n",
      "Averaged stats: lr: 0.000127  min_lr: 0.000127  loss: 0.3772 (0.4248)  class_acc: 1.0000 (0.9581)  weight_decay: 0.0500 (0.0500)\n",
      "Test:  [ 0/38]  eta: 0:13:43  loss: 0.0916 (0.0916)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 21.6755  data: 21.6115  max mem: 2500\n",
      "Test:  [10/38]  eta: 0:00:56  loss: 0.1162 (0.1318)  acc1: 100.0000 (98.1818)  acc5: 100.0000 (100.0000)  time: 2.0136  data: 1.9649  max mem: 2500\n",
      "Test:  [20/38]  eta: 0:00:19  loss: 0.1450 (0.3226)  acc1: 93.3333 (89.8413)  acc5: 100.0000 (100.0000)  time: 0.0484  data: 0.0002  max mem: 2500\n",
      "Test:  [30/38]  eta: 0:00:05  loss: 0.0968 (0.2465)  acc1: 100.0000 (93.1183)  acc5: 100.0000 (100.0000)  time: 0.0482  data: 0.0001  max mem: 2500\n",
      "Test:  [37/38]  eta: 0:00:00  loss: 0.0814 (0.2209)  acc1: 100.0000 (94.1071)  acc5: 100.0000 (100.0000)  time: 0.0457  data: 0.0002  max mem: 2500\n",
      "Test: Total time: 0:00:23 (0.6299 s / it)\n",
      "* Acc@1 94.107 Acc@5 100.000 loss 0.221\n",
      "[[138   0   0   2]\n",
      " [ 27 111   0   2]\n",
      " [  0   1 139   0]\n",
      " [  1   0   0 139]]\n",
      "(4, 4)\n",
      "Accuracy of the model on the 560 test images: 94.1%\n",
      "Max accuracy: 96.25%\n",
      "Epoch: [31]  [  0/227]  eta: 1:22:32  lr: 0.000127  min_lr: 0.000127  loss: 0.3491 (0.3491)  class_acc: 1.0000 (1.0000)  weight_decay: 0.0500 (0.0500)  time: 21.8170  data: 21.6689  max mem: 2500\n",
      "Epoch: [31]  [ 10/227]  eta: 0:07:38  lr: 0.000127  min_lr: 0.000127  loss: 0.3730 (0.4144)  class_acc: 1.0000 (0.9545)  weight_decay: 0.0500 (0.0500)  time: 2.1122  data: 1.9700  max mem: 2500\n",
      "Epoch: [31]  [ 20/227]  eta: 0:04:02  lr: 0.000126  min_lr: 0.000126  loss: 0.3730 (0.4099)  class_acc: 1.0000 (0.9667)  weight_decay: 0.0500 (0.0500)  time: 0.1405  data: 0.0001  max mem: 2500\n",
      "Epoch: [31]  [ 30/227]  eta: 0:02:45  lr: 0.000126  min_lr: 0.000126  loss: 0.3673 (0.4080)  class_acc: 1.0000 (0.9677)  weight_decay: 0.0500 (0.0500)  time: 0.1373  data: 0.0002  max mem: 2500\n",
      "Epoch: [31]  [ 40/227]  eta: 0:02:05  lr: 0.000125  min_lr: 0.000125  loss: 0.3696 (0.4111)  class_acc: 1.0000 (0.9659)  weight_decay: 0.0500 (0.0500)  time: 0.1390  data: 0.0002  max mem: 2500\n",
      "Epoch: [31]  [ 50/227]  eta: 0:01:40  lr: 0.000124  min_lr: 0.000124  loss: 0.3631 (0.4057)  class_acc: 1.0000 (0.9686)  weight_decay: 0.0500 (0.0500)  time: 0.1481  data: 0.0001  max mem: 2500\n",
      "Epoch: [31]  [ 60/227]  eta: 0:01:23  lr: 0.000124  min_lr: 0.000124  loss: 0.3563 (0.4129)  class_acc: 1.0000 (0.9623)  weight_decay: 0.0500 (0.0500)  time: 0.1481  data: 0.0002  max mem: 2500\n",
      "Epoch: [31]  [ 70/227]  eta: 0:01:10  lr: 0.000123  min_lr: 0.000123  loss: 0.4150 (0.4197)  class_acc: 1.0000 (0.9634)  weight_decay: 0.0500 (0.0500)  time: 0.1461  data: 0.0002  max mem: 2500\n",
      "Epoch: [31]  [ 80/227]  eta: 0:01:00  lr: 0.000123  min_lr: 0.000123  loss: 0.3774 (0.4197)  class_acc: 1.0000 (0.9642)  weight_decay: 0.0500 (0.0500)  time: 0.1467  data: 0.0002  max mem: 2500\n",
      "Epoch: [31]  [ 90/227]  eta: 0:00:52  lr: 0.000122  min_lr: 0.000122  loss: 0.3729 (0.4215)  class_acc: 1.0000 (0.9637)  weight_decay: 0.0500 (0.0500)  time: 0.1458  data: 0.0002  max mem: 2500\n",
      "Epoch: [31]  [100/227]  eta: 0:00:45  lr: 0.000122  min_lr: 0.000122  loss: 0.3630 (0.4195)  class_acc: 1.0000 (0.9644)  weight_decay: 0.0500 (0.0500)  time: 0.1455  data: 0.0002  max mem: 2500\n",
      "Epoch: [31]  [110/227]  eta: 0:00:39  lr: 0.000121  min_lr: 0.000121  loss: 0.3618 (0.4162)  class_acc: 1.0000 (0.9667)  weight_decay: 0.0500 (0.0500)  time: 0.1451  data: 0.0001  max mem: 2500\n",
      "Epoch: [31]  [120/227]  eta: 0:00:34  lr: 0.000121  min_lr: 0.000121  loss: 0.3668 (0.4160)  class_acc: 1.0000 (0.9669)  weight_decay: 0.0500 (0.0500)  time: 0.1421  data: 0.0001  max mem: 2500\n",
      "Epoch: [31]  [130/227]  eta: 0:00:29  lr: 0.000120  min_lr: 0.000120  loss: 0.3668 (0.4156)  class_acc: 1.0000 (0.9672)  weight_decay: 0.0500 (0.0500)  time: 0.1385  data: 0.0002  max mem: 2500\n",
      "Epoch: [31]  [140/227]  eta: 0:00:25  lr: 0.000120  min_lr: 0.000120  loss: 0.3602 (0.4150)  class_acc: 1.0000 (0.9681)  weight_decay: 0.0500 (0.0500)  time: 0.1424  data: 0.0002  max mem: 2500\n",
      "Epoch: [31]  [150/227]  eta: 0:00:22  lr: 0.000119  min_lr: 0.000119  loss: 0.3648 (0.4190)  class_acc: 1.0000 (0.9669)  weight_decay: 0.0500 (0.0500)  time: 0.1431  data: 0.0002  max mem: 2500\n",
      "Epoch: [31]  [160/227]  eta: 0:00:18  lr: 0.000119  min_lr: 0.000119  loss: 0.3860 (0.4188)  class_acc: 1.0000 (0.9671)  weight_decay: 0.0500 (0.0500)  time: 0.1396  data: 0.0001  max mem: 2500\n",
      "Epoch: [31]  [170/227]  eta: 0:00:15  lr: 0.000118  min_lr: 0.000118  loss: 0.4056 (0.4219)  class_acc: 1.0000 (0.9649)  weight_decay: 0.0500 (0.0500)  time: 0.1387  data: 0.0002  max mem: 2500\n",
      "Epoch: [31]  [180/227]  eta: 0:00:12  lr: 0.000118  min_lr: 0.000118  loss: 0.4049 (0.4212)  class_acc: 1.0000 (0.9646)  weight_decay: 0.0500 (0.0500)  time: 0.1369  data: 0.0001  max mem: 2500\n",
      "Epoch: [31]  [190/227]  eta: 0:00:09  lr: 0.000117  min_lr: 0.000117  loss: 0.3840 (0.4226)  class_acc: 1.0000 (0.9634)  weight_decay: 0.0500 (0.0500)  time: 0.1338  data: 0.0001  max mem: 2500\n",
      "Epoch: [31]  [200/227]  eta: 0:00:06  lr: 0.000117  min_lr: 0.000117  loss: 0.3728 (0.4231)  class_acc: 1.0000 (0.9632)  weight_decay: 0.0500 (0.0500)  time: 0.1330  data: 0.0002  max mem: 2500\n",
      "Epoch: [31]  [210/227]  eta: 0:00:04  lr: 0.000116  min_lr: 0.000116  loss: 0.3696 (0.4224)  class_acc: 1.0000 (0.9640)  weight_decay: 0.0500 (0.0500)  time: 0.1330  data: 0.0002  max mem: 2500\n",
      "Epoch: [31]  [220/227]  eta: 0:00:01  lr: 0.000116  min_lr: 0.000116  loss: 0.3696 (0.4212)  class_acc: 1.0000 (0.9652)  weight_decay: 0.0500 (0.0500)  time: 0.1325  data: 0.0001  max mem: 2500\n",
      "Epoch: [31]  [226/227]  eta: 0:00:00  lr: 0.000116  min_lr: 0.000116  loss: 0.3761 (0.4207)  class_acc: 1.0000 (0.9652)  weight_decay: 0.0500 (0.0500)  time: 0.1328  data: 0.0002  max mem: 2500\n",
      "Epoch: [31] Total time: 0:00:54 (0.2383 s / it)\n",
      "Averaged stats: lr: 0.000116  min_lr: 0.000116  loss: 0.3761 (0.4207)  class_acc: 1.0000 (0.9652)  weight_decay: 0.0500 (0.0500)\n",
      "Test:  [ 0/38]  eta: 0:13:18  loss: 0.0852 (0.0852)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 21.0261  data: 20.9691  max mem: 2500\n",
      "Test:  [10/38]  eta: 0:00:54  loss: 0.1177 (0.1369)  acc1: 100.0000 (96.9697)  acc5: 100.0000 (100.0000)  time: 1.9539  data: 1.9063  max mem: 2500\n",
      "Test:  [20/38]  eta: 0:00:18  loss: 0.1219 (0.2472)  acc1: 93.3333 (92.6984)  acc5: 100.0000 (100.0000)  time: 0.0467  data: 0.0001  max mem: 2500\n",
      "Test:  [30/38]  eta: 0:00:05  loss: 0.0779 (0.1925)  acc1: 100.0000 (95.0538)  acc5: 100.0000 (100.0000)  time: 0.0466  data: 0.0002  max mem: 2500\n",
      "Test:  [37/38]  eta: 0:00:00  loss: 0.0769 (0.1764)  acc1: 100.0000 (95.8929)  acc5: 100.0000 (100.0000)  time: 0.0450  data: 0.0001  max mem: 2500\n",
      "Test: Total time: 0:00:23 (0.6119 s / it)\n",
      "* Acc@1 95.893 Acc@5 100.000 loss 0.176\n",
      "[[135   3   0   2]\n",
      " [ 16 122   0   2]\n",
      " [  0   0 140   0]\n",
      " [  0   0   0 140]]\n",
      "(4, 4)\n",
      "Accuracy of the model on the 560 test images: 95.9%\n",
      "Max accuracy: 96.25%\n",
      "Epoch: [32]  [  0/227]  eta: 1:19:26  lr: 0.000116  min_lr: 0.000116  loss: 0.3505 (0.3505)  class_acc: 1.0000 (1.0000)  weight_decay: 0.0500 (0.0500)  time: 20.9988  data: 20.8554  max mem: 2500\n",
      "Epoch: [32]  [ 10/227]  eta: 0:07:20  lr: 0.000115  min_lr: 0.000115  loss: 0.3505 (0.3812)  class_acc: 1.0000 (0.9909)  weight_decay: 0.0500 (0.0500)  time: 2.0306  data: 1.8962  max mem: 2500\n",
      "Epoch: [32]  [ 20/227]  eta: 0:03:53  lr: 0.000115  min_lr: 0.000115  loss: 0.3534 (0.3822)  class_acc: 1.0000 (0.9857)  weight_decay: 0.0500 (0.0500)  time: 0.1333  data: 0.0002  max mem: 2500\n",
      "Epoch: [32]  [ 30/227]  eta: 0:02:38  lr: 0.000114  min_lr: 0.000114  loss: 0.3611 (0.3787)  class_acc: 1.0000 (0.9871)  weight_decay: 0.0500 (0.0500)  time: 0.1334  data: 0.0001  max mem: 2500\n",
      "Epoch: [32]  [ 40/227]  eta: 0:02:00  lr: 0.000114  min_lr: 0.000114  loss: 0.3611 (0.3850)  class_acc: 1.0000 (0.9829)  weight_decay: 0.0500 (0.0500)  time: 0.1338  data: 0.0002  max mem: 2500\n",
      "Epoch: [32]  [ 50/227]  eta: 0:01:36  lr: 0.000113  min_lr: 0.000113  loss: 0.3596 (0.3812)  class_acc: 1.0000 (0.9863)  weight_decay: 0.0500 (0.0500)  time: 0.1331  data: 0.0002  max mem: 2500\n",
      "Epoch: [32]  [ 60/227]  eta: 0:01:19  lr: 0.000113  min_lr: 0.000113  loss: 0.3529 (0.3826)  class_acc: 1.0000 (0.9836)  weight_decay: 0.0500 (0.0500)  time: 0.1341  data: 0.0002  max mem: 2500\n",
      "Epoch: [32]  [ 70/227]  eta: 0:01:07  lr: 0.000112  min_lr: 0.000112  loss: 0.3588 (0.3863)  class_acc: 1.0000 (0.9803)  weight_decay: 0.0500 (0.0500)  time: 0.1342  data: 0.0002  max mem: 2500\n",
      "Epoch: [32]  [ 80/227]  eta: 0:00:57  lr: 0.000112  min_lr: 0.000112  loss: 0.3692 (0.3931)  class_acc: 1.0000 (0.9753)  weight_decay: 0.0500 (0.0500)  time: 0.1328  data: 0.0001  max mem: 2500\n",
      "Epoch: [32]  [ 90/227]  eta: 0:00:49  lr: 0.000111  min_lr: 0.000111  loss: 0.3769 (0.3946)  class_acc: 1.0000 (0.9747)  weight_decay: 0.0500 (0.0500)  time: 0.1327  data: 0.0002  max mem: 2500\n",
      "Epoch: [32]  [100/227]  eta: 0:00:43  lr: 0.000111  min_lr: 0.000111  loss: 0.3615 (0.3957)  class_acc: 1.0000 (0.9733)  weight_decay: 0.0500 (0.0500)  time: 0.1325  data: 0.0003  max mem: 2500\n",
      "Epoch: [32]  [110/227]  eta: 0:00:37  lr: 0.000110  min_lr: 0.000110  loss: 0.3938 (0.3993)  class_acc: 1.0000 (0.9721)  weight_decay: 0.0500 (0.0500)  time: 0.1326  data: 0.0002  max mem: 2500\n",
      "Epoch: [32]  [120/227]  eta: 0:00:32  lr: 0.000110  min_lr: 0.000110  loss: 0.3742 (0.3965)  class_acc: 1.0000 (0.9744)  weight_decay: 0.0500 (0.0500)  time: 0.1339  data: 0.0000  max mem: 2500\n",
      "Epoch: [32]  [130/227]  eta: 0:00:28  lr: 0.000109  min_lr: 0.000109  loss: 0.3613 (0.3979)  class_acc: 1.0000 (0.9740)  weight_decay: 0.0500 (0.0500)  time: 0.1341  data: 0.0001  max mem: 2500\n",
      "Epoch: [32]  [140/227]  eta: 0:00:24  lr: 0.000109  min_lr: 0.000109  loss: 0.3642 (0.4008)  class_acc: 1.0000 (0.9738)  weight_decay: 0.0500 (0.0500)  time: 0.1334  data: 0.0002  max mem: 2500\n",
      "Epoch: [32]  [150/227]  eta: 0:00:20  lr: 0.000108  min_lr: 0.000108  loss: 0.3693 (0.4031)  class_acc: 1.0000 (0.9728)  weight_decay: 0.0500 (0.0500)  time: 0.1336  data: 0.0001  max mem: 2500\n",
      "Epoch: [32]  [160/227]  eta: 0:00:17  lr: 0.000108  min_lr: 0.000108  loss: 0.3840 (0.4043)  class_acc: 1.0000 (0.9727)  weight_decay: 0.0500 (0.0500)  time: 0.1346  data: 0.0000  max mem: 2500\n",
      "Epoch: [32]  [170/227]  eta: 0:00:14  lr: 0.000107  min_lr: 0.000107  loss: 0.3828 (0.4041)  class_acc: 1.0000 (0.9719)  weight_decay: 0.0500 (0.0500)  time: 0.1340  data: 0.0001  max mem: 2500\n",
      "Epoch: [32]  [180/227]  eta: 0:00:11  lr: 0.000107  min_lr: 0.000107  loss: 0.3661 (0.4041)  class_acc: 1.0000 (0.9707)  weight_decay: 0.0500 (0.0500)  time: 0.1329  data: 0.0002  max mem: 2500\n",
      "Epoch: [32]  [190/227]  eta: 0:00:08  lr: 0.000106  min_lr: 0.000106  loss: 0.3574 (0.4055)  class_acc: 1.0000 (0.9696)  weight_decay: 0.0500 (0.0500)  time: 0.1344  data: 0.0002  max mem: 2500\n",
      "Epoch: [32]  [200/227]  eta: 0:00:06  lr: 0.000106  min_lr: 0.000106  loss: 0.3601 (0.4052)  class_acc: 1.0000 (0.9697)  weight_decay: 0.0500 (0.0500)  time: 0.1346  data: 0.0001  max mem: 2500\n",
      "Epoch: [32]  [210/227]  eta: 0:00:03  lr: 0.000105  min_lr: 0.000105  loss: 0.3603 (0.4052)  class_acc: 1.0000 (0.9701)  weight_decay: 0.0500 (0.0500)  time: 0.1342  data: 0.0002  max mem: 2500\n",
      "Epoch: [32]  [220/227]  eta: 0:00:01  lr: 0.000105  min_lr: 0.000105  loss: 0.3574 (0.4080)  class_acc: 1.0000 (0.9688)  weight_decay: 0.0500 (0.0500)  time: 0.1351  data: 0.0002  max mem: 2500\n",
      "Epoch: [32]  [226/227]  eta: 0:00:00  lr: 0.000104  min_lr: 0.000104  loss: 0.3603 (0.4082)  class_acc: 1.0000 (0.9683)  weight_decay: 0.0500 (0.0500)  time: 0.1348  data: 0.0001  max mem: 2500\n",
      "Epoch: [32] Total time: 0:00:51 (0.2280 s / it)\n",
      "Averaged stats: lr: 0.000104  min_lr: 0.000104  loss: 0.3603 (0.4082)  class_acc: 1.0000 (0.9683)  weight_decay: 0.0500 (0.0500)\n",
      "Test:  [ 0/38]  eta: 0:13:06  loss: 0.0917 (0.0917)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 20.6915  data: 20.6355  max mem: 2500\n",
      "Test:  [10/38]  eta: 0:00:53  loss: 0.1145 (0.1597)  acc1: 100.0000 (96.9697)  acc5: 100.0000 (100.0000)  time: 1.9238  data: 1.8760  max mem: 2500\n",
      "Test:  [20/38]  eta: 0:00:18  loss: 0.2081 (0.2778)  acc1: 93.3333 (92.0635)  acc5: 100.0000 (100.0000)  time: 0.0468  data: 0.0002  max mem: 2500\n",
      "Test:  [30/38]  eta: 0:00:05  loss: 0.0914 (0.2167)  acc1: 100.0000 (94.4086)  acc5: 100.0000 (100.0000)  time: 0.0466  data: 0.0003  max mem: 2500\n",
      "Test:  [37/38]  eta: 0:00:00  loss: 0.0869 (0.2012)  acc1: 100.0000 (95.1786)  acc5: 100.0000 (100.0000)  time: 0.0450  data: 0.0002  max mem: 2500\n",
      "Test: Total time: 0:00:22 (0.6022 s / it)\n",
      "* Acc@1 95.179 Acc@5 100.000 loss 0.201\n",
      "[[135   2   2   1]\n",
      " [ 14 120   3   3]\n",
      " [  0   0 140   0]\n",
      " [  1   0   1 138]]\n",
      "(4, 4)\n",
      "Accuracy of the model on the 560 test images: 95.2%\n",
      "Max accuracy: 96.25%\n",
      "Epoch: [33]  [  0/227]  eta: 1:18:43  lr: 0.000104  min_lr: 0.000104  loss: 0.3504 (0.3504)  class_acc: 1.0000 (1.0000)  weight_decay: 0.0500 (0.0500)  time: 20.8070  data: 20.6599  max mem: 2500\n",
      "Epoch: [33]  [ 10/227]  eta: 0:07:16  lr: 0.000104  min_lr: 0.000104  loss: 0.3557 (0.3905)  class_acc: 1.0000 (0.9818)  weight_decay: 0.0500 (0.0500)  time: 2.0132  data: 1.8783  max mem: 2500\n",
      "Epoch: [33]  [ 20/227]  eta: 0:03:51  lr: 0.000103  min_lr: 0.000103  loss: 0.3645 (0.4047)  class_acc: 1.0000 (0.9714)  weight_decay: 0.0500 (0.0500)  time: 0.1331  data: 0.0002  max mem: 2500\n",
      "Epoch: [33]  [ 30/227]  eta: 0:02:37  lr: 0.000103  min_lr: 0.000103  loss: 0.3666 (0.4101)  class_acc: 1.0000 (0.9710)  weight_decay: 0.0500 (0.0500)  time: 0.1324  data: 0.0003  max mem: 2500\n",
      "Epoch: [33]  [ 40/227]  eta: 0:01:59  lr: 0.000102  min_lr: 0.000102  loss: 0.3753 (0.4244)  class_acc: 1.0000 (0.9610)  weight_decay: 0.0500 (0.0500)  time: 0.1336  data: 0.0003  max mem: 2500\n",
      "Epoch: [33]  [ 50/227]  eta: 0:01:35  lr: 0.000102  min_lr: 0.000102  loss: 0.3618 (0.4132)  class_acc: 1.0000 (0.9686)  weight_decay: 0.0500 (0.0500)  time: 0.1352  data: 0.0002  max mem: 2500\n",
      "Epoch: [33]  [ 60/227]  eta: 0:01:18  lr: 0.000102  min_lr: 0.000102  loss: 0.3607 (0.4188)  class_acc: 1.0000 (0.9639)  weight_decay: 0.0500 (0.0500)  time: 0.1351  data: 0.0002  max mem: 2500\n",
      "Epoch: [33]  [ 70/227]  eta: 0:01:06  lr: 0.000101  min_lr: 0.000101  loss: 0.4047 (0.4194)  class_acc: 1.0000 (0.9634)  weight_decay: 0.0500 (0.0500)  time: 0.1337  data: 0.0002  max mem: 2500\n",
      "Epoch: [33]  [ 80/227]  eta: 0:00:57  lr: 0.000101  min_lr: 0.000101  loss: 0.3950 (0.4199)  class_acc: 1.0000 (0.9630)  weight_decay: 0.0500 (0.0500)  time: 0.1335  data: 0.0003  max mem: 2500\n",
      "Epoch: [33]  [ 90/227]  eta: 0:00:49  lr: 0.000100  min_lr: 0.000100  loss: 0.3878 (0.4204)  class_acc: 1.0000 (0.9604)  weight_decay: 0.0500 (0.0500)  time: 0.1342  data: 0.0002  max mem: 2500\n",
      "Epoch: [33]  [100/227]  eta: 0:00:42  lr: 0.000100  min_lr: 0.000100  loss: 0.4132 (0.4210)  class_acc: 1.0000 (0.9594)  weight_decay: 0.0500 (0.0500)  time: 0.1337  data: 0.0002  max mem: 2500\n",
      "Epoch: [33]  [110/227]  eta: 0:00:37  lr: 0.000099  min_lr: 0.000099  loss: 0.3856 (0.4180)  class_acc: 1.0000 (0.9613)  weight_decay: 0.0500 (0.0500)  time: 0.1329  data: 0.0002  max mem: 2500\n",
      "Epoch: [33]  [120/227]  eta: 0:00:32  lr: 0.000099  min_lr: 0.000099  loss: 0.3650 (0.4176)  class_acc: 1.0000 (0.9603)  weight_decay: 0.0500 (0.0500)  time: 0.1336  data: 0.0001  max mem: 2500\n",
      "Epoch: [33]  [130/227]  eta: 0:00:28  lr: 0.000098  min_lr: 0.000098  loss: 0.3704 (0.4169)  class_acc: 1.0000 (0.9618)  weight_decay: 0.0500 (0.0500)  time: 0.1345  data: 0.0003  max mem: 2500\n",
      "Epoch: [33]  [140/227]  eta: 0:00:24  lr: 0.000098  min_lr: 0.000098  loss: 0.3587 (0.4177)  class_acc: 1.0000 (0.9631)  weight_decay: 0.0500 (0.0500)  time: 0.1350  data: 0.0002  max mem: 2500\n",
      "Epoch: [33]  [150/227]  eta: 0:00:20  lr: 0.000097  min_lr: 0.000097  loss: 0.3753 (0.4240)  class_acc: 1.0000 (0.9589)  weight_decay: 0.0500 (0.0500)  time: 0.1348  data: 0.0001  max mem: 2500\n",
      "Epoch: [33]  [160/227]  eta: 0:00:17  lr: 0.000097  min_lr: 0.000097  loss: 0.3753 (0.4233)  class_acc: 1.0000 (0.9590)  weight_decay: 0.0500 (0.0500)  time: 0.1347  data: 0.0002  max mem: 2500\n",
      "Epoch: [33]  [170/227]  eta: 0:00:14  lr: 0.000096  min_lr: 0.000096  loss: 0.3662 (0.4229)  class_acc: 1.0000 (0.9596)  weight_decay: 0.0500 (0.0500)  time: 0.1355  data: 0.0001  max mem: 2500\n",
      "Epoch: [33]  [180/227]  eta: 0:00:11  lr: 0.000096  min_lr: 0.000096  loss: 0.3733 (0.4220)  class_acc: 1.0000 (0.9608)  weight_decay: 0.0500 (0.0500)  time: 0.1375  data: 0.0001  max mem: 2500\n",
      "Epoch: [33]  [190/227]  eta: 0:00:08  lr: 0.000095  min_lr: 0.000095  loss: 0.3660 (0.4221)  class_acc: 1.0000 (0.9613)  weight_decay: 0.0500 (0.0500)  time: 0.1386  data: 0.0002  max mem: 2500\n",
      "Epoch: [33]  [200/227]  eta: 0:00:06  lr: 0.000095  min_lr: 0.000095  loss: 0.3660 (0.4223)  class_acc: 1.0000 (0.9612)  weight_decay: 0.0500 (0.0500)  time: 0.1367  data: 0.0002  max mem: 2500\n",
      "Epoch: [33]  [210/227]  eta: 0:00:03  lr: 0.000094  min_lr: 0.000094  loss: 0.3713 (0.4218)  class_acc: 1.0000 (0.9611)  weight_decay: 0.0500 (0.0500)  time: 0.1387  data: 0.0001  max mem: 2500\n",
      "Epoch: [33]  [220/227]  eta: 0:00:01  lr: 0.000094  min_lr: 0.000094  loss: 0.3598 (0.4193)  class_acc: 1.0000 (0.9624)  weight_decay: 0.0500 (0.0500)  time: 0.1377  data: 0.0001  max mem: 2500\n",
      "Epoch: [33]  [226/227]  eta: 0:00:00  lr: 0.000094  min_lr: 0.000094  loss: 0.3636 (0.4187)  class_acc: 1.0000 (0.9626)  weight_decay: 0.0500 (0.0500)  time: 0.1342  data: 0.0001  max mem: 2500\n",
      "Epoch: [33] Total time: 0:00:51 (0.2282 s / it)\n",
      "Averaged stats: lr: 0.000094  min_lr: 0.000094  loss: 0.3636 (0.4187)  class_acc: 1.0000 (0.9626)  weight_decay: 0.0500 (0.0500)\n",
      "Test:  [ 0/38]  eta: 0:13:50  loss: 0.0752 (0.0752)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 21.8653  data: 21.8003  max mem: 2500\n",
      "Test:  [10/38]  eta: 0:00:56  loss: 0.0777 (0.1193)  acc1: 100.0000 (97.5758)  acc5: 100.0000 (100.0000)  time: 2.0339  data: 1.9819  max mem: 2500\n",
      "Test:  [20/38]  eta: 0:00:19  loss: 0.1114 (0.2457)  acc1: 93.3333 (93.3333)  acc5: 100.0000 (100.0000)  time: 0.0505  data: 0.0001  max mem: 2500\n",
      "Test:  [30/38]  eta: 0:00:06  loss: 0.0784 (0.1933)  acc1: 100.0000 (95.4839)  acc5: 100.0000 (100.0000)  time: 0.0488  data: 0.0001  max mem: 2500\n",
      "Test:  [37/38]  eta: 0:00:00  loss: 0.0783 (0.1817)  acc1: 100.0000 (95.8929)  acc5: 100.0000 (100.0000)  time: 0.0460  data: 0.0001  max mem: 2500\n",
      "Test: Total time: 0:00:24 (0.6367 s / it)\n",
      "* Acc@1 95.893 Acc@5 100.000 loss 0.182\n",
      "[[136   3   0   1]\n",
      " [ 15 123   0   2]\n",
      " [  0   0 140   0]\n",
      " [  1   0   1 138]]\n",
      "(4, 4)\n",
      "Accuracy of the model on the 560 test images: 95.9%\n",
      "Max accuracy: 96.25%\n",
      "Epoch: [34]  [  0/227]  eta: 1:18:46  lr: 0.000094  min_lr: 0.000094  loss: 0.5975 (0.5975)  class_acc: 0.9000 (0.9000)  weight_decay: 0.0500 (0.0500)  time: 20.8231  data: 20.6760  max mem: 2500\n",
      "Epoch: [34]  [ 10/227]  eta: 0:07:17  lr: 0.000093  min_lr: 0.000093  loss: 0.3851 (0.4555)  class_acc: 1.0000 (0.9455)  weight_decay: 0.0500 (0.0500)  time: 2.0153  data: 1.8800  max mem: 2500\n",
      "Epoch: [34]  [ 20/227]  eta: 0:03:51  lr: 0.000093  min_lr: 0.000093  loss: 0.3731 (0.4185)  class_acc: 1.0000 (0.9667)  weight_decay: 0.0500 (0.0500)  time: 0.1354  data: 0.0002  max mem: 2500\n",
      "Epoch: [34]  [ 30/227]  eta: 0:02:38  lr: 0.000092  min_lr: 0.000092  loss: 0.3826 (0.4368)  class_acc: 1.0000 (0.9516)  weight_decay: 0.0500 (0.0500)  time: 0.1354  data: 0.0001  max mem: 2500\n",
      "Epoch: [34]  [ 40/227]  eta: 0:01:59  lr: 0.000092  min_lr: 0.000092  loss: 0.3855 (0.4350)  class_acc: 1.0000 (0.9537)  weight_decay: 0.0500 (0.0500)  time: 0.1343  data: 0.0002  max mem: 2500\n",
      "Epoch: [34]  [ 50/227]  eta: 0:01:35  lr: 0.000091  min_lr: 0.000091  loss: 0.3578 (0.4259)  class_acc: 1.0000 (0.9588)  weight_decay: 0.0500 (0.0500)  time: 0.1344  data: 0.0001  max mem: 2500\n",
      "Epoch: [34]  [ 60/227]  eta: 0:01:19  lr: 0.000091  min_lr: 0.000091  loss: 0.3586 (0.4206)  class_acc: 1.0000 (0.9623)  weight_decay: 0.0500 (0.0500)  time: 0.1345  data: 0.0002  max mem: 2500\n",
      "Epoch: [34]  [ 70/227]  eta: 0:01:06  lr: 0.000090  min_lr: 0.000090  loss: 0.3624 (0.4247)  class_acc: 1.0000 (0.9606)  weight_decay: 0.0500 (0.0500)  time: 0.1332  data: 0.0003  max mem: 2500\n",
      "Epoch: [34]  [ 80/227]  eta: 0:00:57  lr: 0.000090  min_lr: 0.000090  loss: 0.3655 (0.4247)  class_acc: 1.0000 (0.9605)  weight_decay: 0.0500 (0.0500)  time: 0.1330  data: 0.0002  max mem: 2500\n",
      "Epoch: [34]  [ 90/227]  eta: 0:00:49  lr: 0.000089  min_lr: 0.000089  loss: 0.3679 (0.4247)  class_acc: 1.0000 (0.9604)  weight_decay: 0.0500 (0.0500)  time: 0.1332  data: 0.0003  max mem: 2500\n",
      "Epoch: [34]  [100/227]  eta: 0:00:43  lr: 0.000089  min_lr: 0.000089  loss: 0.4032 (0.4264)  class_acc: 1.0000 (0.9604)  weight_decay: 0.0500 (0.0500)  time: 0.1325  data: 0.0002  max mem: 2500\n",
      "Epoch: [34]  [110/227]  eta: 0:00:37  lr: 0.000089  min_lr: 0.000089  loss: 0.3862 (0.4261)  class_acc: 1.0000 (0.9613)  weight_decay: 0.0500 (0.0500)  time: 0.1354  data: 0.0003  max mem: 2500\n",
      "Epoch: [34]  [120/227]  eta: 0:00:32  lr: 0.000088  min_lr: 0.000088  loss: 0.3756 (0.4246)  class_acc: 1.0000 (0.9612)  weight_decay: 0.0500 (0.0500)  time: 0.1374  data: 0.0003  max mem: 2500\n",
      "Epoch: [34]  [130/227]  eta: 0:00:28  lr: 0.000088  min_lr: 0.000088  loss: 0.3936 (0.4275)  class_acc: 1.0000 (0.9595)  weight_decay: 0.0500 (0.0500)  time: 0.1341  data: 0.0001  max mem: 2500\n",
      "Epoch: [34]  [140/227]  eta: 0:00:24  lr: 0.000087  min_lr: 0.000087  loss: 0.3682 (0.4255)  class_acc: 1.0000 (0.9610)  weight_decay: 0.0500 (0.0500)  time: 0.1326  data: 0.0001  max mem: 2500\n",
      "Epoch: [34]  [150/227]  eta: 0:00:20  lr: 0.000087  min_lr: 0.000087  loss: 0.3642 (0.4251)  class_acc: 1.0000 (0.9616)  weight_decay: 0.0500 (0.0500)  time: 0.1335  data: 0.0001  max mem: 2500\n",
      "Epoch: [34]  [160/227]  eta: 0:00:17  lr: 0.000086  min_lr: 0.000086  loss: 0.3745 (0.4226)  class_acc: 1.0000 (0.9627)  weight_decay: 0.0500 (0.0500)  time: 0.1336  data: 0.0000  max mem: 2500\n",
      "Epoch: [34]  [170/227]  eta: 0:00:14  lr: 0.000086  min_lr: 0.000086  loss: 0.3745 (0.4241)  class_acc: 1.0000 (0.9626)  weight_decay: 0.0500 (0.0500)  time: 0.1334  data: 0.0002  max mem: 2500\n",
      "Epoch: [34]  [180/227]  eta: 0:00:11  lr: 0.000085  min_lr: 0.000085  loss: 0.3611 (0.4203)  class_acc: 1.0000 (0.9646)  weight_decay: 0.0500 (0.0500)  time: 0.1342  data: 0.0002  max mem: 2500\n",
      "Epoch: [34]  [190/227]  eta: 0:00:08  lr: 0.000085  min_lr: 0.000085  loss: 0.3559 (0.4206)  class_acc: 1.0000 (0.9644)  weight_decay: 0.0500 (0.0500)  time: 0.1340  data: 0.0001  max mem: 2500\n",
      "Epoch: [34]  [200/227]  eta: 0:00:06  lr: 0.000084  min_lr: 0.000084  loss: 0.3654 (0.4202)  class_acc: 1.0000 (0.9652)  weight_decay: 0.0500 (0.0500)  time: 0.1331  data: 0.0002  max mem: 2500\n",
      "Epoch: [34]  [210/227]  eta: 0:00:03  lr: 0.000084  min_lr: 0.000084  loss: 0.3648 (0.4195)  class_acc: 1.0000 (0.9654)  weight_decay: 0.0500 (0.0500)  time: 0.1335  data: 0.0002  max mem: 2500\n",
      "Epoch: [34]  [220/227]  eta: 0:00:01  lr: 0.000084  min_lr: 0.000084  loss: 0.3568 (0.4172)  class_acc: 1.0000 (0.9665)  weight_decay: 0.0500 (0.0500)  time: 0.1350  data: 0.0002  max mem: 2500\n",
      "Epoch: [34]  [226/227]  eta: 0:00:00  lr: 0.000083  min_lr: 0.000083  loss: 0.3568 (0.4160)  class_acc: 1.0000 (0.9670)  weight_decay: 0.0500 (0.0500)  time: 0.1354  data: 0.0002  max mem: 2500\n",
      "Epoch: [34] Total time: 0:00:51 (0.2276 s / it)\n",
      "Averaged stats: lr: 0.000083  min_lr: 0.000083  loss: 0.3568 (0.4160)  class_acc: 1.0000 (0.9670)  weight_decay: 0.0500 (0.0500)\n",
      "Test:  [ 0/38]  eta: 0:13:06  loss: 0.0760 (0.0760)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 20.6905  data: 20.6345  max mem: 2500\n",
      "Test:  [10/38]  eta: 0:00:53  loss: 0.0851 (0.1119)  acc1: 100.0000 (98.1818)  acc5: 100.0000 (100.0000)  time: 1.9233  data: 1.8760  max mem: 2500\n",
      "Test:  [20/38]  eta: 0:00:18  loss: 0.0990 (0.2848)  acc1: 93.3333 (90.7937)  acc5: 100.0000 (100.0000)  time: 0.0466  data: 0.0001  max mem: 2500\n",
      "Test:  [30/38]  eta: 0:00:05  loss: 0.0799 (0.2185)  acc1: 100.0000 (93.7634)  acc5: 100.0000 (100.0000)  time: 0.0465  data: 0.0000  max mem: 2500\n",
      "Test:  [37/38]  eta: 0:00:00  loss: 0.0799 (0.2011)  acc1: 100.0000 (94.6429)  acc5: 100.0000 (100.0000)  time: 0.0450  data: 0.0000  max mem: 2500\n",
      "Test: Total time: 0:00:22 (0.6023 s / it)\n",
      "* Acc@1 94.643 Acc@5 100.000 loss 0.201\n",
      "[[137   1   1   1]\n",
      " [ 23 114   1   2]\n",
      " [  0   0 140   0]\n",
      " [  0   0   1 139]]\n",
      "(4, 4)\n",
      "Accuracy of the model on the 560 test images: 94.6%\n",
      "Max accuracy: 96.25%\n",
      "Epoch: [35]  [  0/227]  eta: 1:19:03  lr: 0.000083  min_lr: 0.000083  loss: 0.3494 (0.3494)  class_acc: 1.0000 (1.0000)  weight_decay: 0.0500 (0.0500)  time: 20.8962  data: 20.7292  max mem: 2500\n",
      "Epoch: [35]  [ 10/227]  eta: 0:07:18  lr: 0.000083  min_lr: 0.000083  loss: 0.3645 (0.4006)  class_acc: 1.0000 (0.9727)  weight_decay: 0.0500 (0.0500)  time: 2.0214  data: 1.8846  max mem: 2500\n",
      "Epoch: [35]  [ 20/227]  eta: 0:03:52  lr: 0.000082  min_lr: 0.000082  loss: 0.3679 (0.4036)  class_acc: 1.0000 (0.9714)  weight_decay: 0.0500 (0.0500)  time: 0.1333  data: 0.0001  max mem: 2500\n",
      "Epoch: [35]  [ 30/227]  eta: 0:02:38  lr: 0.000082  min_lr: 0.000082  loss: 0.3688 (0.4019)  class_acc: 1.0000 (0.9710)  weight_decay: 0.0500 (0.0500)  time: 0.1340  data: 0.0002  max mem: 2500\n",
      "Epoch: [35]  [ 40/227]  eta: 0:01:59  lr: 0.000081  min_lr: 0.000081  loss: 0.3592 (0.3943)  class_acc: 1.0000 (0.9756)  weight_decay: 0.0500 (0.0500)  time: 0.1354  data: 0.0002  max mem: 2500\n",
      "Epoch: [35]  [ 50/227]  eta: 0:01:35  lr: 0.000081  min_lr: 0.000081  loss: 0.3583 (0.4004)  class_acc: 1.0000 (0.9725)  weight_decay: 0.0500 (0.0500)  time: 0.1346  data: 0.0001  max mem: 2500\n",
      "Epoch: [35]  [ 60/227]  eta: 0:01:19  lr: 0.000081  min_lr: 0.000081  loss: 0.3583 (0.3985)  class_acc: 1.0000 (0.9721)  weight_decay: 0.0500 (0.0500)  time: 0.1339  data: 0.0001  max mem: 2500\n",
      "Epoch: [35]  [ 70/227]  eta: 0:01:06  lr: 0.000080  min_lr: 0.000080  loss: 0.3544 (0.4001)  class_acc: 1.0000 (0.9704)  weight_decay: 0.0500 (0.0500)  time: 0.1339  data: 0.0000  max mem: 2500\n",
      "Epoch: [35]  [ 80/227]  eta: 0:00:57  lr: 0.000080  min_lr: 0.000080  loss: 0.3556 (0.3971)  class_acc: 1.0000 (0.9728)  weight_decay: 0.0500 (0.0500)  time: 0.1330  data: 0.0000  max mem: 2500\n",
      "Epoch: [35]  [ 90/227]  eta: 0:00:49  lr: 0.000079  min_lr: 0.000079  loss: 0.3575 (0.4014)  class_acc: 1.0000 (0.9714)  weight_decay: 0.0500 (0.0500)  time: 0.1327  data: 0.0001  max mem: 2500\n",
      "Epoch: [35]  [100/227]  eta: 0:00:43  lr: 0.000079  min_lr: 0.000079  loss: 0.3964 (0.4066)  class_acc: 1.0000 (0.9703)  weight_decay: 0.0500 (0.0500)  time: 0.1329  data: 0.0001  max mem: 2500\n",
      "Epoch: [35]  [110/227]  eta: 0:00:37  lr: 0.000078  min_lr: 0.000078  loss: 0.3593 (0.4051)  class_acc: 1.0000 (0.9721)  weight_decay: 0.0500 (0.0500)  time: 0.1330  data: 0.0002  max mem: 2500\n",
      "Epoch: [35]  [120/227]  eta: 0:00:32  lr: 0.000078  min_lr: 0.000078  loss: 0.3541 (0.4026)  class_acc: 1.0000 (0.9727)  weight_decay: 0.0500 (0.0500)  time: 0.1331  data: 0.0002  max mem: 2500\n",
      "Epoch: [35]  [130/227]  eta: 0:00:28  lr: 0.000078  min_lr: 0.000078  loss: 0.3686 (0.4053)  class_acc: 1.0000 (0.9718)  weight_decay: 0.0500 (0.0500)  time: 0.1329  data: 0.0002  max mem: 2500\n",
      "Epoch: [35]  [140/227]  eta: 0:00:24  lr: 0.000077  min_lr: 0.000077  loss: 0.3732 (0.4053)  class_acc: 1.0000 (0.9716)  weight_decay: 0.0500 (0.0500)  time: 0.1341  data: 0.0002  max mem: 2500\n",
      "Epoch: [35]  [150/227]  eta: 0:00:20  lr: 0.000077  min_lr: 0.000077  loss: 0.3707 (0.4045)  class_acc: 1.0000 (0.9722)  weight_decay: 0.0500 (0.0500)  time: 0.1341  data: 0.0002  max mem: 2500\n",
      "Epoch: [35]  [160/227]  eta: 0:00:17  lr: 0.000076  min_lr: 0.000076  loss: 0.3627 (0.4041)  class_acc: 1.0000 (0.9720)  weight_decay: 0.0500 (0.0500)  time: 0.1325  data: 0.0002  max mem: 2500\n",
      "Epoch: [35]  [170/227]  eta: 0:00:14  lr: 0.000076  min_lr: 0.000076  loss: 0.3627 (0.4058)  class_acc: 1.0000 (0.9696)  weight_decay: 0.0500 (0.0500)  time: 0.1325  data: 0.0001  max mem: 2500\n",
      "Epoch: [35]  [180/227]  eta: 0:00:11  lr: 0.000075  min_lr: 0.000075  loss: 0.3782 (0.4047)  class_acc: 1.0000 (0.9702)  weight_decay: 0.0500 (0.0500)  time: 0.1347  data: 0.0000  max mem: 2500\n",
      "Epoch: [35]  [190/227]  eta: 0:00:08  lr: 0.000075  min_lr: 0.000075  loss: 0.3542 (0.4065)  class_acc: 1.0000 (0.9696)  weight_decay: 0.0500 (0.0500)  time: 0.1343  data: 0.0000  max mem: 2500\n",
      "Epoch: [35]  [200/227]  eta: 0:00:06  lr: 0.000074  min_lr: 0.000074  loss: 0.3542 (0.4076)  class_acc: 1.0000 (0.9692)  weight_decay: 0.0500 (0.0500)  time: 0.1326  data: 0.0001  max mem: 2500\n",
      "Epoch: [35]  [210/227]  eta: 0:00:03  lr: 0.000074  min_lr: 0.000074  loss: 0.3627 (0.4079)  class_acc: 1.0000 (0.9692)  weight_decay: 0.0500 (0.0500)  time: 0.1335  data: 0.0001  max mem: 2500\n",
      "Epoch: [35]  [220/227]  eta: 0:00:01  lr: 0.000074  min_lr: 0.000074  loss: 0.3863 (0.4106)  class_acc: 1.0000 (0.9683)  weight_decay: 0.0500 (0.0500)  time: 0.1342  data: 0.0001  max mem: 2500\n",
      "Epoch: [35]  [226/227]  eta: 0:00:00  lr: 0.000073  min_lr: 0.000073  loss: 0.3574 (0.4106)  class_acc: 1.0000 (0.9683)  weight_decay: 0.0500 (0.0500)  time: 0.1334  data: 0.0001  max mem: 2500\n",
      "Epoch: [35] Total time: 0:00:51 (0.2274 s / it)\n",
      "Averaged stats: lr: 0.000073  min_lr: 0.000073  loss: 0.3574 (0.4106)  class_acc: 1.0000 (0.9683)  weight_decay: 0.0500 (0.0500)\n",
      "Test:  [ 0/38]  eta: 0:13:06  loss: 0.0799 (0.0799)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 20.6944  data: 20.6374  max mem: 2500\n",
      "Test:  [10/38]  eta: 0:00:53  loss: 0.1048 (0.1438)  acc1: 100.0000 (97.5758)  acc5: 100.0000 (100.0000)  time: 1.9238  data: 1.8762  max mem: 2500\n",
      "Test:  [20/38]  eta: 0:00:18  loss: 0.1281 (0.2478)  acc1: 93.3333 (93.6508)  acc5: 100.0000 (100.0000)  time: 0.0467  data: 0.0001  max mem: 2500\n",
      "Test:  [30/38]  eta: 0:00:05  loss: 0.0922 (0.1955)  acc1: 100.0000 (95.6989)  acc5: 100.0000 (100.0000)  time: 0.0467  data: 0.0001  max mem: 2500\n",
      "Test:  [37/38]  eta: 0:00:00  loss: 0.0916 (0.1817)  acc1: 100.0000 (96.2500)  acc5: 100.0000 (100.0000)  time: 0.0451  data: 0.0000  max mem: 2500\n",
      "Test: Total time: 0:00:22 (0.6026 s / it)\n",
      "* Acc@1 96.250 Acc@5 100.000 loss 0.182\n",
      "[[136   3   0   1]\n",
      " [ 12 124   1   3]\n",
      " [  0   0 140   0]\n",
      " [  0   0   1 139]]\n",
      "(4, 4)\n",
      "Accuracy of the model on the 560 test images: 96.3%\n",
      "Max accuracy: 96.25%\n",
      "Epoch: [36]  [  0/227]  eta: 1:18:27  lr: 0.000073  min_lr: 0.000073  loss: 0.3720 (0.3720)  class_acc: 1.0000 (1.0000)  weight_decay: 0.0500 (0.0500)  time: 20.7377  data: 20.5867  max mem: 2500\n",
      "Epoch: [36]  [ 10/227]  eta: 0:07:15  lr: 0.000073  min_lr: 0.000073  loss: 0.3683 (0.4012)  class_acc: 1.0000 (0.9818)  weight_decay: 0.0500 (0.0500)  time: 2.0077  data: 1.8716  max mem: 2500\n",
      "Epoch: [36]  [ 20/227]  eta: 0:03:50  lr: 0.000072  min_lr: 0.000072  loss: 0.3619 (0.4004)  class_acc: 1.0000 (0.9762)  weight_decay: 0.0500 (0.0500)  time: 0.1344  data: 0.0002  max mem: 2500\n",
      "Epoch: [36]  [ 30/227]  eta: 0:02:37  lr: 0.000072  min_lr: 0.000072  loss: 0.3685 (0.4181)  class_acc: 1.0000 (0.9645)  weight_decay: 0.0500 (0.0500)  time: 0.1346  data: 0.0001  max mem: 2500\n",
      "Epoch: [36]  [ 40/227]  eta: 0:01:59  lr: 0.000072  min_lr: 0.000072  loss: 0.3685 (0.4139)  class_acc: 1.0000 (0.9659)  weight_decay: 0.0500 (0.0500)  time: 0.1344  data: 0.0001  max mem: 2500\n",
      "Epoch: [36]  [ 50/227]  eta: 0:01:35  lr: 0.000071  min_lr: 0.000071  loss: 0.3614 (0.4086)  class_acc: 1.0000 (0.9686)  weight_decay: 0.0500 (0.0500)  time: 0.1349  data: 0.0002  max mem: 2500\n",
      "Epoch: [36]  [ 60/227]  eta: 0:01:18  lr: 0.000071  min_lr: 0.000071  loss: 0.3545 (0.4088)  class_acc: 1.0000 (0.9689)  weight_decay: 0.0500 (0.0500)  time: 0.1350  data: 0.0002  max mem: 2500\n",
      "Epoch: [36]  [ 70/227]  eta: 0:01:06  lr: 0.000070  min_lr: 0.000070  loss: 0.3691 (0.4123)  class_acc: 1.0000 (0.9662)  weight_decay: 0.0500 (0.0500)  time: 0.1338  data: 0.0002  max mem: 2500\n",
      "Epoch: [36]  [ 80/227]  eta: 0:00:57  lr: 0.000070  min_lr: 0.000070  loss: 0.3980 (0.4132)  class_acc: 1.0000 (0.9654)  weight_decay: 0.0500 (0.0500)  time: 0.1346  data: 0.0002  max mem: 2500\n",
      "Epoch: [36]  [ 90/227]  eta: 0:00:49  lr: 0.000070  min_lr: 0.000070  loss: 0.3741 (0.4130)  class_acc: 1.0000 (0.9648)  weight_decay: 0.0500 (0.0500)  time: 0.1361  data: 0.0001  max mem: 2500\n",
      "Epoch: [36]  [100/227]  eta: 0:00:43  lr: 0.000069  min_lr: 0.000069  loss: 0.3741 (0.4108)  class_acc: 1.0000 (0.9653)  weight_decay: 0.0500 (0.0500)  time: 0.1347  data: 0.0001  max mem: 2500\n",
      "Epoch: [36]  [110/227]  eta: 0:00:37  lr: 0.000069  min_lr: 0.000069  loss: 0.3587 (0.4113)  class_acc: 1.0000 (0.9658)  weight_decay: 0.0500 (0.0500)  time: 0.1325  data: 0.0001  max mem: 2500\n",
      "Epoch: [36]  [120/227]  eta: 0:00:32  lr: 0.000068  min_lr: 0.000068  loss: 0.3535 (0.4124)  class_acc: 1.0000 (0.9653)  weight_decay: 0.0500 (0.0500)  time: 0.1324  data: 0.0001  max mem: 2500\n",
      "Epoch: [36]  [130/227]  eta: 0:00:28  lr: 0.000068  min_lr: 0.000068  loss: 0.3520 (0.4113)  class_acc: 1.0000 (0.9664)  weight_decay: 0.0500 (0.0500)  time: 0.1322  data: 0.0001  max mem: 2500\n",
      "Epoch: [36]  [140/227]  eta: 0:00:24  lr: 0.000067  min_lr: 0.000067  loss: 0.3570 (0.4107)  class_acc: 1.0000 (0.9674)  weight_decay: 0.0500 (0.0500)  time: 0.1322  data: 0.0001  max mem: 2500\n",
      "Epoch: [36]  [150/227]  eta: 0:00:20  lr: 0.000067  min_lr: 0.000067  loss: 0.3570 (0.4095)  class_acc: 1.0000 (0.9669)  weight_decay: 0.0500 (0.0500)  time: 0.1330  data: 0.0001  max mem: 2500\n",
      "Epoch: [36]  [160/227]  eta: 0:00:17  lr: 0.000067  min_lr: 0.000067  loss: 0.3550 (0.4073)  class_acc: 1.0000 (0.9683)  weight_decay: 0.0500 (0.0500)  time: 0.1332  data: 0.0001  max mem: 2500\n",
      "Epoch: [36]  [170/227]  eta: 0:00:14  lr: 0.000066  min_lr: 0.000066  loss: 0.3657 (0.4093)  class_acc: 1.0000 (0.9661)  weight_decay: 0.0500 (0.0500)  time: 0.1330  data: 0.0001  max mem: 2500\n",
      "Epoch: [36]  [180/227]  eta: 0:00:11  lr: 0.000066  min_lr: 0.000066  loss: 0.3631 (0.4066)  class_acc: 1.0000 (0.9680)  weight_decay: 0.0500 (0.0500)  time: 0.1340  data: 0.0003  max mem: 2500\n",
      "Epoch: [36]  [190/227]  eta: 0:00:08  lr: 0.000065  min_lr: 0.000065  loss: 0.3544 (0.4057)  class_acc: 1.0000 (0.9686)  weight_decay: 0.0500 (0.0500)  time: 0.1341  data: 0.0002  max mem: 2500\n",
      "Epoch: [36]  [200/227]  eta: 0:00:06  lr: 0.000065  min_lr: 0.000065  loss: 0.3567 (0.4076)  class_acc: 1.0000 (0.9672)  weight_decay: 0.0500 (0.0500)  time: 0.1343  data: 0.0000  max mem: 2500\n",
      "Epoch: [36]  [210/227]  eta: 0:00:03  lr: 0.000065  min_lr: 0.000065  loss: 0.3595 (0.4061)  class_acc: 1.0000 (0.9678)  weight_decay: 0.0500 (0.0500)  time: 0.1347  data: 0.0000  max mem: 2500\n",
      "Epoch: [36]  [220/227]  eta: 0:00:01  lr: 0.000064  min_lr: 0.000064  loss: 0.3559 (0.4042)  class_acc: 1.0000 (0.9688)  weight_decay: 0.0500 (0.0500)  time: 0.1333  data: 0.0000  max mem: 2500\n",
      "Epoch: [36]  [226/227]  eta: 0:00:00  lr: 0.000064  min_lr: 0.000064  loss: 0.3528 (0.4030)  class_acc: 1.0000 (0.9696)  weight_decay: 0.0500 (0.0500)  time: 0.1323  data: 0.0000  max mem: 2500\n",
      "Epoch: [36] Total time: 0:00:51 (0.2269 s / it)\n",
      "Averaged stats: lr: 0.000064  min_lr: 0.000064  loss: 0.3528 (0.4030)  class_acc: 1.0000 (0.9696)  weight_decay: 0.0500 (0.0500)\n",
      "Test:  [ 0/38]  eta: 0:13:06  loss: 0.0747 (0.0747)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 20.7093  data: 20.6523  max mem: 2500\n",
      "Test:  [10/38]  eta: 0:00:53  loss: 0.1068 (0.1305)  acc1: 100.0000 (96.9697)  acc5: 100.0000 (100.0000)  time: 1.9250  data: 1.8776  max mem: 2500\n",
      "Test:  [20/38]  eta: 0:00:18  loss: 0.1490 (0.2766)  acc1: 93.3333 (91.4286)  acc5: 100.0000 (100.0000)  time: 0.0467  data: 0.0001  max mem: 2500\n",
      "Test:  [30/38]  eta: 0:00:05  loss: 0.0786 (0.2127)  acc1: 100.0000 (94.1936)  acc5: 100.0000 (100.0000)  time: 0.0466  data: 0.0001  max mem: 2500\n",
      "Test:  [37/38]  eta: 0:00:00  loss: 0.0783 (0.1892)  acc1: 100.0000 (95.1786)  acc5: 100.0000 (100.0000)  time: 0.0450  data: 0.0001  max mem: 2500\n",
      "Test: Total time: 0:00:22 (0.6030 s / it)\n",
      "* Acc@1 95.179 Acc@5 100.000 loss 0.189\n",
      "[[135   2   0   3]\n",
      " [ 16 118   2   4]\n",
      " [  0   0 140   0]\n",
      " [  0   0   0 140]]\n",
      "(4, 4)\n",
      "Accuracy of the model on the 560 test images: 95.2%\n",
      "Max accuracy: 96.25%\n",
      "Epoch: [37]  [  0/227]  eta: 1:18:56  lr: 0.000064  min_lr: 0.000064  loss: 0.4385 (0.4385)  class_acc: 0.9000 (0.9000)  weight_decay: 0.0500 (0.0500)  time: 20.8660  data: 20.7220  max mem: 2500\n",
      "Epoch: [37]  [ 10/227]  eta: 0:07:18  lr: 0.000064  min_lr: 0.000064  loss: 0.3518 (0.3958)  class_acc: 1.0000 (0.9727)  weight_decay: 0.0500 (0.0500)  time: 2.0186  data: 1.8839  max mem: 2500\n",
      "Epoch: [37]  [ 20/227]  eta: 0:03:52  lr: 0.000063  min_lr: 0.000063  loss: 0.3563 (0.4005)  class_acc: 1.0000 (0.9714)  weight_decay: 0.0500 (0.0500)  time: 0.1338  data: 0.0001  max mem: 2500\n",
      "Epoch: [37]  [ 30/227]  eta: 0:02:38  lr: 0.000063  min_lr: 0.000063  loss: 0.3660 (0.4016)  class_acc: 1.0000 (0.9677)  weight_decay: 0.0500 (0.0500)  time: 0.1335  data: 0.0002  max mem: 2500\n",
      "Epoch: [37]  [ 40/227]  eta: 0:01:59  lr: 0.000062  min_lr: 0.000062  loss: 0.3545 (0.3907)  class_acc: 1.0000 (0.9756)  weight_decay: 0.0500 (0.0500)  time: 0.1334  data: 0.0002  max mem: 2500\n",
      "Epoch: [37]  [ 50/227]  eta: 0:01:35  lr: 0.000062  min_lr: 0.000062  loss: 0.3522 (0.3918)  class_acc: 1.0000 (0.9745)  weight_decay: 0.0500 (0.0500)  time: 0.1337  data: 0.0002  max mem: 2500\n",
      "Epoch: [37]  [ 60/227]  eta: 0:01:19  lr: 0.000062  min_lr: 0.000062  loss: 0.3585 (0.3979)  class_acc: 1.0000 (0.9705)  weight_decay: 0.0500 (0.0500)  time: 0.1338  data: 0.0002  max mem: 2500\n",
      "Epoch: [37]  [ 70/227]  eta: 0:01:06  lr: 0.000061  min_lr: 0.000061  loss: 0.3780 (0.3972)  class_acc: 1.0000 (0.9718)  weight_decay: 0.0500 (0.0500)  time: 0.1348  data: 0.0001  max mem: 2500\n",
      "Epoch: [37]  [ 80/227]  eta: 0:00:57  lr: 0.000061  min_lr: 0.000061  loss: 0.3688 (0.4021)  class_acc: 1.0000 (0.9691)  weight_decay: 0.0500 (0.0500)  time: 0.1340  data: 0.0000  max mem: 2500\n",
      "Epoch: [37]  [ 90/227]  eta: 0:00:49  lr: 0.000060  min_lr: 0.000060  loss: 0.3688 (0.4048)  class_acc: 1.0000 (0.9681)  weight_decay: 0.0500 (0.0500)  time: 0.1340  data: 0.0001  max mem: 2500\n",
      "Epoch: [37]  [100/227]  eta: 0:00:43  lr: 0.000060  min_lr: 0.000060  loss: 0.3607 (0.4063)  class_acc: 1.0000 (0.9663)  weight_decay: 0.0500 (0.0500)  time: 0.1349  data: 0.0002  max mem: 2500\n",
      "Epoch: [37]  [110/227]  eta: 0:00:37  lr: 0.000060  min_lr: 0.000060  loss: 0.3556 (0.4033)  class_acc: 1.0000 (0.9694)  weight_decay: 0.0500 (0.0500)  time: 0.1347  data: 0.0002  max mem: 2500\n",
      "Epoch: [37]  [120/227]  eta: 0:00:32  lr: 0.000059  min_lr: 0.000059  loss: 0.3646 (0.4029)  class_acc: 1.0000 (0.9686)  weight_decay: 0.0500 (0.0500)  time: 0.1345  data: 0.0002  max mem: 2500\n",
      "Epoch: [37]  [130/227]  eta: 0:00:28  lr: 0.000059  min_lr: 0.000059  loss: 0.3697 (0.4020)  class_acc: 1.0000 (0.9702)  weight_decay: 0.0500 (0.0500)  time: 0.1335  data: 0.0001  max mem: 2500\n",
      "Epoch: [37]  [140/227]  eta: 0:00:24  lr: 0.000058  min_lr: 0.000058  loss: 0.3568 (0.4015)  class_acc: 1.0000 (0.9702)  weight_decay: 0.0500 (0.0500)  time: 0.1343  data: 0.0002  max mem: 2500\n",
      "Epoch: [37]  [150/227]  eta: 0:00:20  lr: 0.000058  min_lr: 0.000058  loss: 0.4143 (0.4070)  class_acc: 1.0000 (0.9682)  weight_decay: 0.0500 (0.0500)  time: 0.1348  data: 0.0004  max mem: 2500\n",
      "Epoch: [37]  [160/227]  eta: 0:00:17  lr: 0.000058  min_lr: 0.000058  loss: 0.3690 (0.4067)  class_acc: 1.0000 (0.9689)  weight_decay: 0.0500 (0.0500)  time: 0.1333  data: 0.0003  max mem: 2500\n",
      "Epoch: [37]  [170/227]  eta: 0:00:14  lr: 0.000057  min_lr: 0.000057  loss: 0.3797 (0.4081)  class_acc: 1.0000 (0.9667)  weight_decay: 0.0500 (0.0500)  time: 0.1327  data: 0.0000  max mem: 2500\n",
      "Epoch: [37]  [180/227]  eta: 0:00:11  lr: 0.000057  min_lr: 0.000057  loss: 0.3566 (0.4055)  class_acc: 1.0000 (0.9685)  weight_decay: 0.0500 (0.0500)  time: 0.1336  data: 0.0001  max mem: 2500\n",
      "Epoch: [37]  [190/227]  eta: 0:00:08  lr: 0.000056  min_lr: 0.000056  loss: 0.3547 (0.4049)  class_acc: 1.0000 (0.9681)  weight_decay: 0.0500 (0.0500)  time: 0.1347  data: 0.0002  max mem: 2500\n",
      "Epoch: [37]  [200/227]  eta: 0:00:06  lr: 0.000056  min_lr: 0.000056  loss: 0.3643 (0.4043)  class_acc: 1.0000 (0.9687)  weight_decay: 0.0500 (0.0500)  time: 0.1336  data: 0.0004  max mem: 2500\n",
      "Epoch: [37]  [210/227]  eta: 0:00:03  lr: 0.000056  min_lr: 0.000056  loss: 0.3587 (0.4034)  class_acc: 1.0000 (0.9697)  weight_decay: 0.0500 (0.0500)  time: 0.1337  data: 0.0003  max mem: 2500\n",
      "Epoch: [37]  [220/227]  eta: 0:00:01  lr: 0.000055  min_lr: 0.000055  loss: 0.3528 (0.4026)  class_acc: 1.0000 (0.9697)  weight_decay: 0.0500 (0.0500)  time: 0.1346  data: 0.0002  max mem: 2500\n",
      "Epoch: [37]  [226/227]  eta: 0:00:00  lr: 0.000055  min_lr: 0.000055  loss: 0.3516 (0.4012)  class_acc: 1.0000 (0.9705)  weight_decay: 0.0500 (0.0500)  time: 0.1332  data: 0.0002  max mem: 2500\n",
      "Epoch: [37] Total time: 0:00:51 (0.2275 s / it)\n",
      "Averaged stats: lr: 0.000055  min_lr: 0.000055  loss: 0.3516 (0.4012)  class_acc: 1.0000 (0.9705)  weight_decay: 0.0500 (0.0500)\n",
      "Test:  [ 0/38]  eta: 0:13:17  loss: 0.0819 (0.0819)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 20.9845  data: 20.9305  max mem: 2500\n",
      "Test:  [10/38]  eta: 0:00:54  loss: 0.1215 (0.1468)  acc1: 93.3333 (96.3636)  acc5: 100.0000 (100.0000)  time: 1.9527  data: 1.9028  max mem: 2500\n",
      "Test:  [20/38]  eta: 0:00:18  loss: 0.1327 (0.2087)  acc1: 93.3333 (93.9683)  acc5: 100.0000 (100.0000)  time: 0.0505  data: 0.0000  max mem: 2500\n",
      "Test:  [30/38]  eta: 0:00:05  loss: 0.0765 (0.1660)  acc1: 100.0000 (95.9140)  acc5: 100.0000 (100.0000)  time: 0.0498  data: 0.0002  max mem: 2500\n",
      "Test:  [37/38]  eta: 0:00:00  loss: 0.0758 (0.1500)  acc1: 100.0000 (96.6071)  acc5: 100.0000 (100.0000)  time: 0.0466  data: 0.0001  max mem: 2500\n",
      "Test: Total time: 0:00:23 (0.6133 s / it)\n",
      "* Acc@1 96.607 Acc@5 100.000 loss 0.150\n",
      "[[134   3   0   3]\n",
      " [  9 127   1   3]\n",
      " [  0   0 140   0]\n",
      " [  0   0   0 140]]\n",
      "(4, 4)\n",
      "Accuracy of the model on the 560 test images: 96.6%\n",
      "Max accuracy: 96.61%\n",
      "Epoch: [38]  [  0/227]  eta: 1:19:42  lr: 0.000055  min_lr: 0.000055  loss: 0.3524 (0.3524)  class_acc: 1.0000 (1.0000)  weight_decay: 0.0500 (0.0500)  time: 21.0661  data: 20.9151  max mem: 2500\n",
      "Epoch: [38]  [ 10/227]  eta: 0:07:22  lr: 0.000055  min_lr: 0.000055  loss: 0.3532 (0.3752)  class_acc: 1.0000 (0.9909)  weight_decay: 0.0500 (0.0500)  time: 2.0405  data: 1.9016  max mem: 2500\n",
      "Epoch: [38]  [ 20/227]  eta: 0:03:54  lr: 0.000054  min_lr: 0.000054  loss: 0.3576 (0.3897)  class_acc: 1.0000 (0.9810)  weight_decay: 0.0500 (0.0500)  time: 0.1363  data: 0.0003  max mem: 2500\n",
      "Epoch: [38]  [ 30/227]  eta: 0:02:39  lr: 0.000054  min_lr: 0.000054  loss: 0.3576 (0.3838)  class_acc: 1.0000 (0.9839)  weight_decay: 0.0500 (0.0500)  time: 0.1350  data: 0.0003  max mem: 2500\n",
      "Epoch: [38]  [ 40/227]  eta: 0:02:00  lr: 0.000054  min_lr: 0.000054  loss: 0.3530 (0.3883)  class_acc: 1.0000 (0.9780)  weight_decay: 0.0500 (0.0500)  time: 0.1359  data: 0.0002  max mem: 2500\n",
      "Epoch: [38]  [ 50/227]  eta: 0:01:36  lr: 0.000053  min_lr: 0.000053  loss: 0.3510 (0.3812)  class_acc: 1.0000 (0.9824)  weight_decay: 0.0500 (0.0500)  time: 0.1382  data: 0.0001  max mem: 2500\n",
      "Epoch: [38]  [ 60/227]  eta: 0:01:20  lr: 0.000053  min_lr: 0.000053  loss: 0.3510 (0.3857)  class_acc: 1.0000 (0.9787)  weight_decay: 0.0500 (0.0500)  time: 0.1426  data: 0.0003  max mem: 2500\n",
      "Epoch: [38]  [ 70/227]  eta: 0:01:08  lr: 0.000052  min_lr: 0.000052  loss: 0.3519 (0.3888)  class_acc: 1.0000 (0.9775)  weight_decay: 0.0500 (0.0500)  time: 0.1438  data: 0.0002  max mem: 2500\n",
      "Epoch: [38]  [ 80/227]  eta: 0:00:58  lr: 0.000052  min_lr: 0.000052  loss: 0.3505 (0.3888)  class_acc: 1.0000 (0.9778)  weight_decay: 0.0500 (0.0500)  time: 0.1385  data: 0.0001  max mem: 2500\n",
      "Epoch: [38]  [ 90/227]  eta: 0:00:50  lr: 0.000052  min_lr: 0.000052  loss: 0.3626 (0.3923)  class_acc: 1.0000 (0.9758)  weight_decay: 0.0500 (0.0500)  time: 0.1361  data: 0.0002  max mem: 2500\n",
      "Epoch: [38]  [100/227]  eta: 0:00:43  lr: 0.000051  min_lr: 0.000051  loss: 0.3625 (0.3954)  class_acc: 1.0000 (0.9733)  weight_decay: 0.0500 (0.0500)  time: 0.1362  data: 0.0001  max mem: 2500\n",
      "Epoch: [38]  [110/227]  eta: 0:00:38  lr: 0.000051  min_lr: 0.000051  loss: 0.3553 (0.3969)  class_acc: 1.0000 (0.9730)  weight_decay: 0.0500 (0.0500)  time: 0.1361  data: 0.0002  max mem: 2500\n",
      "Epoch: [38]  [120/227]  eta: 0:00:33  lr: 0.000051  min_lr: 0.000051  loss: 0.3553 (0.3980)  class_acc: 1.0000 (0.9736)  weight_decay: 0.0500 (0.0500)  time: 0.1367  data: 0.0003  max mem: 2500\n",
      "Epoch: [38]  [130/227]  eta: 0:00:28  lr: 0.000050  min_lr: 0.000050  loss: 0.3549 (0.3969)  class_acc: 1.0000 (0.9748)  weight_decay: 0.0500 (0.0500)  time: 0.1366  data: 0.0002  max mem: 2500\n",
      "Epoch: [38]  [140/227]  eta: 0:00:24  lr: 0.000050  min_lr: 0.000050  loss: 0.3548 (0.3971)  class_acc: 1.0000 (0.9752)  weight_decay: 0.0500 (0.0500)  time: 0.1362  data: 0.0002  max mem: 2500\n",
      "Epoch: [38]  [150/227]  eta: 0:00:21  lr: 0.000050  min_lr: 0.000050  loss: 0.3568 (0.3998)  class_acc: 1.0000 (0.9748)  weight_decay: 0.0500 (0.0500)  time: 0.1376  data: 0.0001  max mem: 2500\n",
      "Epoch: [38]  [160/227]  eta: 0:00:17  lr: 0.000049  min_lr: 0.000049  loss: 0.3596 (0.4007)  class_acc: 1.0000 (0.9739)  weight_decay: 0.0500 (0.0500)  time: 0.1389  data: 0.0001  max mem: 2500\n",
      "Epoch: [38]  [170/227]  eta: 0:00:14  lr: 0.000049  min_lr: 0.000049  loss: 0.3701 (0.4007)  class_acc: 1.0000 (0.9743)  weight_decay: 0.0500 (0.0500)  time: 0.1375  data: 0.0001  max mem: 2500\n",
      "Epoch: [38]  [180/227]  eta: 0:00:11  lr: 0.000048  min_lr: 0.000048  loss: 0.3704 (0.3996)  class_acc: 1.0000 (0.9746)  weight_decay: 0.0500 (0.0500)  time: 0.1371  data: 0.0001  max mem: 2500\n",
      "Epoch: [38]  [190/227]  eta: 0:00:09  lr: 0.000048  min_lr: 0.000048  loss: 0.3690 (0.3993)  class_acc: 1.0000 (0.9743)  weight_decay: 0.0500 (0.0500)  time: 0.1379  data: 0.0001  max mem: 2500\n",
      "Epoch: [38]  [200/227]  eta: 0:00:06  lr: 0.000048  min_lr: 0.000048  loss: 0.3626 (0.3991)  class_acc: 1.0000 (0.9741)  weight_decay: 0.0500 (0.0500)  time: 0.1369  data: 0.0001  max mem: 2500\n",
      "Epoch: [38]  [210/227]  eta: 0:00:04  lr: 0.000047  min_lr: 0.000047  loss: 0.3655 (0.3992)  class_acc: 1.0000 (0.9735)  weight_decay: 0.0500 (0.0500)  time: 0.1356  data: 0.0003  max mem: 2500\n",
      "Epoch: [38]  [220/227]  eta: 0:00:01  lr: 0.000047  min_lr: 0.000047  loss: 0.3538 (0.3984)  class_acc: 1.0000 (0.9738)  weight_decay: 0.0500 (0.0500)  time: 0.1352  data: 0.0004  max mem: 2500\n",
      "Epoch: [38]  [226/227]  eta: 0:00:00  lr: 0.000047  min_lr: 0.000047  loss: 0.3527 (0.3974)  class_acc: 1.0000 (0.9744)  weight_decay: 0.0500 (0.0500)  time: 0.1355  data: 0.0003  max mem: 2500\n",
      "Epoch: [38] Total time: 0:00:52 (0.2319 s / it)\n",
      "Averaged stats: lr: 0.000047  min_lr: 0.000047  loss: 0.3527 (0.3974)  class_acc: 1.0000 (0.9744)  weight_decay: 0.0500 (0.0500)\n",
      "Test:  [ 0/38]  eta: 0:13:15  loss: 0.0853 (0.0853)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 20.9239  data: 20.8669  max mem: 2500\n",
      "Test:  [10/38]  eta: 0:00:54  loss: 0.1449 (0.1689)  acc1: 93.3333 (96.3636)  acc5: 100.0000 (100.0000)  time: 1.9446  data: 1.8970  max mem: 2500\n",
      "Test:  [20/38]  eta: 0:00:18  loss: 0.1514 (0.2370)  acc1: 93.3333 (94.2857)  acc5: 100.0000 (100.0000)  time: 0.0467  data: 0.0001  max mem: 2500\n",
      "Test:  [30/38]  eta: 0:00:05  loss: 0.0760 (0.1850)  acc1: 100.0000 (96.1290)  acc5: 100.0000 (100.0000)  time: 0.0465  data: 0.0001  max mem: 2500\n",
      "Test:  [37/38]  eta: 0:00:00  loss: 0.0760 (0.1666)  acc1: 100.0000 (96.6071)  acc5: 100.0000 (100.0000)  time: 0.0449  data: 0.0000  max mem: 2500\n",
      "Test: Total time: 0:00:23 (0.6083 s / it)\n",
      "* Acc@1 96.607 Acc@5 100.000 loss 0.167\n",
      "[[134   2   0   4]\n",
      " [  6 128   3   3]\n",
      " [  0   0 140   0]\n",
      " [  0   0   1 139]]\n",
      "(4, 4)\n",
      "Accuracy of the model on the 560 test images: 96.6%\n",
      "Max accuracy: 96.61%\n",
      "Epoch: [39]  [  0/227]  eta: 1:19:31  lr: 0.000047  min_lr: 0.000047  loss: 0.3667 (0.3667)  class_acc: 1.0000 (1.0000)  weight_decay: 0.0500 (0.0500)  time: 21.0199  data: 20.8728  max mem: 2500\n",
      "Epoch: [39]  [ 10/227]  eta: 0:07:21  lr: 0.000046  min_lr: 0.000046  loss: 0.3524 (0.3869)  class_acc: 1.0000 (0.9727)  weight_decay: 0.0500 (0.0500)  time: 2.0333  data: 1.8977  max mem: 2500\n",
      "Epoch: [39]  [ 20/227]  eta: 0:03:54  lr: 0.000046  min_lr: 0.000046  loss: 0.3514 (0.3897)  class_acc: 1.0000 (0.9714)  weight_decay: 0.0500 (0.0500)  time: 0.1362  data: 0.0002  max mem: 2500\n",
      "Epoch: [39]  [ 30/227]  eta: 0:02:39  lr: 0.000046  min_lr: 0.000046  loss: 0.3511 (0.4015)  class_acc: 1.0000 (0.9710)  weight_decay: 0.0500 (0.0500)  time: 0.1360  data: 0.0001  max mem: 2500\n",
      "Epoch: [39]  [ 40/227]  eta: 0:02:00  lr: 0.000045  min_lr: 0.000045  loss: 0.3518 (0.3937)  class_acc: 1.0000 (0.9756)  weight_decay: 0.0500 (0.0500)  time: 0.1346  data: 0.0001  max mem: 2500\n",
      "Epoch: [39]  [ 50/227]  eta: 0:01:36  lr: 0.000045  min_lr: 0.000045  loss: 0.3518 (0.3915)  class_acc: 1.0000 (0.9765)  weight_decay: 0.0500 (0.0500)  time: 0.1365  data: 0.0000  max mem: 2500\n",
      "Epoch: [39]  [ 60/227]  eta: 0:01:19  lr: 0.000045  min_lr: 0.000045  loss: 0.3516 (0.3908)  class_acc: 1.0000 (0.9770)  weight_decay: 0.0500 (0.0500)  time: 0.1360  data: 0.0001  max mem: 2500\n",
      "Epoch: [39]  [ 70/227]  eta: 0:01:07  lr: 0.000044  min_lr: 0.000044  loss: 0.3531 (0.3902)  class_acc: 1.0000 (0.9761)  weight_decay: 0.0500 (0.0500)  time: 0.1347  data: 0.0001  max mem: 2500\n",
      "Epoch: [39]  [ 80/227]  eta: 0:00:57  lr: 0.000044  min_lr: 0.000044  loss: 0.3580 (0.3882)  class_acc: 1.0000 (0.9778)  weight_decay: 0.0500 (0.0500)  time: 0.1342  data: 0.0001  max mem: 2500\n",
      "Epoch: [39]  [ 90/227]  eta: 0:00:49  lr: 0.000044  min_lr: 0.000044  loss: 0.3544 (0.3906)  class_acc: 1.0000 (0.9747)  weight_decay: 0.0500 (0.0500)  time: 0.1336  data: 0.0002  max mem: 2500\n",
      "Epoch: [39]  [100/227]  eta: 0:00:43  lr: 0.000043  min_lr: 0.000043  loss: 0.3566 (0.3914)  class_acc: 1.0000 (0.9752)  weight_decay: 0.0500 (0.0500)  time: 0.1340  data: 0.0003  max mem: 2500\n",
      "Epoch: [39]  [110/227]  eta: 0:00:37  lr: 0.000043  min_lr: 0.000043  loss: 0.3514 (0.3882)  class_acc: 1.0000 (0.9775)  weight_decay: 0.0500 (0.0500)  time: 0.1343  data: 0.0003  max mem: 2500\n",
      "Epoch: [39]  [120/227]  eta: 0:00:32  lr: 0.000043  min_lr: 0.000043  loss: 0.3499 (0.3915)  class_acc: 1.0000 (0.9760)  weight_decay: 0.0500 (0.0500)  time: 0.1333  data: 0.0001  max mem: 2500\n",
      "Epoch: [39]  [130/227]  eta: 0:00:28  lr: 0.000042  min_lr: 0.000042  loss: 0.3580 (0.3914)  class_acc: 1.0000 (0.9763)  weight_decay: 0.0500 (0.0500)  time: 0.1320  data: 0.0001  max mem: 2500\n",
      "Epoch: [39]  [140/227]  eta: 0:00:24  lr: 0.000042  min_lr: 0.000042  loss: 0.3593 (0.3924)  class_acc: 1.0000 (0.9752)  weight_decay: 0.0500 (0.0500)  time: 0.1324  data: 0.0001  max mem: 2500\n",
      "Epoch: [39]  [150/227]  eta: 0:00:20  lr: 0.000042  min_lr: 0.000042  loss: 0.3636 (0.3969)  class_acc: 1.0000 (0.9728)  weight_decay: 0.0500 (0.0500)  time: 0.1334  data: 0.0001  max mem: 2500\n",
      "Epoch: [39]  [160/227]  eta: 0:00:17  lr: 0.000041  min_lr: 0.000041  loss: 0.3663 (0.3963)  class_acc: 1.0000 (0.9733)  weight_decay: 0.0500 (0.0500)  time: 0.1351  data: 0.0002  max mem: 2500\n",
      "Epoch: [39]  [170/227]  eta: 0:00:14  lr: 0.000041  min_lr: 0.000041  loss: 0.3616 (0.3950)  class_acc: 1.0000 (0.9743)  weight_decay: 0.0500 (0.0500)  time: 0.1345  data: 0.0001  max mem: 2500\n",
      "Epoch: [39]  [180/227]  eta: 0:00:11  lr: 0.000041  min_lr: 0.000041  loss: 0.3616 (0.3959)  class_acc: 1.0000 (0.9729)  weight_decay: 0.0500 (0.0500)  time: 0.1365  data: 0.0001  max mem: 2500\n",
      "Epoch: [39]  [190/227]  eta: 0:00:09  lr: 0.000040  min_lr: 0.000040  loss: 0.3530 (0.3953)  class_acc: 1.0000 (0.9733)  weight_decay: 0.0500 (0.0500)  time: 0.1451  data: 0.0002  max mem: 2500\n",
      "Epoch: [39]  [200/227]  eta: 0:00:06  lr: 0.000040  min_lr: 0.000040  loss: 0.3530 (0.3943)  class_acc: 1.0000 (0.9741)  weight_decay: 0.0500 (0.0500)  time: 0.1529  data: 0.0002  max mem: 2500\n",
      "Epoch: [39]  [210/227]  eta: 0:00:04  lr: 0.000040  min_lr: 0.000040  loss: 0.3595 (0.3942)  class_acc: 1.0000 (0.9744)  weight_decay: 0.0500 (0.0500)  time: 0.1539  data: 0.0001  max mem: 2500\n",
      "Epoch: [39]  [220/227]  eta: 0:00:01  lr: 0.000039  min_lr: 0.000039  loss: 0.3535 (0.3936)  class_acc: 1.0000 (0.9747)  weight_decay: 0.0500 (0.0500)  time: 0.1522  data: 0.0000  max mem: 2500\n",
      "Epoch: [39]  [226/227]  eta: 0:00:00  lr: 0.000039  min_lr: 0.000039  loss: 0.3534 (0.3940)  class_acc: 1.0000 (0.9744)  weight_decay: 0.0500 (0.0500)  time: 0.1521  data: 0.0000  max mem: 2500\n",
      "Epoch: [39] Total time: 0:00:52 (0.2328 s / it)\n",
      "Averaged stats: lr: 0.000039  min_lr: 0.000039  loss: 0.3534 (0.3940)  class_acc: 1.0000 (0.9744)  weight_decay: 0.0500 (0.0500)\n",
      "Test:  [ 0/38]  eta: 0:13:16  loss: 0.0751 (0.0751)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 20.9596  data: 20.9015  max mem: 2500\n",
      "Test:  [10/38]  eta: 0:00:54  loss: 0.0833 (0.1107)  acc1: 100.0000 (98.7879)  acc5: 100.0000 (100.0000)  time: 1.9480  data: 1.9001  max mem: 2500\n",
      "Test:  [20/38]  eta: 0:00:18  loss: 0.1141 (0.3073)  acc1: 93.3333 (90.1587)  acc5: 100.0000 (100.0000)  time: 0.0468  data: 0.0001  max mem: 2500\n",
      "Test:  [30/38]  eta: 0:00:05  loss: 0.0787 (0.2330)  acc1: 100.0000 (93.3333)  acc5: 100.0000 (100.0000)  time: 0.0467  data: 0.0001  max mem: 2500\n",
      "Test:  [37/38]  eta: 0:00:00  loss: 0.0787 (0.2060)  acc1: 100.0000 (94.4643)  acc5: 100.0000 (100.0000)  time: 0.0451  data: 0.0001  max mem: 2500\n",
      "Test: Total time: 0:00:23 (0.6095 s / it)\n",
      "* Acc@1 94.464 Acc@5 100.000 loss 0.206\n",
      "[[138   0   0   2]\n",
      " [ 25 111   1   3]\n",
      " [  0   0 140   0]\n",
      " [  0   0   0 140]]\n",
      "(4, 4)\n",
      "Accuracy of the model on the 560 test images: 94.5%\n",
      "Max accuracy: 96.61%\n",
      "Epoch: [40]  [  0/227]  eta: 1:18:33  lr: 0.000039  min_lr: 0.000039  loss: 0.3980 (0.3980)  class_acc: 1.0000 (1.0000)  weight_decay: 0.0500 (0.0500)  time: 20.7631  data: 20.6031  max mem: 2500\n",
      "Epoch: [40]  [ 10/227]  eta: 0:07:16  lr: 0.000039  min_lr: 0.000039  loss: 0.3497 (0.3668)  class_acc: 1.0000 (1.0000)  weight_decay: 0.0500 (0.0500)  time: 2.0109  data: 1.8730  max mem: 2500\n",
      "Epoch: [40]  [ 20/227]  eta: 0:03:51  lr: 0.000038  min_lr: 0.000038  loss: 0.3501 (0.3937)  class_acc: 1.0000 (0.9762)  weight_decay: 0.0500 (0.0500)  time: 0.1342  data: 0.0001  max mem: 2500\n",
      "Epoch: [40]  [ 30/227]  eta: 0:02:37  lr: 0.000038  min_lr: 0.000038  loss: 0.3646 (0.4121)  class_acc: 1.0000 (0.9677)  weight_decay: 0.0500 (0.0500)  time: 0.1329  data: 0.0001  max mem: 2500\n",
      "Epoch: [40]  [ 40/227]  eta: 0:01:59  lr: 0.000038  min_lr: 0.000038  loss: 0.3578 (0.4016)  class_acc: 1.0000 (0.9732)  weight_decay: 0.0500 (0.0500)  time: 0.1350  data: 0.0001  max mem: 2500\n",
      "Epoch: [40]  [ 50/227]  eta: 0:01:35  lr: 0.000037  min_lr: 0.000037  loss: 0.3504 (0.3928)  class_acc: 1.0000 (0.9784)  weight_decay: 0.0500 (0.0500)  time: 0.1355  data: 0.0001  max mem: 2500\n",
      "Epoch: [40]  [ 60/227]  eta: 0:01:18  lr: 0.000037  min_lr: 0.000037  loss: 0.3502 (0.3876)  class_acc: 1.0000 (0.9820)  weight_decay: 0.0500 (0.0500)  time: 0.1340  data: 0.0001  max mem: 2500\n",
      "Epoch: [40]  [ 70/227]  eta: 0:01:06  lr: 0.000037  min_lr: 0.000037  loss: 0.3513 (0.3830)  class_acc: 1.0000 (0.9845)  weight_decay: 0.0500 (0.0500)  time: 0.1346  data: 0.0001  max mem: 2500\n",
      "Epoch: [40]  [ 80/227]  eta: 0:00:57  lr: 0.000037  min_lr: 0.000037  loss: 0.3513 (0.3815)  class_acc: 1.0000 (0.9852)  weight_decay: 0.0500 (0.0500)  time: 0.1369  data: 0.0001  max mem: 2500\n",
      "Epoch: [40]  [ 90/227]  eta: 0:00:49  lr: 0.000036  min_lr: 0.000036  loss: 0.3560 (0.3798)  class_acc: 1.0000 (0.9868)  weight_decay: 0.0500 (0.0500)  time: 0.1376  data: 0.0001  max mem: 2500\n",
      "Epoch: [40]  [100/227]  eta: 0:00:43  lr: 0.000036  min_lr: 0.000036  loss: 0.3596 (0.3808)  class_acc: 1.0000 (0.9871)  weight_decay: 0.0500 (0.0500)  time: 0.1355  data: 0.0001  max mem: 2500\n",
      "Epoch: [40]  [110/227]  eta: 0:00:37  lr: 0.000036  min_lr: 0.000036  loss: 0.3531 (0.3814)  class_acc: 1.0000 (0.9865)  weight_decay: 0.0500 (0.0500)  time: 0.1349  data: 0.0001  max mem: 2500\n",
      "Epoch: [40]  [120/227]  eta: 0:00:32  lr: 0.000035  min_lr: 0.000035  loss: 0.3566 (0.3815)  class_acc: 1.0000 (0.9860)  weight_decay: 0.0500 (0.0500)  time: 0.1348  data: 0.0002  max mem: 2500\n",
      "Epoch: [40]  [130/227]  eta: 0:00:28  lr: 0.000035  min_lr: 0.000035  loss: 0.3566 (0.3869)  class_acc: 1.0000 (0.9824)  weight_decay: 0.0500 (0.0500)  time: 0.1342  data: 0.0002  max mem: 2500\n",
      "Epoch: [40]  [140/227]  eta: 0:00:24  lr: 0.000035  min_lr: 0.000035  loss: 0.3554 (0.3887)  class_acc: 1.0000 (0.9809)  weight_decay: 0.0500 (0.0500)  time: 0.1342  data: 0.0001  max mem: 2500\n",
      "Epoch: [40]  [150/227]  eta: 0:00:20  lr: 0.000034  min_lr: 0.000034  loss: 0.3532 (0.3896)  class_acc: 1.0000 (0.9808)  weight_decay: 0.0500 (0.0500)  time: 0.1336  data: 0.0001  max mem: 2500\n",
      "Epoch: [40]  [160/227]  eta: 0:00:17  lr: 0.000034  min_lr: 0.000034  loss: 0.3533 (0.3909)  class_acc: 1.0000 (0.9801)  weight_decay: 0.0500 (0.0500)  time: 0.1352  data: 0.0003  max mem: 2500\n",
      "Epoch: [40]  [170/227]  eta: 0:00:14  lr: 0.000034  min_lr: 0.000034  loss: 0.3691 (0.3919)  class_acc: 1.0000 (0.9795)  weight_decay: 0.0500 (0.0500)  time: 0.1353  data: 0.0004  max mem: 2500\n",
      "Epoch: [40]  [180/227]  eta: 0:00:11  lr: 0.000033  min_lr: 0.000033  loss: 0.3591 (0.3909)  class_acc: 1.0000 (0.9801)  weight_decay: 0.0500 (0.0500)  time: 0.1333  data: 0.0001  max mem: 2500\n",
      "Epoch: [40]  [190/227]  eta: 0:00:08  lr: 0.000033  min_lr: 0.000033  loss: 0.3576 (0.3910)  class_acc: 1.0000 (0.9796)  weight_decay: 0.0500 (0.0500)  time: 0.1328  data: 0.0001  max mem: 2500\n",
      "Epoch: [40]  [200/227]  eta: 0:00:06  lr: 0.000033  min_lr: 0.000033  loss: 0.3576 (0.3904)  class_acc: 1.0000 (0.9801)  weight_decay: 0.0500 (0.0500)  time: 0.1334  data: 0.0001  max mem: 2500\n",
      "Epoch: [40]  [210/227]  eta: 0:00:03  lr: 0.000033  min_lr: 0.000033  loss: 0.3524 (0.3904)  class_acc: 1.0000 (0.9796)  weight_decay: 0.0500 (0.0500)  time: 0.1333  data: 0.0001  max mem: 2500\n",
      "Epoch: [40]  [220/227]  eta: 0:00:01  lr: 0.000032  min_lr: 0.000032  loss: 0.3597 (0.3904)  class_acc: 1.0000 (0.9792)  weight_decay: 0.0500 (0.0500)  time: 0.1333  data: 0.0001  max mem: 2500\n",
      "Epoch: [40]  [226/227]  eta: 0:00:00  lr: 0.000032  min_lr: 0.000032  loss: 0.3556 (0.3904)  class_acc: 1.0000 (0.9789)  weight_decay: 0.0500 (0.0500)  time: 0.1335  data: 0.0001  max mem: 2500\n",
      "Epoch: [40] Total time: 0:00:51 (0.2276 s / it)\n",
      "Averaged stats: lr: 0.000032  min_lr: 0.000032  loss: 0.3556 (0.3904)  class_acc: 1.0000 (0.9789)  weight_decay: 0.0500 (0.0500)\n",
      "Test:  [ 0/38]  eta: 0:13:19  loss: 0.0792 (0.0792)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 21.0357  data: 20.9786  max mem: 2500\n",
      "Test:  [10/38]  eta: 0:00:54  loss: 0.0890 (0.1323)  acc1: 100.0000 (96.9697)  acc5: 100.0000 (100.0000)  time: 1.9548  data: 1.9072  max mem: 2500\n",
      "Test:  [20/38]  eta: 0:00:18  loss: 0.1220 (0.2387)  acc1: 93.3333 (93.0159)  acc5: 100.0000 (100.0000)  time: 0.0480  data: 0.0002  max mem: 2500\n",
      "Test:  [30/38]  eta: 0:00:05  loss: 0.0799 (0.1874)  acc1: 100.0000 (95.2688)  acc5: 100.0000 (100.0000)  time: 0.0480  data: 0.0003  max mem: 2500\n",
      "Test:  [37/38]  eta: 0:00:00  loss: 0.0794 (0.1682)  acc1: 100.0000 (96.0714)  acc5: 100.0000 (100.0000)  time: 0.0452  data: 0.0002  max mem: 2500\n",
      "Test: Total time: 0:00:23 (0.6123 s / it)\n",
      "* Acc@1 96.071 Acc@5 100.000 loss 0.168\n",
      "[[135   2   0   3]\n",
      " [ 14 123   1   2]\n",
      " [  0   0 140   0]\n",
      " [  0   0   0 140]]\n",
      "(4, 4)\n",
      "Accuracy of the model on the 560 test images: 96.1%\n",
      "Max accuracy: 96.61%\n",
      "Epoch: [41]  [  0/227]  eta: 1:20:25  lr: 0.000032  min_lr: 0.000032  loss: 0.3499 (0.3499)  class_acc: 1.0000 (1.0000)  weight_decay: 0.0500 (0.0500)  time: 21.2558  data: 21.1038  max mem: 2500\n",
      "Epoch: [41]  [ 10/227]  eta: 0:07:26  lr: 0.000032  min_lr: 0.000032  loss: 0.3499 (0.3684)  class_acc: 1.0000 (0.9909)  weight_decay: 0.0500 (0.0500)  time: 2.0559  data: 1.9186  max mem: 2500\n",
      "Epoch: [41]  [ 20/227]  eta: 0:03:56  lr: 0.000031  min_lr: 0.000031  loss: 0.3520 (0.3856)  class_acc: 1.0000 (0.9762)  weight_decay: 0.0500 (0.0500)  time: 0.1369  data: 0.0001  max mem: 2500\n",
      "Epoch: [41]  [ 30/227]  eta: 0:02:41  lr: 0.000031  min_lr: 0.000031  loss: 0.3529 (0.3835)  class_acc: 1.0000 (0.9806)  weight_decay: 0.0500 (0.0500)  time: 0.1370  data: 0.0002  max mem: 2500\n",
      "Epoch: [41]  [ 40/227]  eta: 0:02:01  lr: 0.000031  min_lr: 0.000031  loss: 0.3520 (0.3788)  class_acc: 1.0000 (0.9829)  weight_decay: 0.0500 (0.0500)  time: 0.1348  data: 0.0001  max mem: 2500\n",
      "Epoch: [41]  [ 50/227]  eta: 0:01:37  lr: 0.000031  min_lr: 0.000031  loss: 0.3520 (0.3825)  class_acc: 1.0000 (0.9804)  weight_decay: 0.0500 (0.0500)  time: 0.1355  data: 0.0001  max mem: 2500\n",
      "Epoch: [41]  [ 60/227]  eta: 0:01:20  lr: 0.000030  min_lr: 0.000030  loss: 0.3533 (0.3826)  class_acc: 1.0000 (0.9787)  weight_decay: 0.0500 (0.0500)  time: 0.1418  data: 0.0003  max mem: 2500\n",
      "Epoch: [41]  [ 70/227]  eta: 0:01:08  lr: 0.000030  min_lr: 0.000030  loss: 0.3512 (0.3860)  class_acc: 1.0000 (0.9775)  weight_decay: 0.0500 (0.0500)  time: 0.1413  data: 0.0003  max mem: 2500\n",
      "Epoch: [41]  [ 80/227]  eta: 0:00:58  lr: 0.000030  min_lr: 0.000030  loss: 0.3505 (0.3898)  class_acc: 1.0000 (0.9753)  weight_decay: 0.0500 (0.0500)  time: 0.1424  data: 0.0002  max mem: 2500\n",
      "Epoch: [41]  [ 90/227]  eta: 0:00:50  lr: 0.000029  min_lr: 0.000029  loss: 0.3540 (0.3891)  class_acc: 1.0000 (0.9758)  weight_decay: 0.0500 (0.0500)  time: 0.1434  data: 0.0002  max mem: 2500\n",
      "Epoch: [41]  [100/227]  eta: 0:00:44  lr: 0.000029  min_lr: 0.000029  loss: 0.3587 (0.3892)  class_acc: 1.0000 (0.9762)  weight_decay: 0.0500 (0.0500)  time: 0.1375  data: 0.0002  max mem: 2500\n",
      "Epoch: [41]  [110/227]  eta: 0:00:38  lr: 0.000029  min_lr: 0.000029  loss: 0.3806 (0.3932)  class_acc: 1.0000 (0.9739)  weight_decay: 0.0500 (0.0500)  time: 0.1373  data: 0.0001  max mem: 2500\n",
      "Epoch: [41]  [120/227]  eta: 0:00:33  lr: 0.000029  min_lr: 0.000029  loss: 0.3852 (0.3937)  class_acc: 1.0000 (0.9736)  weight_decay: 0.0500 (0.0500)  time: 0.1371  data: 0.0000  max mem: 2500\n",
      "Epoch: [41]  [130/227]  eta: 0:00:29  lr: 0.000028  min_lr: 0.000028  loss: 0.3541 (0.3925)  class_acc: 1.0000 (0.9740)  weight_decay: 0.0500 (0.0500)  time: 0.1369  data: 0.0001  max mem: 2500\n",
      "Epoch: [41]  [140/227]  eta: 0:00:25  lr: 0.000028  min_lr: 0.000028  loss: 0.3506 (0.3907)  class_acc: 1.0000 (0.9752)  weight_decay: 0.0500 (0.0500)  time: 0.1380  data: 0.0001  max mem: 2500\n",
      "Epoch: [41]  [150/227]  eta: 0:00:21  lr: 0.000028  min_lr: 0.000028  loss: 0.3530 (0.3901)  class_acc: 1.0000 (0.9762)  weight_decay: 0.0500 (0.0500)  time: 0.1374  data: 0.0001  max mem: 2500\n",
      "Epoch: [41]  [160/227]  eta: 0:00:18  lr: 0.000027  min_lr: 0.000027  loss: 0.3682 (0.3914)  class_acc: 1.0000 (0.9764)  weight_decay: 0.0500 (0.0500)  time: 0.1364  data: 0.0002  max mem: 2500\n",
      "Epoch: [41]  [170/227]  eta: 0:00:14  lr: 0.000027  min_lr: 0.000027  loss: 0.3568 (0.3912)  class_acc: 1.0000 (0.9766)  weight_decay: 0.0500 (0.0500)  time: 0.1377  data: 0.0003  max mem: 2500\n",
      "Epoch: [41]  [180/227]  eta: 0:00:11  lr: 0.000027  min_lr: 0.000027  loss: 0.3514 (0.3895)  class_acc: 1.0000 (0.9779)  weight_decay: 0.0500 (0.0500)  time: 0.1379  data: 0.0003  max mem: 2500\n",
      "Epoch: [41]  [190/227]  eta: 0:00:09  lr: 0.000027  min_lr: 0.000027  loss: 0.3526 (0.3917)  class_acc: 1.0000 (0.9770)  weight_decay: 0.0500 (0.0500)  time: 0.1370  data: 0.0002  max mem: 2500\n",
      "Epoch: [41]  [200/227]  eta: 0:00:06  lr: 0.000026  min_lr: 0.000026  loss: 0.3614 (0.3908)  class_acc: 1.0000 (0.9776)  weight_decay: 0.0500 (0.0500)  time: 0.1383  data: 0.0001  max mem: 2500\n",
      "Epoch: [41]  [210/227]  eta: 0:00:04  lr: 0.000026  min_lr: 0.000026  loss: 0.3585 (0.3919)  class_acc: 1.0000 (0.9773)  weight_decay: 0.0500 (0.0500)  time: 0.1387  data: 0.0001  max mem: 2500\n",
      "Epoch: [41]  [220/227]  eta: 0:00:01  lr: 0.000026  min_lr: 0.000026  loss: 0.3565 (0.3940)  class_acc: 1.0000 (0.9765)  weight_decay: 0.0500 (0.0500)  time: 0.1367  data: 0.0001  max mem: 2500\n",
      "Epoch: [41]  [226/227]  eta: 0:00:00  lr: 0.000026  min_lr: 0.000026  loss: 0.3525 (0.3932)  class_acc: 1.0000 (0.9767)  weight_decay: 0.0500 (0.0500)  time: 0.1373  data: 0.0001  max mem: 2500\n",
      "Epoch: [41] Total time: 0:00:52 (0.2334 s / it)\n",
      "Averaged stats: lr: 0.000026  min_lr: 0.000026  loss: 0.3525 (0.3932)  class_acc: 1.0000 (0.9767)  weight_decay: 0.0500 (0.0500)\n",
      "Test:  [ 0/38]  eta: 0:13:27  loss: 0.0838 (0.0838)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 21.2544  data: 21.1974  max mem: 2500\n",
      "Test:  [10/38]  eta: 0:00:55  loss: 0.0959 (0.1523)  acc1: 100.0000 (96.9697)  acc5: 100.0000 (100.0000)  time: 1.9761  data: 1.9272  max mem: 2500\n",
      "Test:  [20/38]  eta: 0:00:19  loss: 0.1594 (0.2349)  acc1: 93.3333 (93.9683)  acc5: 100.0000 (100.0000)  time: 0.0480  data: 0.0002  max mem: 2500\n",
      "Test:  [30/38]  eta: 0:00:05  loss: 0.0790 (0.1846)  acc1: 100.0000 (95.9140)  acc5: 100.0000 (100.0000)  time: 0.0476  data: 0.0002  max mem: 2500\n",
      "Test:  [37/38]  eta: 0:00:00  loss: 0.0788 (0.1660)  acc1: 100.0000 (96.6071)  acc5: 100.0000 (100.0000)  time: 0.0460  data: 0.0002  max mem: 2500\n",
      "Test: Total time: 0:00:23 (0.6183 s / it)\n",
      "* Acc@1 96.607 Acc@5 100.000 loss 0.166\n",
      "[[135   2   0   3]\n",
      " [ 11 126   1   2]\n",
      " [  0   0 140   0]\n",
      " [  0   0   0 140]]\n",
      "(4, 4)\n",
      "Accuracy of the model on the 560 test images: 96.6%\n",
      "Max accuracy: 96.61%\n",
      "Epoch: [42]  [  0/227]  eta: 1:20:46  lr: 0.000026  min_lr: 0.000026  loss: 0.3590 (0.3590)  class_acc: 1.0000 (1.0000)  weight_decay: 0.0500 (0.0500)  time: 21.3522  data: 21.2092  max mem: 2500\n",
      "Epoch: [42]  [ 10/227]  eta: 0:07:27  lr: 0.000025  min_lr: 0.000025  loss: 0.3516 (0.3665)  class_acc: 1.0000 (0.9909)  weight_decay: 0.0500 (0.0500)  time: 2.0633  data: 1.9283  max mem: 2500\n",
      "Epoch: [42]  [ 20/227]  eta: 0:03:56  lr: 0.000025  min_lr: 0.000025  loss: 0.3560 (0.3749)  class_acc: 1.0000 (0.9857)  weight_decay: 0.0500 (0.0500)  time: 0.1340  data: 0.0002  max mem: 2500\n",
      "Epoch: [42]  [ 30/227]  eta: 0:02:41  lr: 0.000025  min_lr: 0.000025  loss: 0.3584 (0.3883)  class_acc: 1.0000 (0.9774)  weight_decay: 0.0500 (0.0500)  time: 0.1340  data: 0.0002  max mem: 2500\n",
      "Epoch: [42]  [ 40/227]  eta: 0:02:01  lr: 0.000025  min_lr: 0.000025  loss: 0.3590 (0.3934)  class_acc: 1.0000 (0.9756)  weight_decay: 0.0500 (0.0500)  time: 0.1334  data: 0.0002  max mem: 2500\n",
      "Epoch: [42]  [ 50/227]  eta: 0:01:37  lr: 0.000024  min_lr: 0.000024  loss: 0.3533 (0.3873)  class_acc: 1.0000 (0.9804)  weight_decay: 0.0500 (0.0500)  time: 0.1342  data: 0.0001  max mem: 2500\n",
      "Epoch: [42]  [ 60/227]  eta: 0:01:20  lr: 0.000024  min_lr: 0.000024  loss: 0.3528 (0.3894)  class_acc: 1.0000 (0.9820)  weight_decay: 0.0500 (0.0500)  time: 0.1354  data: 0.0002  max mem: 2500\n",
      "Epoch: [42]  [ 70/227]  eta: 0:01:07  lr: 0.000024  min_lr: 0.000024  loss: 0.3533 (0.3937)  class_acc: 1.0000 (0.9789)  weight_decay: 0.0500 (0.0500)  time: 0.1336  data: 0.0003  max mem: 2500\n",
      "Epoch: [42]  [ 80/227]  eta: 0:00:58  lr: 0.000024  min_lr: 0.000024  loss: 0.3507 (0.3902)  class_acc: 1.0000 (0.9802)  weight_decay: 0.0500 (0.0500)  time: 0.1330  data: 0.0002  max mem: 2500\n",
      "Epoch: [42]  [ 90/227]  eta: 0:00:50  lr: 0.000023  min_lr: 0.000023  loss: 0.3504 (0.3934)  class_acc: 1.0000 (0.9791)  weight_decay: 0.0500 (0.0500)  time: 0.1339  data: 0.0002  max mem: 2500\n",
      "Epoch: [42]  [100/227]  eta: 0:00:43  lr: 0.000023  min_lr: 0.000023  loss: 0.3565 (0.3944)  class_acc: 1.0000 (0.9772)  weight_decay: 0.0500 (0.0500)  time: 0.1336  data: 0.0002  max mem: 2500\n",
      "Epoch: [42]  [110/227]  eta: 0:00:38  lr: 0.000023  min_lr: 0.000023  loss: 0.3515 (0.3935)  class_acc: 1.0000 (0.9775)  weight_decay: 0.0500 (0.0500)  time: 0.1341  data: 0.0002  max mem: 2500\n",
      "Epoch: [42]  [120/227]  eta: 0:00:33  lr: 0.000023  min_lr: 0.000023  loss: 0.3515 (0.3912)  class_acc: 1.0000 (0.9785)  weight_decay: 0.0500 (0.0500)  time: 0.1345  data: 0.0002  max mem: 2500\n",
      "Epoch: [42]  [130/227]  eta: 0:00:28  lr: 0.000022  min_lr: 0.000022  loss: 0.3529 (0.3904)  class_acc: 1.0000 (0.9786)  weight_decay: 0.0500 (0.0500)  time: 0.1348  data: 0.0002  max mem: 2500\n",
      "Epoch: [42]  [140/227]  eta: 0:00:24  lr: 0.000022  min_lr: 0.000022  loss: 0.3528 (0.3908)  class_acc: 1.0000 (0.9787)  weight_decay: 0.0500 (0.0500)  time: 0.1351  data: 0.0002  max mem: 2500\n",
      "Epoch: [42]  [150/227]  eta: 0:00:21  lr: 0.000022  min_lr: 0.000022  loss: 0.3520 (0.3892)  class_acc: 1.0000 (0.9801)  weight_decay: 0.0500 (0.0500)  time: 0.1336  data: 0.0002  max mem: 2500\n",
      "Epoch: [42]  [160/227]  eta: 0:00:17  lr: 0.000022  min_lr: 0.000022  loss: 0.3520 (0.3883)  class_acc: 1.0000 (0.9807)  weight_decay: 0.0500 (0.0500)  time: 0.1343  data: 0.0005  max mem: 2500\n",
      "Epoch: [42]  [170/227]  eta: 0:00:14  lr: 0.000021  min_lr: 0.000021  loss: 0.3656 (0.3908)  class_acc: 1.0000 (0.9789)  weight_decay: 0.0500 (0.0500)  time: 0.1340  data: 0.0005  max mem: 2500\n",
      "Epoch: [42]  [180/227]  eta: 0:00:11  lr: 0.000021  min_lr: 0.000021  loss: 0.3745 (0.3922)  class_acc: 1.0000 (0.9779)  weight_decay: 0.0500 (0.0500)  time: 0.1326  data: 0.0003  max mem: 2500\n",
      "Epoch: [42]  [190/227]  eta: 0:00:09  lr: 0.000021  min_lr: 0.000021  loss: 0.3586 (0.3919)  class_acc: 1.0000 (0.9785)  weight_decay: 0.0500 (0.0500)  time: 0.1332  data: 0.0003  max mem: 2500\n",
      "Epoch: [42]  [200/227]  eta: 0:00:06  lr: 0.000021  min_lr: 0.000021  loss: 0.3524 (0.3920)  class_acc: 1.0000 (0.9781)  weight_decay: 0.0500 (0.0500)  time: 0.1354  data: 0.0002  max mem: 2500\n",
      "Epoch: [42]  [210/227]  eta: 0:00:03  lr: 0.000020  min_lr: 0.000020  loss: 0.3507 (0.3918)  class_acc: 1.0000 (0.9782)  weight_decay: 0.0500 (0.0500)  time: 0.1387  data: 0.0002  max mem: 2500\n",
      "Epoch: [42]  [220/227]  eta: 0:00:01  lr: 0.000020  min_lr: 0.000020  loss: 0.3518 (0.3925)  class_acc: 1.0000 (0.9769)  weight_decay: 0.0500 (0.0500)  time: 0.1374  data: 0.0002  max mem: 2500\n",
      "Epoch: [42]  [226/227]  eta: 0:00:00  lr: 0.000020  min_lr: 0.000020  loss: 0.3523 (0.3915)  class_acc: 1.0000 (0.9775)  weight_decay: 0.0500 (0.0500)  time: 0.1389  data: 0.0002  max mem: 2500\n",
      "Epoch: [42] Total time: 0:00:52 (0.2304 s / it)\n",
      "Averaged stats: lr: 0.000020  min_lr: 0.000020  loss: 0.3523 (0.3915)  class_acc: 1.0000 (0.9775)  weight_decay: 0.0500 (0.0500)\n",
      "Test:  [ 0/38]  eta: 0:13:06  loss: 0.0808 (0.0808)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 20.6939  data: 20.6379  max mem: 2500\n",
      "Test:  [10/38]  eta: 0:00:53  loss: 0.0928 (0.1290)  acc1: 100.0000 (97.5758)  acc5: 100.0000 (100.0000)  time: 1.9237  data: 1.8763  max mem: 2500\n",
      "Test:  [20/38]  eta: 0:00:18  loss: 0.1344 (0.2761)  acc1: 93.3333 (92.3810)  acc5: 100.0000 (100.0000)  time: 0.0467  data: 0.0002  max mem: 2500\n",
      "Test:  [30/38]  eta: 0:00:05  loss: 0.0772 (0.2126)  acc1: 100.0000 (94.8387)  acc5: 100.0000 (100.0000)  time: 0.0465  data: 0.0001  max mem: 2500\n",
      "Test:  [37/38]  eta: 0:00:00  loss: 0.0772 (0.1908)  acc1: 100.0000 (95.5357)  acc5: 100.0000 (100.0000)  time: 0.0451  data: 0.0002  max mem: 2500\n",
      "Test: Total time: 0:00:22 (0.6023 s / it)\n",
      "* Acc@1 95.536 Acc@5 100.000 loss 0.191\n",
      "[[136   2   0   2]\n",
      " [ 16 120   2   2]\n",
      " [  0   0 140   0]\n",
      " [  0   0   1 139]]\n",
      "(4, 4)\n",
      "Accuracy of the model on the 560 test images: 95.5%\n",
      "Max accuracy: 96.61%\n",
      "Epoch: [43]  [  0/227]  eta: 1:18:37  lr: 0.000020  min_lr: 0.000020  loss: 0.4808 (0.4808)  class_acc: 0.9000 (0.9000)  weight_decay: 0.0500 (0.0500)  time: 20.7805  data: 20.6225  max mem: 2500\n",
      "Epoch: [43]  [ 10/227]  eta: 0:07:16  lr: 0.000020  min_lr: 0.000020  loss: 0.3862 (0.4090)  class_acc: 1.0000 (0.9636)  weight_decay: 0.0500 (0.0500)  time: 2.0122  data: 1.8750  max mem: 2500\n",
      "Epoch: [43]  [ 20/227]  eta: 0:03:51  lr: 0.000020  min_lr: 0.000020  loss: 0.3630 (0.3968)  class_acc: 1.0000 (0.9714)  weight_decay: 0.0500 (0.0500)  time: 0.1339  data: 0.0003  max mem: 2500\n",
      "Epoch: [43]  [ 30/227]  eta: 0:02:37  lr: 0.000019  min_lr: 0.000019  loss: 0.3519 (0.4015)  class_acc: 1.0000 (0.9742)  weight_decay: 0.0500 (0.0500)  time: 0.1332  data: 0.0002  max mem: 2500\n",
      "Epoch: [43]  [ 40/227]  eta: 0:01:59  lr: 0.000019  min_lr: 0.000019  loss: 0.3519 (0.3940)  class_acc: 1.0000 (0.9780)  weight_decay: 0.0500 (0.0500)  time: 0.1338  data: 0.0001  max mem: 2500\n",
      "Epoch: [43]  [ 50/227]  eta: 0:01:35  lr: 0.000019  min_lr: 0.000019  loss: 0.3519 (0.3881)  class_acc: 1.0000 (0.9824)  weight_decay: 0.0500 (0.0500)  time: 0.1338  data: 0.0000  max mem: 2500\n",
      "Epoch: [43]  [ 60/227]  eta: 0:01:18  lr: 0.000019  min_lr: 0.000019  loss: 0.3544 (0.3933)  class_acc: 1.0000 (0.9803)  weight_decay: 0.0500 (0.0500)  time: 0.1338  data: 0.0001  max mem: 2500\n",
      "Epoch: [43]  [ 70/227]  eta: 0:01:06  lr: 0.000018  min_lr: 0.000018  loss: 0.3746 (0.3916)  class_acc: 1.0000 (0.9803)  weight_decay: 0.0500 (0.0500)  time: 0.1340  data: 0.0002  max mem: 2500\n",
      "Epoch: [43]  [ 80/227]  eta: 0:00:57  lr: 0.000018  min_lr: 0.000018  loss: 0.3517 (0.3924)  class_acc: 1.0000 (0.9790)  weight_decay: 0.0500 (0.0500)  time: 0.1336  data: 0.0003  max mem: 2500\n",
      "Epoch: [43]  [ 90/227]  eta: 0:00:49  lr: 0.000018  min_lr: 0.000018  loss: 0.3541 (0.3931)  class_acc: 1.0000 (0.9769)  weight_decay: 0.0500 (0.0500)  time: 0.1332  data: 0.0002  max mem: 2500\n",
      "Epoch: [43]  [100/227]  eta: 0:00:42  lr: 0.000018  min_lr: 0.000018  loss: 0.3788 (0.3940)  class_acc: 1.0000 (0.9762)  weight_decay: 0.0500 (0.0500)  time: 0.1342  data: 0.0002  max mem: 2500\n",
      "Epoch: [43]  [110/227]  eta: 0:00:37  lr: 0.000017  min_lr: 0.000017  loss: 0.3687 (0.3946)  class_acc: 1.0000 (0.9757)  weight_decay: 0.0500 (0.0500)  time: 0.1344  data: 0.0002  max mem: 2500\n",
      "Epoch: [43]  [120/227]  eta: 0:00:32  lr: 0.000017  min_lr: 0.000017  loss: 0.3653 (0.3955)  class_acc: 1.0000 (0.9744)  weight_decay: 0.0500 (0.0500)  time: 0.1335  data: 0.0001  max mem: 2500\n",
      "Epoch: [43]  [130/227]  eta: 0:00:28  lr: 0.000017  min_lr: 0.000017  loss: 0.3761 (0.3954)  class_acc: 1.0000 (0.9740)  weight_decay: 0.0500 (0.0500)  time: 0.1329  data: 0.0002  max mem: 2500\n",
      "Epoch: [43]  [140/227]  eta: 0:00:24  lr: 0.000017  min_lr: 0.000017  loss: 0.3761 (0.3980)  class_acc: 1.0000 (0.9730)  weight_decay: 0.0500 (0.0500)  time: 0.1339  data: 0.0001  max mem: 2500\n",
      "Epoch: [43]  [150/227]  eta: 0:00:20  lr: 0.000017  min_lr: 0.000017  loss: 0.3509 (0.4030)  class_acc: 1.0000 (0.9702)  weight_decay: 0.0500 (0.0500)  time: 0.1352  data: 0.0001  max mem: 2500\n",
      "Epoch: [43]  [160/227]  eta: 0:00:17  lr: 0.000016  min_lr: 0.000016  loss: 0.3509 (0.4009)  class_acc: 1.0000 (0.9714)  weight_decay: 0.0500 (0.0500)  time: 0.1353  data: 0.0002  max mem: 2500\n",
      "Epoch: [43]  [170/227]  eta: 0:00:14  lr: 0.000016  min_lr: 0.000016  loss: 0.3523 (0.4002)  class_acc: 1.0000 (0.9725)  weight_decay: 0.0500 (0.0500)  time: 0.1340  data: 0.0003  max mem: 2500\n",
      "Epoch: [43]  [180/227]  eta: 0:00:11  lr: 0.000016  min_lr: 0.000016  loss: 0.3552 (0.3991)  class_acc: 1.0000 (0.9729)  weight_decay: 0.0500 (0.0500)  time: 0.1346  data: 0.0003  max mem: 2500\n",
      "Epoch: [43]  [190/227]  eta: 0:00:08  lr: 0.000016  min_lr: 0.000016  loss: 0.3619 (0.3989)  class_acc: 1.0000 (0.9728)  weight_decay: 0.0500 (0.0500)  time: 0.1361  data: 0.0003  max mem: 2500\n",
      "Epoch: [43]  [200/227]  eta: 0:00:06  lr: 0.000016  min_lr: 0.000016  loss: 0.3578 (0.3980)  class_acc: 1.0000 (0.9731)  weight_decay: 0.0500 (0.0500)  time: 0.1349  data: 0.0003  max mem: 2500\n",
      "Epoch: [43]  [210/227]  eta: 0:00:03  lr: 0.000015  min_lr: 0.000015  loss: 0.3548 (0.3981)  class_acc: 1.0000 (0.9735)  weight_decay: 0.0500 (0.0500)  time: 0.1335  data: 0.0002  max mem: 2500\n",
      "Epoch: [43]  [220/227]  eta: 0:00:01  lr: 0.000015  min_lr: 0.000015  loss: 0.3548 (0.3972)  class_acc: 1.0000 (0.9742)  weight_decay: 0.0500 (0.0500)  time: 0.1354  data: 0.0002  max mem: 2500\n",
      "Epoch: [43]  [226/227]  eta: 0:00:00  lr: 0.000015  min_lr: 0.000015  loss: 0.3508 (0.3964)  class_acc: 1.0000 (0.9744)  weight_decay: 0.0500 (0.0500)  time: 0.1352  data: 0.0001  max mem: 2500\n",
      "Epoch: [43] Total time: 0:00:51 (0.2274 s / it)\n",
      "Averaged stats: lr: 0.000015  min_lr: 0.000015  loss: 0.3508 (0.3964)  class_acc: 1.0000 (0.9744)  weight_decay: 0.0500 (0.0500)\n",
      "Test:  [ 0/38]  eta: 0:13:06  loss: 0.0787 (0.0787)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 20.7091  data: 20.6531  max mem: 2500\n",
      "Test:  [10/38]  eta: 0:00:53  loss: 0.0844 (0.1322)  acc1: 100.0000 (96.9697)  acc5: 100.0000 (100.0000)  time: 1.9250  data: 1.8776  max mem: 2500\n",
      "Test:  [20/38]  eta: 0:00:18  loss: 0.1329 (0.2383)  acc1: 93.3333 (93.6508)  acc5: 100.0000 (100.0000)  time: 0.0467  data: 0.0001  max mem: 2500\n",
      "Test:  [30/38]  eta: 0:00:05  loss: 0.0795 (0.1866)  acc1: 100.0000 (95.6989)  acc5: 100.0000 (100.0000)  time: 0.0466  data: 0.0001  max mem: 2500\n",
      "Test:  [37/38]  eta: 0:00:00  loss: 0.0795 (0.1680)  acc1: 100.0000 (96.4286)  acc5: 100.0000 (100.0000)  time: 0.0451  data: 0.0002  max mem: 2500\n",
      "Test: Total time: 0:00:22 (0.6032 s / it)\n",
      "* Acc@1 96.429 Acc@5 100.000 loss 0.168\n",
      "[[135   2   0   3]\n",
      " [ 12 125   1   2]\n",
      " [  0   0 140   0]\n",
      " [  0   0   0 140]]\n",
      "(4, 4)\n",
      "Accuracy of the model on the 560 test images: 96.4%\n",
      "Max accuracy: 96.61%\n",
      "Epoch: [44]  [  0/227]  eta: 1:18:28  lr: 0.000015  min_lr: 0.000015  loss: 0.3491 (0.3491)  class_acc: 1.0000 (1.0000)  weight_decay: 0.0500 (0.0500)  time: 20.7427  data: 20.5977  max mem: 2500\n",
      "Epoch: [44]  [ 10/227]  eta: 0:07:15  lr: 0.000015  min_lr: 0.000015  loss: 0.3515 (0.3638)  class_acc: 1.0000 (0.9909)  weight_decay: 0.0500 (0.0500)  time: 2.0063  data: 1.8727  max mem: 2500\n",
      "Epoch: [44]  [ 20/227]  eta: 0:03:50  lr: 0.000015  min_lr: 0.000015  loss: 0.3517 (0.3867)  class_acc: 1.0000 (0.9762)  weight_decay: 0.0500 (0.0500)  time: 0.1325  data: 0.0002  max mem: 2500\n",
      "Epoch: [44]  [ 30/227]  eta: 0:02:37  lr: 0.000014  min_lr: 0.000014  loss: 0.3560 (0.3821)  class_acc: 1.0000 (0.9806)  weight_decay: 0.0500 (0.0500)  time: 0.1324  data: 0.0001  max mem: 2500\n",
      "Epoch: [44]  [ 40/227]  eta: 0:01:58  lr: 0.000014  min_lr: 0.000014  loss: 0.3522 (0.3791)  class_acc: 1.0000 (0.9829)  weight_decay: 0.0500 (0.0500)  time: 0.1336  data: 0.0002  max mem: 2500\n",
      "Epoch: [44]  [ 50/227]  eta: 0:01:35  lr: 0.000014  min_lr: 0.000014  loss: 0.3517 (0.3819)  class_acc: 1.0000 (0.9804)  weight_decay: 0.0500 (0.0500)  time: 0.1354  data: 0.0002  max mem: 2500\n",
      "Epoch: [44]  [ 60/227]  eta: 0:01:18  lr: 0.000014  min_lr: 0.000014  loss: 0.3517 (0.3801)  class_acc: 1.0000 (0.9820)  weight_decay: 0.0500 (0.0500)  time: 0.1361  data: 0.0001  max mem: 2500\n",
      "Epoch: [44]  [ 70/227]  eta: 0:01:06  lr: 0.000014  min_lr: 0.000014  loss: 0.3499 (0.3800)  class_acc: 1.0000 (0.9817)  weight_decay: 0.0500 (0.0500)  time: 0.1352  data: 0.0002  max mem: 2500\n",
      "Epoch: [44]  [ 80/227]  eta: 0:00:57  lr: 0.000013  min_lr: 0.000013  loss: 0.3497 (0.3796)  class_acc: 1.0000 (0.9827)  weight_decay: 0.0500 (0.0500)  time: 0.1353  data: 0.0001  max mem: 2500\n",
      "Epoch: [44]  [ 90/227]  eta: 0:00:49  lr: 0.000013  min_lr: 0.000013  loss: 0.3498 (0.3829)  class_acc: 1.0000 (0.9791)  weight_decay: 0.0500 (0.0500)  time: 0.1353  data: 0.0000  max mem: 2500\n",
      "Epoch: [44]  [100/227]  eta: 0:00:42  lr: 0.000013  min_lr: 0.000013  loss: 0.3539 (0.3821)  class_acc: 1.0000 (0.9792)  weight_decay: 0.0500 (0.0500)  time: 0.1344  data: 0.0000  max mem: 2500\n",
      "Epoch: [44]  [110/227]  eta: 0:00:37  lr: 0.000013  min_lr: 0.000013  loss: 0.3512 (0.3818)  class_acc: 1.0000 (0.9802)  weight_decay: 0.0500 (0.0500)  time: 0.1359  data: 0.0000  max mem: 2500\n",
      "Epoch: [44]  [120/227]  eta: 0:00:32  lr: 0.000013  min_lr: 0.000013  loss: 0.3512 (0.3797)  class_acc: 1.0000 (0.9818)  weight_decay: 0.0500 (0.0500)  time: 0.1361  data: 0.0001  max mem: 2500\n",
      "Epoch: [44]  [130/227]  eta: 0:00:28  lr: 0.000012  min_lr: 0.000012  loss: 0.3547 (0.3808)  class_acc: 1.0000 (0.9817)  weight_decay: 0.0500 (0.0500)  time: 0.1336  data: 0.0001  max mem: 2500\n",
      "Epoch: [44]  [140/227]  eta: 0:00:24  lr: 0.000012  min_lr: 0.000012  loss: 0.3566 (0.3839)  class_acc: 1.0000 (0.9794)  weight_decay: 0.0500 (0.0500)  time: 0.1324  data: 0.0001  max mem: 2500\n",
      "Epoch: [44]  [150/227]  eta: 0:00:20  lr: 0.000012  min_lr: 0.000012  loss: 0.3519 (0.3835)  class_acc: 1.0000 (0.9795)  weight_decay: 0.0500 (0.0500)  time: 0.1329  data: 0.0002  max mem: 2500\n",
      "Epoch: [44]  [160/227]  eta: 0:00:17  lr: 0.000012  min_lr: 0.000012  loss: 0.3519 (0.3854)  class_acc: 1.0000 (0.9783)  weight_decay: 0.0500 (0.0500)  time: 0.1350  data: 0.0002  max mem: 2500\n",
      "Epoch: [44]  [170/227]  eta: 0:00:14  lr: 0.000012  min_lr: 0.000012  loss: 0.3537 (0.3864)  class_acc: 1.0000 (0.9772)  weight_decay: 0.0500 (0.0500)  time: 0.1358  data: 0.0002  max mem: 2500\n",
      "Epoch: [44]  [180/227]  eta: 0:00:11  lr: 0.000012  min_lr: 0.000012  loss: 0.3547 (0.3849)  class_acc: 1.0000 (0.9785)  weight_decay: 0.0500 (0.0500)  time: 0.1353  data: 0.0001  max mem: 2500\n",
      "Epoch: [44]  [190/227]  eta: 0:00:08  lr: 0.000011  min_lr: 0.000011  loss: 0.3569 (0.3861)  class_acc: 1.0000 (0.9785)  weight_decay: 0.0500 (0.0500)  time: 0.1339  data: 0.0000  max mem: 2500\n",
      "Epoch: [44]  [200/227]  eta: 0:00:06  lr: 0.000011  min_lr: 0.000011  loss: 0.3571 (0.3864)  class_acc: 1.0000 (0.9776)  weight_decay: 0.0500 (0.0500)  time: 0.1331  data: 0.0002  max mem: 2500\n",
      "Epoch: [44]  [210/227]  eta: 0:00:03  lr: 0.000011  min_lr: 0.000011  loss: 0.3543 (0.3872)  class_acc: 1.0000 (0.9777)  weight_decay: 0.0500 (0.0500)  time: 0.1333  data: 0.0001  max mem: 2500\n",
      "Epoch: [44]  [220/227]  eta: 0:00:01  lr: 0.000011  min_lr: 0.000011  loss: 0.3543 (0.3877)  class_acc: 1.0000 (0.9774)  weight_decay: 0.0500 (0.0500)  time: 0.1338  data: 0.0001  max mem: 2500\n",
      "Epoch: [44]  [226/227]  eta: 0:00:00  lr: 0.000011  min_lr: 0.000011  loss: 0.3518 (0.3889)  class_acc: 1.0000 (0.9767)  weight_decay: 0.0500 (0.0500)  time: 0.1339  data: 0.0001  max mem: 2500\n",
      "Epoch: [44] Total time: 0:00:51 (0.2273 s / it)\n",
      "Averaged stats: lr: 0.000011  min_lr: 0.000011  loss: 0.3518 (0.3889)  class_acc: 1.0000 (0.9767)  weight_decay: 0.0500 (0.0500)\n",
      "Test:  [ 0/38]  eta: 0:13:07  loss: 0.0799 (0.0799)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 20.7330  data: 20.6750  max mem: 2500\n",
      "Test:  [10/38]  eta: 0:00:53  loss: 0.0914 (0.1466)  acc1: 100.0000 (96.9697)  acc5: 100.0000 (100.0000)  time: 1.9272  data: 1.8795  max mem: 2500\n",
      "Test:  [20/38]  eta: 0:00:18  loss: 0.1480 (0.2280)  acc1: 93.3333 (93.9683)  acc5: 100.0000 (100.0000)  time: 0.0467  data: 0.0001  max mem: 2500\n",
      "Test:  [30/38]  eta: 0:00:05  loss: 0.0779 (0.1795)  acc1: 100.0000 (95.9140)  acc5: 100.0000 (100.0000)  time: 0.0466  data: 0.0001  max mem: 2500\n",
      "Test:  [37/38]  eta: 0:00:00  loss: 0.0777 (0.1618)  acc1: 100.0000 (96.6071)  acc5: 100.0000 (100.0000)  time: 0.0449  data: 0.0001  max mem: 2500\n",
      "Test: Total time: 0:00:22 (0.6043 s / it)\n",
      "* Acc@1 96.607 Acc@5 100.000 loss 0.162\n",
      "[[135   2   0   3]\n",
      " [ 11 126   1   2]\n",
      " [  0   0 140   0]\n",
      " [  0   0   0 140]]\n",
      "(4, 4)\n",
      "Accuracy of the model on the 560 test images: 96.6%\n",
      "Max accuracy: 96.61%\n",
      "Epoch: [45]  [  0/227]  eta: 1:18:15  lr: 0.000011  min_lr: 0.000011  loss: 0.3493 (0.3493)  class_acc: 1.0000 (1.0000)  weight_decay: 0.0500 (0.0500)  time: 20.6864  data: 20.5364  max mem: 2500\n",
      "Epoch: [45]  [ 10/227]  eta: 0:07:14  lr: 0.000011  min_lr: 0.000011  loss: 0.3521 (0.3954)  class_acc: 1.0000 (0.9636)  weight_decay: 0.0500 (0.0500)  time: 2.0009  data: 1.8670  max mem: 2500\n",
      "Epoch: [45]  [ 20/227]  eta: 0:03:49  lr: 0.000010  min_lr: 0.000010  loss: 0.3516 (0.3838)  class_acc: 1.0000 (0.9762)  weight_decay: 0.0500 (0.0500)  time: 0.1323  data: 0.0002  max mem: 2500\n",
      "Epoch: [45]  [ 30/227]  eta: 0:02:36  lr: 0.000010  min_lr: 0.000010  loss: 0.3516 (0.3836)  class_acc: 1.0000 (0.9774)  weight_decay: 0.0500 (0.0500)  time: 0.1328  data: 0.0002  max mem: 2500\n",
      "Epoch: [45]  [ 40/227]  eta: 0:01:58  lr: 0.000010  min_lr: 0.000010  loss: 0.3572 (0.3840)  class_acc: 1.0000 (0.9780)  weight_decay: 0.0500 (0.0500)  time: 0.1351  data: 0.0001  max mem: 2500\n",
      "Epoch: [45]  [ 50/227]  eta: 0:01:35  lr: 0.000010  min_lr: 0.000010  loss: 0.3678 (0.3856)  class_acc: 1.0000 (0.9784)  weight_decay: 0.0500 (0.0500)  time: 0.1370  data: 0.0001  max mem: 2500\n",
      "Epoch: [45]  [ 60/227]  eta: 0:01:18  lr: 0.000010  min_lr: 0.000010  loss: 0.3612 (0.3842)  class_acc: 1.0000 (0.9787)  weight_decay: 0.0500 (0.0500)  time: 0.1365  data: 0.0002  max mem: 2500\n",
      "Epoch: [45]  [ 70/227]  eta: 0:01:06  lr: 0.000010  min_lr: 0.000010  loss: 0.3550 (0.3860)  class_acc: 1.0000 (0.9775)  weight_decay: 0.0500 (0.0500)  time: 0.1348  data: 0.0002  max mem: 2500\n",
      "Epoch: [45]  [ 80/227]  eta: 0:00:57  lr: 0.000009  min_lr: 0.000009  loss: 0.3510 (0.3844)  class_acc: 1.0000 (0.9790)  weight_decay: 0.0500 (0.0500)  time: 0.1343  data: 0.0001  max mem: 2500\n",
      "Epoch: [45]  [ 90/227]  eta: 0:00:49  lr: 0.000009  min_lr: 0.000009  loss: 0.3513 (0.3847)  class_acc: 1.0000 (0.9780)  weight_decay: 0.0500 (0.0500)  time: 0.1338  data: 0.0001  max mem: 2500\n",
      "Epoch: [45]  [100/227]  eta: 0:00:42  lr: 0.000009  min_lr: 0.000009  loss: 0.3520 (0.3845)  class_acc: 1.0000 (0.9792)  weight_decay: 0.0500 (0.0500)  time: 0.1338  data: 0.0000  max mem: 2500\n",
      "Epoch: [45]  [110/227]  eta: 0:00:37  lr: 0.000009  min_lr: 0.000009  loss: 0.3539 (0.3826)  class_acc: 1.0000 (0.9793)  weight_decay: 0.0500 (0.0500)  time: 0.1340  data: 0.0001  max mem: 2500\n",
      "Epoch: [45]  [120/227]  eta: 0:00:32  lr: 0.000009  min_lr: 0.000009  loss: 0.3524 (0.3817)  class_acc: 1.0000 (0.9802)  weight_decay: 0.0500 (0.0500)  time: 0.1344  data: 0.0001  max mem: 2500\n",
      "Epoch: [45]  [130/227]  eta: 0:00:28  lr: 0.000009  min_lr: 0.000009  loss: 0.3527 (0.3832)  class_acc: 1.0000 (0.9802)  weight_decay: 0.0500 (0.0500)  time: 0.1351  data: 0.0001  max mem: 2500\n",
      "Epoch: [45]  [140/227]  eta: 0:00:24  lr: 0.000009  min_lr: 0.000009  loss: 0.3527 (0.3830)  class_acc: 1.0000 (0.9801)  weight_decay: 0.0500 (0.0500)  time: 0.1338  data: 0.0000  max mem: 2500\n",
      "Epoch: [45]  [150/227]  eta: 0:00:20  lr: 0.000008  min_lr: 0.000008  loss: 0.3497 (0.3838)  class_acc: 1.0000 (0.9795)  weight_decay: 0.0500 (0.0500)  time: 0.1330  data: 0.0001  max mem: 2500\n",
      "Epoch: [45]  [160/227]  eta: 0:00:17  lr: 0.000008  min_lr: 0.000008  loss: 0.3497 (0.3838)  class_acc: 1.0000 (0.9795)  weight_decay: 0.0500 (0.0500)  time: 0.1331  data: 0.0001  max mem: 2500\n",
      "Epoch: [45]  [170/227]  eta: 0:00:14  lr: 0.000008  min_lr: 0.000008  loss: 0.3541 (0.3860)  class_acc: 1.0000 (0.9789)  weight_decay: 0.0500 (0.0500)  time: 0.1330  data: 0.0001  max mem: 2500\n",
      "Epoch: [45]  [180/227]  eta: 0:00:11  lr: 0.000008  min_lr: 0.000008  loss: 0.3527 (0.3859)  class_acc: 1.0000 (0.9796)  weight_decay: 0.0500 (0.0500)  time: 0.1342  data: 0.0002  max mem: 2500\n",
      "Epoch: [45]  [190/227]  eta: 0:00:08  lr: 0.000008  min_lr: 0.000008  loss: 0.3521 (0.3884)  class_acc: 1.0000 (0.9785)  weight_decay: 0.0500 (0.0500)  time: 0.1372  data: 0.0002  max mem: 2500\n",
      "Epoch: [45]  [200/227]  eta: 0:00:06  lr: 0.000008  min_lr: 0.000008  loss: 0.3525 (0.3868)  class_acc: 1.0000 (0.9796)  weight_decay: 0.0500 (0.0500)  time: 0.1372  data: 0.0001  max mem: 2500\n",
      "Epoch: [45]  [210/227]  eta: 0:00:03  lr: 0.000008  min_lr: 0.000008  loss: 0.3519 (0.3858)  class_acc: 1.0000 (0.9806)  weight_decay: 0.0500 (0.0500)  time: 0.1356  data: 0.0002  max mem: 2500\n",
      "Epoch: [45]  [220/227]  eta: 0:00:01  lr: 0.000007  min_lr: 0.000007  loss: 0.3504 (0.3854)  class_acc: 1.0000 (0.9810)  weight_decay: 0.0500 (0.0500)  time: 0.1357  data: 0.0003  max mem: 2500\n",
      "Epoch: [45]  [226/227]  eta: 0:00:00  lr: 0.000007  min_lr: 0.000007  loss: 0.3504 (0.3850)  class_acc: 1.0000 (0.9811)  weight_decay: 0.0500 (0.0500)  time: 0.1358  data: 0.0002  max mem: 2500\n",
      "Epoch: [45] Total time: 0:00:51 (0.2275 s / it)\n",
      "Averaged stats: lr: 0.000007  min_lr: 0.000007  loss: 0.3504 (0.3850)  class_acc: 1.0000 (0.9811)  weight_decay: 0.0500 (0.0500)\n",
      "Test:  [ 0/38]  eta: 0:13:21  loss: 0.0813 (0.0813)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 21.0847  data: 21.0277  max mem: 2500\n",
      "Test:  [10/38]  eta: 0:00:54  loss: 0.0983 (0.1545)  acc1: 100.0000 (96.9697)  acc5: 100.0000 (100.0000)  time: 1.9591  data: 1.9116  max mem: 2500\n",
      "Test:  [20/38]  eta: 0:00:18  loss: 0.1584 (0.2240)  acc1: 93.3333 (93.9683)  acc5: 100.0000 (100.0000)  time: 0.0466  data: 0.0002  max mem: 2500\n",
      "Test:  [30/38]  eta: 0:00:05  loss: 0.0784 (0.1771)  acc1: 100.0000 (95.9140)  acc5: 100.0000 (100.0000)  time: 0.0465  data: 0.0002  max mem: 2500\n",
      "Test:  [37/38]  eta: 0:00:00  loss: 0.0784 (0.1604)  acc1: 100.0000 (96.6071)  acc5: 100.0000 (100.0000)  time: 0.0449  data: 0.0001  max mem: 2500\n",
      "Test: Total time: 0:00:23 (0.6126 s / it)\n",
      "* Acc@1 96.607 Acc@5 100.000 loss 0.160\n",
      "[[135   2   0   3]\n",
      " [ 11 126   1   2]\n",
      " [  0   0 140   0]\n",
      " [  0   0   0 140]]\n",
      "(4, 4)\n",
      "Accuracy of the model on the 560 test images: 96.6%\n",
      "Max accuracy: 96.61%\n",
      "Epoch: [46]  [  0/227]  eta: 1:19:05  lr: 0.000007  min_lr: 0.000007  loss: 0.3493 (0.3493)  class_acc: 1.0000 (1.0000)  weight_decay: 0.0500 (0.0500)  time: 20.9047  data: 20.7626  max mem: 2500\n",
      "Epoch: [46]  [ 10/227]  eta: 0:07:18  lr: 0.000007  min_lr: 0.000007  loss: 0.3498 (0.3659)  class_acc: 1.0000 (0.9909)  weight_decay: 0.0500 (0.0500)  time: 2.0213  data: 1.8875  max mem: 2500\n",
      "Epoch: [46]  [ 20/227]  eta: 0:03:52  lr: 0.000007  min_lr: 0.000007  loss: 0.3522 (0.3871)  class_acc: 1.0000 (0.9762)  weight_decay: 0.0500 (0.0500)  time: 0.1343  data: 0.0001  max mem: 2500\n",
      "Epoch: [46]  [ 30/227]  eta: 0:02:38  lr: 0.000007  min_lr: 0.000007  loss: 0.3640 (0.4010)  class_acc: 1.0000 (0.9742)  weight_decay: 0.0500 (0.0500)  time: 0.1354  data: 0.0002  max mem: 2500\n",
      "Epoch: [46]  [ 40/227]  eta: 0:01:59  lr: 0.000007  min_lr: 0.000007  loss: 0.3502 (0.3907)  class_acc: 1.0000 (0.9805)  weight_decay: 0.0500 (0.0500)  time: 0.1337  data: 0.0002  max mem: 2500\n",
      "Epoch: [46]  [ 50/227]  eta: 0:01:35  lr: 0.000007  min_lr: 0.000007  loss: 0.3497 (0.3837)  class_acc: 1.0000 (0.9843)  weight_decay: 0.0500 (0.0500)  time: 0.1344  data: 0.0003  max mem: 2500\n",
      "Epoch: [46]  [ 60/227]  eta: 0:01:19  lr: 0.000006  min_lr: 0.000006  loss: 0.3510 (0.3818)  class_acc: 1.0000 (0.9836)  weight_decay: 0.0500 (0.0500)  time: 0.1358  data: 0.0002  max mem: 2500\n",
      "Epoch: [46]  [ 70/227]  eta: 0:01:07  lr: 0.000006  min_lr: 0.000006  loss: 0.3626 (0.3891)  class_acc: 1.0000 (0.9803)  weight_decay: 0.0500 (0.0500)  time: 0.1337  data: 0.0001  max mem: 2500\n",
      "Epoch: [46]  [ 80/227]  eta: 0:00:57  lr: 0.000006  min_lr: 0.000006  loss: 0.3552 (0.3870)  class_acc: 1.0000 (0.9815)  weight_decay: 0.0500 (0.0500)  time: 0.1333  data: 0.0003  max mem: 2500\n",
      "Epoch: [46]  [ 90/227]  eta: 0:00:49  lr: 0.000006  min_lr: 0.000006  loss: 0.3516 (0.3892)  class_acc: 1.0000 (0.9802)  weight_decay: 0.0500 (0.0500)  time: 0.1336  data: 0.0002  max mem: 2500\n",
      "Epoch: [46]  [100/227]  eta: 0:00:43  lr: 0.000006  min_lr: 0.000006  loss: 0.3516 (0.3895)  class_acc: 1.0000 (0.9782)  weight_decay: 0.0500 (0.0500)  time: 0.1330  data: 0.0001  max mem: 2500\n",
      "Epoch: [46]  [110/227]  eta: 0:00:37  lr: 0.000006  min_lr: 0.000006  loss: 0.3575 (0.3904)  class_acc: 1.0000 (0.9784)  weight_decay: 0.0500 (0.0500)  time: 0.1339  data: 0.0001  max mem: 2500\n",
      "Epoch: [46]  [120/227]  eta: 0:00:32  lr: 0.000006  min_lr: 0.000006  loss: 0.3515 (0.3887)  class_acc: 1.0000 (0.9785)  weight_decay: 0.0500 (0.0500)  time: 0.1348  data: 0.0002  max mem: 2500\n",
      "Epoch: [46]  [130/227]  eta: 0:00:28  lr: 0.000006  min_lr: 0.000006  loss: 0.3552 (0.3906)  class_acc: 1.0000 (0.9786)  weight_decay: 0.0500 (0.0500)  time: 0.1338  data: 0.0002  max mem: 2500\n",
      "Epoch: [46]  [140/227]  eta: 0:00:24  lr: 0.000005  min_lr: 0.000005  loss: 0.3604 (0.3905)  class_acc: 1.0000 (0.9780)  weight_decay: 0.0500 (0.0500)  time: 0.1327  data: 0.0001  max mem: 2500\n",
      "Epoch: [46]  [150/227]  eta: 0:00:20  lr: 0.000005  min_lr: 0.000005  loss: 0.3544 (0.3885)  class_acc: 1.0000 (0.9795)  weight_decay: 0.0500 (0.0500)  time: 0.1338  data: 0.0001  max mem: 2500\n",
      "Epoch: [46]  [160/227]  eta: 0:00:17  lr: 0.000005  min_lr: 0.000005  loss: 0.3566 (0.3908)  class_acc: 1.0000 (0.9776)  weight_decay: 0.0500 (0.0500)  time: 0.1337  data: 0.0001  max mem: 2500\n",
      "Epoch: [46]  [170/227]  eta: 0:00:14  lr: 0.000005  min_lr: 0.000005  loss: 0.3750 (0.3905)  class_acc: 1.0000 (0.9778)  weight_decay: 0.0500 (0.0500)  time: 0.1334  data: 0.0001  max mem: 2500\n",
      "Epoch: [46]  [180/227]  eta: 0:00:11  lr: 0.000005  min_lr: 0.000005  loss: 0.3598 (0.3910)  class_acc: 1.0000 (0.9768)  weight_decay: 0.0500 (0.0500)  time: 0.1355  data: 0.0001  max mem: 2500\n",
      "Epoch: [46]  [190/227]  eta: 0:00:08  lr: 0.000005  min_lr: 0.000005  loss: 0.3559 (0.3909)  class_acc: 1.0000 (0.9764)  weight_decay: 0.0500 (0.0500)  time: 0.1361  data: 0.0001  max mem: 2500\n",
      "Epoch: [46]  [200/227]  eta: 0:00:06  lr: 0.000005  min_lr: 0.000005  loss: 0.3559 (0.3912)  class_acc: 1.0000 (0.9761)  weight_decay: 0.0500 (0.0500)  time: 0.1339  data: 0.0002  max mem: 2500\n",
      "Epoch: [46]  [210/227]  eta: 0:00:03  lr: 0.000005  min_lr: 0.000005  loss: 0.3528 (0.3909)  class_acc: 1.0000 (0.9758)  weight_decay: 0.0500 (0.0500)  time: 0.1343  data: 0.0002  max mem: 2500\n",
      "Epoch: [46]  [220/227]  eta: 0:00:01  lr: 0.000005  min_lr: 0.000005  loss: 0.3535 (0.3900)  class_acc: 1.0000 (0.9765)  weight_decay: 0.0500 (0.0500)  time: 0.1345  data: 0.0001  max mem: 2500\n",
      "Epoch: [46]  [226/227]  eta: 0:00:00  lr: 0.000005  min_lr: 0.000005  loss: 0.3564 (0.3907)  class_acc: 1.0000 (0.9762)  weight_decay: 0.0500 (0.0500)  time: 0.1330  data: 0.0001  max mem: 2500\n",
      "Epoch: [46] Total time: 0:00:51 (0.2278 s / it)\n",
      "Averaged stats: lr: 0.000005  min_lr: 0.000005  loss: 0.3564 (0.3907)  class_acc: 1.0000 (0.9762)  weight_decay: 0.0500 (0.0500)\n",
      "Test:  [ 0/38]  eta: 0:13:04  loss: 0.0805 (0.0805)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 20.6537  data: 20.5987  max mem: 2500\n",
      "Test:  [10/38]  eta: 0:00:53  loss: 0.0937 (0.1445)  acc1: 100.0000 (96.9697)  acc5: 100.0000 (100.0000)  time: 1.9200  data: 1.8727  max mem: 2500\n",
      "Test:  [20/38]  eta: 0:00:18  loss: 0.1430 (0.2358)  acc1: 93.3333 (93.6508)  acc5: 100.0000 (100.0000)  time: 0.0467  data: 0.0001  max mem: 2500\n",
      "Test:  [30/38]  eta: 0:00:05  loss: 0.0779 (0.1848)  acc1: 100.0000 (95.6989)  acc5: 100.0000 (100.0000)  time: 0.0466  data: 0.0001  max mem: 2500\n",
      "Test:  [37/38]  eta: 0:00:00  loss: 0.0779 (0.1665)  acc1: 100.0000 (96.4286)  acc5: 100.0000 (100.0000)  time: 0.0450  data: 0.0002  max mem: 2500\n",
      "Test: Total time: 0:00:22 (0.6013 s / it)\n",
      "* Acc@1 96.429 Acc@5 100.000 loss 0.166\n",
      "[[135   2   0   3]\n",
      " [ 11 125   2   2]\n",
      " [  0   0 140   0]\n",
      " [  0   0   0 140]]\n",
      "(4, 4)\n",
      "Accuracy of the model on the 560 test images: 96.4%\n",
      "Max accuracy: 96.61%\n",
      "Epoch: [47]  [  0/227]  eta: 1:18:26  lr: 0.000005  min_lr: 0.000005  loss: 0.3494 (0.3494)  class_acc: 1.0000 (1.0000)  weight_decay: 0.0500 (0.0500)  time: 20.7328  data: 20.5907  max mem: 2500\n",
      "Epoch: [47]  [ 10/227]  eta: 0:07:15  lr: 0.000004  min_lr: 0.000004  loss: 0.3494 (0.3808)  class_acc: 1.0000 (0.9818)  weight_decay: 0.0500 (0.0500)  time: 2.0065  data: 1.8721  max mem: 2500\n",
      "Epoch: [47]  [ 20/227]  eta: 0:03:51  lr: 0.000004  min_lr: 0.000004  loss: 0.3498 (0.3724)  class_acc: 1.0000 (0.9857)  weight_decay: 0.0500 (0.0500)  time: 0.1357  data: 0.0001  max mem: 2500\n",
      "Epoch: [47]  [ 30/227]  eta: 0:02:37  lr: 0.000004  min_lr: 0.000004  loss: 0.3549 (0.3780)  class_acc: 1.0000 (0.9839)  weight_decay: 0.0500 (0.0500)  time: 0.1354  data: 0.0000  max mem: 2500\n",
      "Epoch: [47]  [ 40/227]  eta: 0:01:59  lr: 0.000004  min_lr: 0.000004  loss: 0.3549 (0.3850)  class_acc: 1.0000 (0.9805)  weight_decay: 0.0500 (0.0500)  time: 0.1335  data: 0.0000  max mem: 2500\n",
      "Epoch: [47]  [ 50/227]  eta: 0:01:35  lr: 0.000004  min_lr: 0.000004  loss: 0.3528 (0.3845)  class_acc: 1.0000 (0.9804)  weight_decay: 0.0500 (0.0500)  time: 0.1342  data: 0.0002  max mem: 2500\n",
      "Epoch: [47]  [ 60/227]  eta: 0:01:18  lr: 0.000004  min_lr: 0.000004  loss: 0.3524 (0.3865)  class_acc: 1.0000 (0.9803)  weight_decay: 0.0500 (0.0500)  time: 0.1348  data: 0.0002  max mem: 2500\n",
      "Epoch: [47]  [ 70/227]  eta: 0:01:06  lr: 0.000004  min_lr: 0.000004  loss: 0.3523 (0.3819)  class_acc: 1.0000 (0.9831)  weight_decay: 0.0500 (0.0500)  time: 0.1349  data: 0.0001  max mem: 2500\n",
      "Epoch: [47]  [ 80/227]  eta: 0:00:57  lr: 0.000004  min_lr: 0.000004  loss: 0.3529 (0.3830)  class_acc: 1.0000 (0.9827)  weight_decay: 0.0500 (0.0500)  time: 0.1349  data: 0.0003  max mem: 2500\n",
      "Epoch: [47]  [ 90/227]  eta: 0:00:49  lr: 0.000004  min_lr: 0.000004  loss: 0.3526 (0.3818)  class_acc: 1.0000 (0.9824)  weight_decay: 0.0500 (0.0500)  time: 0.1344  data: 0.0003  max mem: 2500\n",
      "Epoch: [47]  [100/227]  eta: 0:00:42  lr: 0.000004  min_lr: 0.000004  loss: 0.3525 (0.3807)  class_acc: 1.0000 (0.9832)  weight_decay: 0.0500 (0.0500)  time: 0.1339  data: 0.0002  max mem: 2500\n",
      "Epoch: [47]  [110/227]  eta: 0:00:37  lr: 0.000003  min_lr: 0.000003  loss: 0.3520 (0.3782)  class_acc: 1.0000 (0.9847)  weight_decay: 0.0500 (0.0500)  time: 0.1334  data: 0.0001  max mem: 2500\n",
      "Epoch: [47]  [120/227]  eta: 0:00:32  lr: 0.000003  min_lr: 0.000003  loss: 0.3506 (0.3762)  class_acc: 1.0000 (0.9860)  weight_decay: 0.0500 (0.0500)  time: 0.1334  data: 0.0002  max mem: 2500\n",
      "Epoch: [47]  [130/227]  eta: 0:00:28  lr: 0.000003  min_lr: 0.000003  loss: 0.3507 (0.3761)  class_acc: 1.0000 (0.9855)  weight_decay: 0.0500 (0.0500)  time: 0.1330  data: 0.0003  max mem: 2500\n",
      "Epoch: [47]  [140/227]  eta: 0:00:24  lr: 0.000003  min_lr: 0.000003  loss: 0.3513 (0.3784)  class_acc: 1.0000 (0.9851)  weight_decay: 0.0500 (0.0500)  time: 0.1347  data: 0.0003  max mem: 2500\n",
      "Epoch: [47]  [150/227]  eta: 0:00:20  lr: 0.000003  min_lr: 0.000003  loss: 0.3541 (0.3810)  class_acc: 1.0000 (0.9834)  weight_decay: 0.0500 (0.0500)  time: 0.1360  data: 0.0002  max mem: 2500\n",
      "Epoch: [47]  [160/227]  eta: 0:00:17  lr: 0.000003  min_lr: 0.000003  loss: 0.3538 (0.3819)  class_acc: 1.0000 (0.9826)  weight_decay: 0.0500 (0.0500)  time: 0.1348  data: 0.0001  max mem: 2500\n",
      "Epoch: [47]  [170/227]  eta: 0:00:14  lr: 0.000003  min_lr: 0.000003  loss: 0.3518 (0.3817)  class_acc: 1.0000 (0.9830)  weight_decay: 0.0500 (0.0500)  time: 0.1354  data: 0.0002  max mem: 2500\n",
      "Epoch: [47]  [180/227]  eta: 0:00:11  lr: 0.000003  min_lr: 0.000003  loss: 0.3510 (0.3822)  class_acc: 1.0000 (0.9834)  weight_decay: 0.0500 (0.0500)  time: 0.1365  data: 0.0002  max mem: 2500\n",
      "Epoch: [47]  [190/227]  eta: 0:00:08  lr: 0.000003  min_lr: 0.000003  loss: 0.3531 (0.3811)  class_acc: 1.0000 (0.9843)  weight_decay: 0.0500 (0.0500)  time: 0.1352  data: 0.0002  max mem: 2500\n",
      "Epoch: [47]  [200/227]  eta: 0:00:06  lr: 0.000003  min_lr: 0.000003  loss: 0.3535 (0.3818)  class_acc: 1.0000 (0.9841)  weight_decay: 0.0500 (0.0500)  time: 0.1327  data: 0.0002  max mem: 2500\n",
      "Epoch: [47]  [210/227]  eta: 0:00:03  lr: 0.000003  min_lr: 0.000003  loss: 0.3535 (0.3835)  class_acc: 1.0000 (0.9834)  weight_decay: 0.0500 (0.0500)  time: 0.1337  data: 0.0002  max mem: 2500\n",
      "Epoch: [47]  [220/227]  eta: 0:00:01  lr: 0.000003  min_lr: 0.000003  loss: 0.3501 (0.3829)  class_acc: 1.0000 (0.9833)  weight_decay: 0.0500 (0.0500)  time: 0.1352  data: 0.0002  max mem: 2500\n",
      "Epoch: [47]  [226/227]  eta: 0:00:00  lr: 0.000003  min_lr: 0.000003  loss: 0.3501 (0.3821)  class_acc: 1.0000 (0.9837)  weight_decay: 0.0500 (0.0500)  time: 0.1342  data: 0.0002  max mem: 2500\n",
      "Epoch: [47] Total time: 0:00:51 (0.2275 s / it)\n",
      "Averaged stats: lr: 0.000003  min_lr: 0.000003  loss: 0.3501 (0.3821)  class_acc: 1.0000 (0.9837)  weight_decay: 0.0500 (0.0500)\n",
      "Test:  [ 0/38]  eta: 0:13:03  loss: 0.0809 (0.0809)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 20.6315  data: 20.5755  max mem: 2500\n",
      "Test:  [10/38]  eta: 0:00:53  loss: 0.1012 (0.1498)  acc1: 100.0000 (96.9697)  acc5: 100.0000 (100.0000)  time: 1.9180  data: 1.8705  max mem: 2500\n",
      "Test:  [20/38]  eta: 0:00:18  loss: 0.1407 (0.2241)  acc1: 93.3333 (93.6508)  acc5: 100.0000 (100.0000)  time: 0.0467  data: 0.0000  max mem: 2500\n",
      "Test:  [30/38]  eta: 0:00:05  loss: 0.0779 (0.1770)  acc1: 100.0000 (95.6989)  acc5: 100.0000 (100.0000)  time: 0.0466  data: 0.0001  max mem: 2500\n",
      "Test:  [37/38]  eta: 0:00:00  loss: 0.0779 (0.1600)  acc1: 100.0000 (96.4286)  acc5: 100.0000 (100.0000)  time: 0.0449  data: 0.0001  max mem: 2500\n",
      "Test: Total time: 0:00:22 (0.6006 s / it)\n",
      "* Acc@1 96.429 Acc@5 100.000 loss 0.160\n",
      "[[135   2   0   3]\n",
      " [ 11 125   2   2]\n",
      " [  0   0 140   0]\n",
      " [  0   0   0 140]]\n",
      "(4, 4)\n",
      "Accuracy of the model on the 560 test images: 96.4%\n",
      "Max accuracy: 96.61%\n",
      "Epoch: [48]  [  0/227]  eta: 1:18:52  lr: 0.000003  min_lr: 0.000003  loss: 0.3490 (0.3490)  class_acc: 1.0000 (1.0000)  weight_decay: 0.0500 (0.0500)  time: 20.8461  data: 20.7001  max mem: 2500\n",
      "Epoch: [48]  [ 10/227]  eta: 0:07:17  lr: 0.000003  min_lr: 0.000003  loss: 0.3498 (0.3856)  class_acc: 1.0000 (0.9818)  weight_decay: 0.0500 (0.0500)  time: 2.0174  data: 1.8821  max mem: 2500\n",
      "Epoch: [48]  [ 20/227]  eta: 0:03:52  lr: 0.000002  min_lr: 0.000002  loss: 0.3502 (0.3804)  class_acc: 1.0000 (0.9857)  weight_decay: 0.0500 (0.0500)  time: 0.1347  data: 0.0002  max mem: 2500\n",
      "Epoch: [48]  [ 30/227]  eta: 0:02:38  lr: 0.000002  min_lr: 0.000002  loss: 0.3607 (0.3822)  class_acc: 1.0000 (0.9806)  weight_decay: 0.0500 (0.0500)  time: 0.1363  data: 0.0001  max mem: 2500\n",
      "Epoch: [48]  [ 40/227]  eta: 0:01:59  lr: 0.000002  min_lr: 0.000002  loss: 0.3591 (0.3872)  class_acc: 1.0000 (0.9780)  weight_decay: 0.0500 (0.0500)  time: 0.1357  data: 0.0001  max mem: 2500\n",
      "Epoch: [48]  [ 50/227]  eta: 0:01:35  lr: 0.000002  min_lr: 0.000002  loss: 0.3614 (0.3851)  class_acc: 1.0000 (0.9804)  weight_decay: 0.0500 (0.0500)  time: 0.1346  data: 0.0000  max mem: 2500\n",
      "Epoch: [48]  [ 60/227]  eta: 0:01:19  lr: 0.000002  min_lr: 0.000002  loss: 0.3509 (0.3866)  class_acc: 1.0000 (0.9803)  weight_decay: 0.0500 (0.0500)  time: 0.1344  data: 0.0000  max mem: 2500\n",
      "Epoch: [48]  [ 70/227]  eta: 0:01:06  lr: 0.000002  min_lr: 0.000002  loss: 0.3530 (0.3925)  class_acc: 1.0000 (0.9746)  weight_decay: 0.0500 (0.0500)  time: 0.1342  data: 0.0001  max mem: 2500\n",
      "Epoch: [48]  [ 80/227]  eta: 0:00:57  lr: 0.000002  min_lr: 0.000002  loss: 0.4070 (0.3919)  class_acc: 1.0000 (0.9753)  weight_decay: 0.0500 (0.0500)  time: 0.1358  data: 0.0002  max mem: 2500\n",
      "Epoch: [48]  [ 90/227]  eta: 0:00:49  lr: 0.000002  min_lr: 0.000002  loss: 0.3554 (0.3884)  class_acc: 1.0000 (0.9769)  weight_decay: 0.0500 (0.0500)  time: 0.1357  data: 0.0002  max mem: 2500\n",
      "Epoch: [48]  [100/227]  eta: 0:00:43  lr: 0.000002  min_lr: 0.000002  loss: 0.3614 (0.3967)  class_acc: 1.0000 (0.9713)  weight_decay: 0.0500 (0.0500)  time: 0.1344  data: 0.0003  max mem: 2500\n",
      "Epoch: [48]  [110/227]  eta: 0:00:37  lr: 0.000002  min_lr: 0.000002  loss: 0.3530 (0.3929)  class_acc: 1.0000 (0.9739)  weight_decay: 0.0500 (0.0500)  time: 0.1329  data: 0.0003  max mem: 2500\n",
      "Epoch: [48]  [120/227]  eta: 0:00:32  lr: 0.000002  min_lr: 0.000002  loss: 0.3529 (0.3914)  class_acc: 1.0000 (0.9752)  weight_decay: 0.0500 (0.0500)  time: 0.1337  data: 0.0003  max mem: 2500\n",
      "Epoch: [48]  [130/227]  eta: 0:00:28  lr: 0.000002  min_lr: 0.000002  loss: 0.3522 (0.3916)  class_acc: 1.0000 (0.9740)  weight_decay: 0.0500 (0.0500)  time: 0.1338  data: 0.0001  max mem: 2500\n",
      "Epoch: [48]  [140/227]  eta: 0:00:24  lr: 0.000002  min_lr: 0.000002  loss: 0.3512 (0.3913)  class_acc: 1.0000 (0.9752)  weight_decay: 0.0500 (0.0500)  time: 0.1339  data: 0.0000  max mem: 2500\n",
      "Epoch: [48]  [150/227]  eta: 0:00:20  lr: 0.000002  min_lr: 0.000002  loss: 0.3519 (0.3924)  class_acc: 1.0000 (0.9755)  weight_decay: 0.0500 (0.0500)  time: 0.1344  data: 0.0001  max mem: 2500\n",
      "Epoch: [48]  [160/227]  eta: 0:00:17  lr: 0.000002  min_lr: 0.000002  loss: 0.3507 (0.3914)  class_acc: 1.0000 (0.9764)  weight_decay: 0.0500 (0.0500)  time: 0.1353  data: 0.0001  max mem: 2500\n",
      "Epoch: [48]  [170/227]  eta: 0:00:14  lr: 0.000002  min_lr: 0.000002  loss: 0.3507 (0.3909)  class_acc: 1.0000 (0.9766)  weight_decay: 0.0500 (0.0500)  time: 0.1355  data: 0.0001  max mem: 2500\n",
      "Epoch: [48]  [180/227]  eta: 0:00:11  lr: 0.000002  min_lr: 0.000002  loss: 0.3522 (0.3893)  class_acc: 1.0000 (0.9773)  weight_decay: 0.0500 (0.0500)  time: 0.1343  data: 0.0002  max mem: 2500\n",
      "Epoch: [48]  [190/227]  eta: 0:00:08  lr: 0.000002  min_lr: 0.000002  loss: 0.3531 (0.3886)  class_acc: 1.0000 (0.9780)  weight_decay: 0.0500 (0.0500)  time: 0.1345  data: 0.0002  max mem: 2500\n",
      "Epoch: [48]  [200/227]  eta: 0:00:06  lr: 0.000001  min_lr: 0.000001  loss: 0.3597 (0.3886)  class_acc: 1.0000 (0.9781)  weight_decay: 0.0500 (0.0500)  time: 0.1334  data: 0.0002  max mem: 2500\n",
      "Epoch: [48]  [210/227]  eta: 0:00:03  lr: 0.000001  min_lr: 0.000001  loss: 0.3559 (0.3879)  class_acc: 1.0000 (0.9787)  weight_decay: 0.0500 (0.0500)  time: 0.1343  data: 0.0001  max mem: 2500\n",
      "Epoch: [48]  [220/227]  eta: 0:00:01  lr: 0.000001  min_lr: 0.000001  loss: 0.3553 (0.3872)  class_acc: 1.0000 (0.9792)  weight_decay: 0.0500 (0.0500)  time: 0.1339  data: 0.0002  max mem: 2500\n",
      "Epoch: [48]  [226/227]  eta: 0:00:00  lr: 0.000001  min_lr: 0.000001  loss: 0.3546 (0.3867)  class_acc: 1.0000 (0.9793)  weight_decay: 0.0500 (0.0500)  time: 0.1339  data: 0.0002  max mem: 2500\n",
      "Epoch: [48] Total time: 0:00:51 (0.2281 s / it)\n",
      "Averaged stats: lr: 0.000001  min_lr: 0.000001  loss: 0.3546 (0.3867)  class_acc: 1.0000 (0.9793)  weight_decay: 0.0500 (0.0500)\n",
      "Test:  [ 0/38]  eta: 0:13:09  loss: 0.0818 (0.0818)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 20.7771  data: 20.7101  max mem: 2500\n",
      "Test:  [10/38]  eta: 0:00:54  loss: 0.1035 (0.1525)  acc1: 100.0000 (96.9697)  acc5: 100.0000 (100.0000)  time: 1.9310  data: 1.8828  max mem: 2500\n",
      "Test:  [20/38]  eta: 0:00:18  loss: 0.1512 (0.2246)  acc1: 93.3333 (93.9683)  acc5: 100.0000 (100.0000)  time: 0.0466  data: 0.0002  max mem: 2500\n",
      "Test:  [30/38]  eta: 0:00:05  loss: 0.0777 (0.1773)  acc1: 100.0000 (95.9140)  acc5: 100.0000 (100.0000)  time: 0.0466  data: 0.0002  max mem: 2500\n",
      "Test:  [37/38]  eta: 0:00:00  loss: 0.0775 (0.1599)  acc1: 100.0000 (96.6071)  acc5: 100.0000 (100.0000)  time: 0.0450  data: 0.0000  max mem: 2500\n",
      "Test: Total time: 0:00:22 (0.6045 s / it)\n",
      "* Acc@1 96.607 Acc@5 100.000 loss 0.160\n",
      "[[135   2   0   3]\n",
      " [ 10 126   2   2]\n",
      " [  0   0 140   0]\n",
      " [  0   0   0 140]]\n",
      "(4, 4)\n",
      "Accuracy of the model on the 560 test images: 96.6%\n",
      "Max accuracy: 96.61%\n",
      "Epoch: [49]  [  0/227]  eta: 1:18:35  lr: 0.000001  min_lr: 0.000001  loss: 0.3567 (0.3567)  class_acc: 1.0000 (1.0000)  weight_decay: 0.0500 (0.0500)  time: 20.7741  data: 20.6261  max mem: 2500\n",
      "Epoch: [49]  [ 10/227]  eta: 0:07:16  lr: 0.000001  min_lr: 0.000001  loss: 0.3497 (0.3538)  class_acc: 1.0000 (1.0000)  weight_decay: 0.0500 (0.0500)  time: 2.0104  data: 1.8752  max mem: 2500\n",
      "Epoch: [49]  [ 20/227]  eta: 0:03:51  lr: 0.000001  min_lr: 0.000001  loss: 0.3507 (0.3608)  class_acc: 1.0000 (0.9952)  weight_decay: 0.0500 (0.0500)  time: 0.1331  data: 0.0001  max mem: 2500\n",
      "Epoch: [49]  [ 30/227]  eta: 0:02:37  lr: 0.000001  min_lr: 0.000001  loss: 0.3588 (0.3753)  class_acc: 1.0000 (0.9871)  weight_decay: 0.0500 (0.0500)  time: 0.1336  data: 0.0002  max mem: 2500\n",
      "Epoch: [49]  [ 40/227]  eta: 0:01:59  lr: 0.000001  min_lr: 0.000001  loss: 0.3520 (0.3709)  class_acc: 1.0000 (0.9902)  weight_decay: 0.0500 (0.0500)  time: 0.1345  data: 0.0002  max mem: 2500\n",
      "Epoch: [49]  [ 50/227]  eta: 0:01:35  lr: 0.000001  min_lr: 0.000001  loss: 0.3499 (0.3727)  class_acc: 1.0000 (0.9882)  weight_decay: 0.0500 (0.0500)  time: 0.1346  data: 0.0002  max mem: 2500\n",
      "Epoch: [49]  [ 60/227]  eta: 0:01:18  lr: 0.000001  min_lr: 0.000001  loss: 0.3503 (0.3749)  class_acc: 1.0000 (0.9869)  weight_decay: 0.0500 (0.0500)  time: 0.1348  data: 0.0001  max mem: 2500\n",
      "Epoch: [49]  [ 70/227]  eta: 0:01:06  lr: 0.000001  min_lr: 0.000001  loss: 0.3522 (0.3744)  class_acc: 1.0000 (0.9873)  weight_decay: 0.0500 (0.0500)  time: 0.1344  data: 0.0000  max mem: 2500\n",
      "Epoch: [49]  [ 80/227]  eta: 0:00:57  lr: 0.000001  min_lr: 0.000001  loss: 0.3598 (0.3751)  class_acc: 1.0000 (0.9877)  weight_decay: 0.0500 (0.0500)  time: 0.1343  data: 0.0001  max mem: 2500\n",
      "Epoch: [49]  [ 90/227]  eta: 0:00:49  lr: 0.000001  min_lr: 0.000001  loss: 0.3509 (0.3741)  class_acc: 1.0000 (0.9890)  weight_decay: 0.0500 (0.0500)  time: 0.1347  data: 0.0001  max mem: 2500\n",
      "Epoch: [49]  [100/227]  eta: 0:00:43  lr: 0.000001  min_lr: 0.000001  loss: 0.3531 (0.3768)  class_acc: 1.0000 (0.9871)  weight_decay: 0.0500 (0.0500)  time: 0.1345  data: 0.0001  max mem: 2500\n",
      "Epoch: [49]  [110/227]  eta: 0:00:37  lr: 0.000001  min_lr: 0.000001  loss: 0.3614 (0.3753)  class_acc: 1.0000 (0.9883)  weight_decay: 0.0500 (0.0500)  time: 0.1335  data: 0.0002  max mem: 2500\n",
      "Epoch: [49]  [120/227]  eta: 0:00:32  lr: 0.000001  min_lr: 0.000001  loss: 0.3605 (0.3779)  class_acc: 1.0000 (0.9868)  weight_decay: 0.0500 (0.0500)  time: 0.1340  data: 0.0003  max mem: 2500\n",
      "Epoch: [49]  [130/227]  eta: 0:00:28  lr: 0.000001  min_lr: 0.000001  loss: 0.3605 (0.3819)  class_acc: 1.0000 (0.9832)  weight_decay: 0.0500 (0.0500)  time: 0.1346  data: 0.0002  max mem: 2500\n",
      "Epoch: [49]  [140/227]  eta: 0:00:24  lr: 0.000001  min_lr: 0.000001  loss: 0.3517 (0.3826)  class_acc: 1.0000 (0.9830)  weight_decay: 0.0500 (0.0500)  time: 0.1340  data: 0.0001  max mem: 2500\n",
      "Epoch: [49]  [150/227]  eta: 0:00:20  lr: 0.000001  min_lr: 0.000001  loss: 0.3507 (0.3843)  class_acc: 1.0000 (0.9821)  weight_decay: 0.0500 (0.0500)  time: 0.1341  data: 0.0001  max mem: 2500\n",
      "Epoch: [49]  [160/227]  eta: 0:00:17  lr: 0.000001  min_lr: 0.000001  loss: 0.3517 (0.3829)  class_acc: 1.0000 (0.9832)  weight_decay: 0.0500 (0.0500)  time: 0.1341  data: 0.0002  max mem: 2500\n",
      "Epoch: [49]  [170/227]  eta: 0:00:14  lr: 0.000001  min_lr: 0.000001  loss: 0.3573 (0.3839)  class_acc: 1.0000 (0.9836)  weight_decay: 0.0500 (0.0500)  time: 0.1337  data: 0.0001  max mem: 2500\n",
      "Epoch: [49]  [180/227]  eta: 0:00:11  lr: 0.000001  min_lr: 0.000001  loss: 0.3592 (0.3827)  class_acc: 1.0000 (0.9845)  weight_decay: 0.0500 (0.0500)  time: 0.1329  data: 0.0002  max mem: 2500\n",
      "Epoch: [49]  [190/227]  eta: 0:00:08  lr: 0.000001  min_lr: 0.000001  loss: 0.3543 (0.3831)  class_acc: 1.0000 (0.9838)  weight_decay: 0.0500 (0.0500)  time: 0.1328  data: 0.0002  max mem: 2500\n",
      "Epoch: [49]  [200/227]  eta: 0:00:06  lr: 0.000001  min_lr: 0.000001  loss: 0.3553 (0.3847)  class_acc: 1.0000 (0.9826)  weight_decay: 0.0500 (0.0500)  time: 0.1334  data: 0.0001  max mem: 2500\n",
      "Epoch: [49]  [210/227]  eta: 0:00:03  lr: 0.000001  min_lr: 0.000001  loss: 0.3840 (0.3869)  class_acc: 1.0000 (0.9820)  weight_decay: 0.0500 (0.0500)  time: 0.1345  data: 0.0002  max mem: 2500\n",
      "Epoch: [49]  [220/227]  eta: 0:00:01  lr: 0.000001  min_lr: 0.000001  loss: 0.3543 (0.3869)  class_acc: 1.0000 (0.9819)  weight_decay: 0.0500 (0.0500)  time: 0.1347  data: 0.0001  max mem: 2500\n",
      "Epoch: [49]  [226/227]  eta: 0:00:00  lr: 0.000001  min_lr: 0.000001  loss: 0.3533 (0.3862)  class_acc: 1.0000 (0.9824)  weight_decay: 0.0500 (0.0500)  time: 0.1339  data: 0.0001  max mem: 2500\n",
      "Epoch: [49] Total time: 0:00:51 (0.2274 s / it)\n",
      "Averaged stats: lr: 0.000001  min_lr: 0.000001  loss: 0.3533 (0.3862)  class_acc: 1.0000 (0.9824)  weight_decay: 0.0500 (0.0500)\n",
      "Test:  [ 0/38]  eta: 0:13:08  loss: 0.0821 (0.0821)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 20.7469  data: 20.6869  max mem: 2500\n",
      "Test:  [10/38]  eta: 0:00:53  loss: 0.1061 (0.1547)  acc1: 100.0000 (96.9697)  acc5: 100.0000 (100.0000)  time: 1.9285  data: 1.8807  max mem: 2500\n",
      "Test:  [20/38]  eta: 0:00:18  loss: 0.1542 (0.2256)  acc1: 93.3333 (93.9683)  acc5: 100.0000 (100.0000)  time: 0.0467  data: 0.0002  max mem: 2500\n",
      "Test:  [30/38]  eta: 0:00:05  loss: 0.0774 (0.1778)  acc1: 100.0000 (95.9140)  acc5: 100.0000 (100.0000)  time: 0.0465  data: 0.0002  max mem: 2500\n",
      "Test:  [37/38]  eta: 0:00:00  loss: 0.0774 (0.1603)  acc1: 100.0000 (96.6071)  acc5: 100.0000 (100.0000)  time: 0.0450  data: 0.0002  max mem: 2500\n",
      "Test: Total time: 0:00:22 (0.6035 s / it)\n",
      "* Acc@1 96.607 Acc@5 100.000 loss 0.160\n",
      "[[135   2   0   3]\n",
      " [ 10 126   2   2]\n",
      " [  0   0 140   0]\n",
      " [  0   0   0 140]]\n",
      "(4, 4)\n",
      "Accuracy of the model on the 560 test images: 96.6%\n",
      "Max accuracy: 96.61%\n",
      "Training time 1:03:19\n"
     ]
    }
   ],
   "source": [
    "!python main.py --epochs 50 \\\n",
    "                --model convnext_tiny \\\n",
    "                --data_set image_folder \\\n",
    "                --data_path C:/Users/qiezh/Desktop/FYP/FYPConvNext/ChestXRays/train \\\n",
    "                --eval_data_path C:/Users/qiezh/Desktop/FYP/FYPConvNext/ChestXRays/val \\\n",
    "                --batch_size 10 \\\n",
    "                --nb_classes 4 \\\n",
    "                --num_workers 8 \\\n",
    "                --warmup_epochs 0 \\\n",
    "                --save_ckpt true \\\n",
    "                --output_dir C:/Users/qiezh/Desktop/FYP/FYPConvNext/ConvNextResults/Results50epoch \\\n",
    "                --finetune convnext_tiny_1k_224_ema.pth \\\n",
    "                --cutmix 0 \\\n",
    "                --mixup 0 --lr 4e-4 \\\n",
    "                --enable_wandb true --wandb_ckpt true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d4ab7ed1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not using distributed mode\n",
      "Namespace(aa='rand-m9-mstd0.5-inc1', auto_resume=True, batch_size=64, clip_grad=None, color_jitter=0.4, crop_pct=None, cutmix=1.0, cutmix_minmax=None, data_path='C:/Users/qiezh/Desktop/FYP/FYPConvNext/ChestXRays', data_set='IMNET', device='cuda', disable_eval=False, dist_eval=True, dist_on_itp=False, dist_url='env://', distributed=False, drop_path=0.2, enable_wandb=False, epochs=300, eval=True, eval_data_path=None, finetune='', head_init_scale=1.0, imagenet_default_mean_and_std=True, input_size=224, layer_decay=1.0, layer_scale_init_value=1e-06, local_rank=-1, log_dir=None, lr=0.004, min_lr=1e-06, mixup=0.8, mixup_mode='batch', mixup_prob=1.0, mixup_switch_prob=0.5, model='my_model', model_ema=False, model_ema_decay=0.9999, model_ema_eval=False, model_ema_force_cpu=False, model_key='model|module', model_prefix='', momentum=0.9, nb_classes=4, num_workers=10, opt='adamw', opt_betas=None, opt_eps=1e-08, output_dir='', pin_mem=True, project='convnext', recount=1, remode='pixel', reprob=0.25, resplit=False, resume='', save_ckpt=True, save_ckpt_freq=1, save_ckpt_num=3, seed=0, smoothing=0.1, start_epoch=0, train_interpolation='bicubic', update_freq=1, use_amp=False, wandb_ckpt=False, warmup_epochs=20, warmup_steps=-1, weight_decay=0.05, weight_decay_end=None, world_size=1)\n",
      "Transform = \n",
      "RandomResizedCropAndInterpolation(size=(224, 224), scale=(0.08, 1.0), ratio=(0.75, 1.3333), interpolation=PIL.Image.BICUBIC)\n",
      "RandomHorizontalFlip(p=0.5)\n",
      "<timm.data.auto_augment.RandAugment object at 0x000001E18C81ED90>\n",
      "ToTensor()\n",
      "Normalize(mean=tensor([0.4850, 0.4560, 0.4060]), std=tensor([0.2290, 0.2240, 0.2250]))\n",
      "<timm.data.random_erasing.RandomErasing object at 0x000001E18C82D160>\n",
      "---------------------------\n",
      "reading from datapath C:/Users/qiezh/Desktop/FYP/FYPConvNext/ChestXRays\n",
      "Number of the class = 1000\n",
      "Transform = \n",
      "Resize(size=256, interpolation=bicubic)\n",
      "CenterCrop(size=(224, 224))\n",
      "ToTensor()\n",
      "Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225))\n",
      "---------------------------\n",
      "reading from datapath C:/Users/qiezh/Desktop/FYP/FYPConvNext/ChestXRays\n",
      "Number of the class = 1000\n",
      "Sampler_train = <torch.utils.data.distributed.DistributedSampler object at 0x000001E18C81E550>\n",
      "Mixup is activated!\n",
      "Model = ConvNeXt_Zheng(\n",
      "  (downsample_layers): ModuleList(\n",
      "    (0): Sequential(\n",
      "      (0): Conv2d(3, 96, kernel_size=(4, 4), stride=(4, 4))\n",
      "      (1): LayerNorm()\n",
      "    )\n",
      "    (1): Sequential(\n",
      "      (0): LayerNorm()\n",
      "      (1): Conv2d(96, 192, kernel_size=(2, 2), stride=(2, 2))\n",
      "    )\n",
      "    (2): Sequential(\n",
      "      (0): LayerNorm()\n",
      "      (1): Conv2d(192, 384, kernel_size=(2, 2), stride=(2, 2))\n",
      "    )\n",
      "    (3): Sequential(\n",
      "      (0): LayerNorm()\n",
      "      (1): Conv2d(384, 768, kernel_size=(2, 2), stride=(2, 2))\n",
      "    )\n",
      "  )\n",
      "  (stages): ModuleList(\n",
      "    (0): Sequential(\n",
      "      (0): Block(\n",
      "        (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)\n",
      "        (norm): LayerNorm()\n",
      "        (pwconv1): Linear(in_features=96, out_features=384, bias=True)\n",
      "        (act): GELU()\n",
      "        (pwconv2): Linear(in_features=384, out_features=96, bias=True)\n",
      "        (drop_path): Identity()\n",
      "      )\n",
      "      (1): Block(\n",
      "        (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)\n",
      "        (norm): LayerNorm()\n",
      "        (pwconv1): Linear(in_features=96, out_features=384, bias=True)\n",
      "        (act): GELU()\n",
      "        (pwconv2): Linear(in_features=384, out_features=96, bias=True)\n",
      "        (drop_path): DropPath()\n",
      "      )\n",
      "      (2): Block(\n",
      "        (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)\n",
      "        (norm): LayerNorm()\n",
      "        (pwconv1): Linear(in_features=96, out_features=384, bias=True)\n",
      "        (act): GELU()\n",
      "        (pwconv2): Linear(in_features=384, out_features=96, bias=True)\n",
      "        (drop_path): DropPath()\n",
      "      )\n",
      "    )\n",
      "    (1): Sequential(\n",
      "      (0): Block(\n",
      "        (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)\n",
      "        (norm): LayerNorm()\n",
      "        (pwconv1): Linear(in_features=192, out_features=768, bias=True)\n",
      "        (act): GELU()\n",
      "        (pwconv2): Linear(in_features=768, out_features=192, bias=True)\n",
      "        (drop_path): DropPath()\n",
      "      )\n",
      "      (1): Block(\n",
      "        (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)\n",
      "        (norm): LayerNorm()\n",
      "        (pwconv1): Linear(in_features=192, out_features=768, bias=True)\n",
      "        (act): GELU()\n",
      "        (pwconv2): Linear(in_features=768, out_features=192, bias=True)\n",
      "        (drop_path): DropPath()\n",
      "      )\n",
      "      (2): Block(\n",
      "        (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)\n",
      "        (norm): LayerNorm()\n",
      "        (pwconv1): Linear(in_features=192, out_features=768, bias=True)\n",
      "        (act): GELU()\n",
      "        (pwconv2): Linear(in_features=768, out_features=192, bias=True)\n",
      "        (drop_path): DropPath()\n",
      "      )\n",
      "    )\n",
      "    (2): Sequential(\n",
      "      (0): Block(\n",
      "        (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n",
      "        (norm): LayerNorm()\n",
      "        (pwconv1): Linear(in_features=384, out_features=1536, bias=True)\n",
      "        (act): GELU()\n",
      "        (pwconv2): Linear(in_features=1536, out_features=384, bias=True)\n",
      "        (drop_path): DropPath()\n",
      "      )\n",
      "      (1): Block(\n",
      "        (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n",
      "        (norm): LayerNorm()\n",
      "        (pwconv1): Linear(in_features=384, out_features=1536, bias=True)\n",
      "        (act): GELU()\n",
      "        (pwconv2): Linear(in_features=1536, out_features=384, bias=True)\n",
      "        (drop_path): DropPath()\n",
      "      )\n",
      "      (2): Block(\n",
      "        (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n",
      "        (norm): LayerNorm()\n",
      "        (pwconv1): Linear(in_features=384, out_features=1536, bias=True)\n",
      "        (act): GELU()\n",
      "        (pwconv2): Linear(in_features=1536, out_features=384, bias=True)\n",
      "        (drop_path): DropPath()\n",
      "      )\n",
      "      (3): Block(\n",
      "        (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n",
      "        (norm): LayerNorm()\n",
      "        (pwconv1): Linear(in_features=384, out_features=1536, bias=True)\n",
      "        (act): GELU()\n",
      "        (pwconv2): Linear(in_features=1536, out_features=384, bias=True)\n",
      "        (drop_path): DropPath()\n",
      "      )\n",
      "      (4): Block(\n",
      "        (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n",
      "        (norm): LayerNorm()\n",
      "        (pwconv1): Linear(in_features=384, out_features=1536, bias=True)\n",
      "        (act): GELU()\n",
      "        (pwconv2): Linear(in_features=1536, out_features=384, bias=True)\n",
      "        (drop_path): DropPath()\n",
      "      )\n",
      "      (5): Block(\n",
      "        (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n",
      "        (norm): LayerNorm()\n",
      "        (pwconv1): Linear(in_features=384, out_features=1536, bias=True)\n",
      "        (act): GELU()\n",
      "        (pwconv2): Linear(in_features=1536, out_features=384, bias=True)\n",
      "        (drop_path): DropPath()\n",
      "      )\n",
      "      (6): Block(\n",
      "        (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n",
      "        (norm): LayerNorm()\n",
      "        (pwconv1): Linear(in_features=384, out_features=1536, bias=True)\n",
      "        (act): GELU()\n",
      "        (pwconv2): Linear(in_features=1536, out_features=384, bias=True)\n",
      "        (drop_path): DropPath()\n",
      "      )\n",
      "      (7): Block(\n",
      "        (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n",
      "        (norm): LayerNorm()\n",
      "        (pwconv1): Linear(in_features=384, out_features=1536, bias=True)\n",
      "        (act): GELU()\n",
      "        (pwconv2): Linear(in_features=1536, out_features=384, bias=True)\n",
      "        (drop_path): DropPath()\n",
      "      )\n",
      "      (8): Block(\n",
      "        (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n",
      "        (norm): LayerNorm()\n",
      "        (pwconv1): Linear(in_features=384, out_features=1536, bias=True)\n",
      "        (act): GELU()\n",
      "        (pwconv2): Linear(in_features=1536, out_features=384, bias=True)\n",
      "        (drop_path): DropPath()\n",
      "      )\n",
      "    )\n",
      "    (3): Sequential(\n",
      "      (0): Block(\n",
      "        (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)\n",
      "        (norm): LayerNorm()\n",
      "        (pwconv1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "        (act): GELU()\n",
      "        (pwconv2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        (drop_path): DropPath()\n",
      "      )\n",
      "      (1): Block(\n",
      "        (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)\n",
      "        (norm): LayerNorm()\n",
      "        (pwconv1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "        (act): GELU()\n",
      "        (pwconv2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        (drop_path): DropPath()\n",
      "      )\n",
      "      (2): Block(\n",
      "        (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)\n",
      "        (norm): LayerNorm()\n",
      "        (pwconv1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "        (act): GELU()\n",
      "        (pwconv2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        (drop_path): DropPath()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "  (head): Linear(in_features=768, out_features=4, bias=True)\n",
      ")\n",
      "number of params: 27823204\n",
      "LR = 0.00400000\n",
      "Batch size = 64\n",
      "Update frequent = 1\n",
      "Number of training examples = 2270\n",
      "Number of training training per epoch = 35\n",
      "Param groups = {\n",
      "  \"decay\": {\n",
      "    \"weight_decay\": 0.05,\n",
      "    \"params\": [\n",
      "      \"downsample_layers.0.0.weight\",\n",
      "      \"downsample_layers.1.1.weight\",\n",
      "      \"downsample_layers.2.1.weight\",\n",
      "      \"downsample_layers.3.1.weight\",\n",
      "      \"stages.0.0.dwconv.weight\",\n",
      "      \"stages.0.0.pwconv1.weight\",\n",
      "      \"stages.0.0.pwconv2.weight\",\n",
      "      \"stages.0.1.dwconv.weight\",\n",
      "      \"stages.0.1.pwconv1.weight\",\n",
      "      \"stages.0.1.pwconv2.weight\",\n",
      "      \"stages.0.2.dwconv.weight\",\n",
      "      \"stages.0.2.pwconv1.weight\",\n",
      "      \"stages.0.2.pwconv2.weight\",\n",
      "      \"stages.1.0.dwconv.weight\",\n",
      "      \"stages.1.0.pwconv1.weight\",\n",
      "      \"stages.1.0.pwconv2.weight\",\n",
      "      \"stages.1.1.dwconv.weight\",\n",
      "      \"stages.1.1.pwconv1.weight\",\n",
      "      \"stages.1.1.pwconv2.weight\",\n",
      "      \"stages.1.2.dwconv.weight\",\n",
      "      \"stages.1.2.pwconv1.weight\",\n",
      "      \"stages.1.2.pwconv2.weight\",\n",
      "      \"stages.2.0.dwconv.weight\",\n",
      "      \"stages.2.0.pwconv1.weight\",\n",
      "      \"stages.2.0.pwconv2.weight\",\n",
      "      \"stages.2.1.dwconv.weight\",\n",
      "      \"stages.2.1.pwconv1.weight\",\n",
      "      \"stages.2.1.pwconv2.weight\",\n",
      "      \"stages.2.2.dwconv.weight\",\n",
      "      \"stages.2.2.pwconv1.weight\",\n",
      "      \"stages.2.2.pwconv2.weight\",\n",
      "      \"stages.2.3.dwconv.weight\",\n",
      "      \"stages.2.3.pwconv1.weight\",\n",
      "      \"stages.2.3.pwconv2.weight\",\n",
      "      \"stages.2.4.dwconv.weight\",\n",
      "      \"stages.2.4.pwconv1.weight\",\n",
      "      \"stages.2.4.pwconv2.weight\",\n",
      "      \"stages.2.5.dwconv.weight\",\n",
      "      \"stages.2.5.pwconv1.weight\",\n",
      "      \"stages.2.5.pwconv2.weight\",\n",
      "      \"stages.2.6.dwconv.weight\",\n",
      "      \"stages.2.6.pwconv1.weight\",\n",
      "      \"stages.2.6.pwconv2.weight\",\n",
      "      \"stages.2.7.dwconv.weight\",\n",
      "      \"stages.2.7.pwconv1.weight\",\n",
      "      \"stages.2.7.pwconv2.weight\",\n",
      "      \"stages.2.8.dwconv.weight\",\n",
      "      \"stages.2.8.pwconv1.weight\",\n",
      "      \"stages.2.8.pwconv2.weight\",\n",
      "      \"stages.3.0.dwconv.weight\",\n",
      "      \"stages.3.0.pwconv1.weight\",\n",
      "      \"stages.3.0.pwconv2.weight\",\n",
      "      \"stages.3.1.dwconv.weight\",\n",
      "      \"stages.3.1.pwconv1.weight\",\n",
      "      \"stages.3.1.pwconv2.weight\",\n",
      "      \"stages.3.2.dwconv.weight\",\n",
      "      \"stages.3.2.pwconv1.weight\",\n",
      "      \"stages.3.2.pwconv2.weight\",\n",
      "      \"head.weight\"\n",
      "    ],\n",
      "    \"lr_scale\": 1.0\n",
      "  },\n",
      "  \"no_decay\": {\n",
      "    \"weight_decay\": 0.0,\n",
      "    \"params\": [\n",
      "      \"downsample_layers.0.0.bias\",\n",
      "      \"downsample_layers.0.1.weight\",\n",
      "      \"downsample_layers.0.1.bias\",\n",
      "      \"downsample_layers.1.0.weight\",\n",
      "      \"downsample_layers.1.0.bias\",\n",
      "      \"downsample_layers.1.1.bias\",\n",
      "      \"downsample_layers.2.0.weight\",\n",
      "      \"downsample_layers.2.0.bias\",\n",
      "      \"downsample_layers.2.1.bias\",\n",
      "      \"downsample_layers.3.0.weight\",\n",
      "      \"downsample_layers.3.0.bias\",\n",
      "      \"downsample_layers.3.1.bias\",\n",
      "      \"stages.0.0.gamma\",\n",
      "      \"stages.0.0.dwconv.bias\",\n",
      "      \"stages.0.0.norm.weight\",\n",
      "      \"stages.0.0.norm.bias\",\n",
      "      \"stages.0.0.pwconv1.bias\",\n",
      "      \"stages.0.0.pwconv2.bias\",\n",
      "      \"stages.0.1.gamma\",\n",
      "      \"stages.0.1.dwconv.bias\",\n",
      "      \"stages.0.1.norm.weight\",\n",
      "      \"stages.0.1.norm.bias\",\n",
      "      \"stages.0.1.pwconv1.bias\",\n",
      "      \"stages.0.1.pwconv2.bias\",\n",
      "      \"stages.0.2.gamma\",\n",
      "      \"stages.0.2.dwconv.bias\",\n",
      "      \"stages.0.2.norm.weight\",\n",
      "      \"stages.0.2.norm.bias\",\n",
      "      \"stages.0.2.pwconv1.bias\",\n",
      "      \"stages.0.2.pwconv2.bias\",\n",
      "      \"stages.1.0.gamma\",\n",
      "      \"stages.1.0.dwconv.bias\",\n",
      "      \"stages.1.0.norm.weight\",\n",
      "      \"stages.1.0.norm.bias\",\n",
      "      \"stages.1.0.pwconv1.bias\",\n",
      "      \"stages.1.0.pwconv2.bias\",\n",
      "      \"stages.1.1.gamma\",\n",
      "      \"stages.1.1.dwconv.bias\",\n",
      "      \"stages.1.1.norm.weight\",\n",
      "      \"stages.1.1.norm.bias\",\n",
      "      \"stages.1.1.pwconv1.bias\",\n",
      "      \"stages.1.1.pwconv2.bias\",\n",
      "      \"stages.1.2.gamma\",\n",
      "      \"stages.1.2.dwconv.bias\",\n",
      "      \"stages.1.2.norm.weight\",\n",
      "      \"stages.1.2.norm.bias\",\n",
      "      \"stages.1.2.pwconv1.bias\",\n",
      "      \"stages.1.2.pwconv2.bias\",\n",
      "      \"stages.2.0.gamma\",\n",
      "      \"stages.2.0.dwconv.bias\",\n",
      "      \"stages.2.0.norm.weight\",\n",
      "      \"stages.2.0.norm.bias\",\n",
      "      \"stages.2.0.pwconv1.bias\",\n",
      "      \"stages.2.0.pwconv2.bias\",\n",
      "      \"stages.2.1.gamma\",\n",
      "      \"stages.2.1.dwconv.bias\",\n",
      "      \"stages.2.1.norm.weight\",\n",
      "      \"stages.2.1.norm.bias\",\n",
      "      \"stages.2.1.pwconv1.bias\",\n",
      "      \"stages.2.1.pwconv2.bias\",\n",
      "      \"stages.2.2.gamma\",\n",
      "      \"stages.2.2.dwconv.bias\",\n",
      "      \"stages.2.2.norm.weight\",\n",
      "      \"stages.2.2.norm.bias\",\n",
      "      \"stages.2.2.pwconv1.bias\",\n",
      "      \"stages.2.2.pwconv2.bias\",\n",
      "      \"stages.2.3.gamma\",\n",
      "      \"stages.2.3.dwconv.bias\",\n",
      "      \"stages.2.3.norm.weight\",\n",
      "      \"stages.2.3.norm.bias\",\n",
      "      \"stages.2.3.pwconv1.bias\",\n",
      "      \"stages.2.3.pwconv2.bias\",\n",
      "      \"stages.2.4.gamma\",\n",
      "      \"stages.2.4.dwconv.bias\",\n",
      "      \"stages.2.4.norm.weight\",\n",
      "      \"stages.2.4.norm.bias\",\n",
      "      \"stages.2.4.pwconv1.bias\",\n",
      "      \"stages.2.4.pwconv2.bias\",\n",
      "      \"stages.2.5.gamma\",\n",
      "      \"stages.2.5.dwconv.bias\",\n",
      "      \"stages.2.5.norm.weight\",\n",
      "      \"stages.2.5.norm.bias\",\n",
      "      \"stages.2.5.pwconv1.bias\",\n",
      "      \"stages.2.5.pwconv2.bias\",\n",
      "      \"stages.2.6.gamma\",\n",
      "      \"stages.2.6.dwconv.bias\",\n",
      "      \"stages.2.6.norm.weight\",\n",
      "      \"stages.2.6.norm.bias\",\n",
      "      \"stages.2.6.pwconv1.bias\",\n",
      "      \"stages.2.6.pwconv2.bias\",\n",
      "      \"stages.2.7.gamma\",\n",
      "      \"stages.2.7.dwconv.bias\",\n",
      "      \"stages.2.7.norm.weight\",\n",
      "      \"stages.2.7.norm.bias\",\n",
      "      \"stages.2.7.pwconv1.bias\",\n",
      "      \"stages.2.7.pwconv2.bias\",\n",
      "      \"stages.2.8.gamma\",\n",
      "      \"stages.2.8.dwconv.bias\",\n",
      "      \"stages.2.8.norm.weight\",\n",
      "      \"stages.2.8.norm.bias\",\n",
      "      \"stages.2.8.pwconv1.bias\",\n",
      "      \"stages.2.8.pwconv2.bias\",\n",
      "      \"stages.3.0.gamma\",\n",
      "      \"stages.3.0.dwconv.bias\",\n",
      "      \"stages.3.0.norm.weight\",\n",
      "      \"stages.3.0.norm.bias\",\n",
      "      \"stages.3.0.pwconv1.bias\",\n",
      "      \"stages.3.0.pwconv2.bias\",\n",
      "      \"stages.3.1.gamma\",\n",
      "      \"stages.3.1.dwconv.bias\",\n",
      "      \"stages.3.1.norm.weight\",\n",
      "      \"stages.3.1.norm.bias\",\n",
      "      \"stages.3.1.pwconv1.bias\",\n",
      "      \"stages.3.1.pwconv2.bias\",\n",
      "      \"stages.3.2.gamma\",\n",
      "      \"stages.3.2.dwconv.bias\",\n",
      "      \"stages.3.2.norm.weight\",\n",
      "      \"stages.3.2.norm.bias\",\n",
      "      \"stages.3.2.pwconv1.bias\",\n",
      "      \"stages.3.2.pwconv2.bias\",\n",
      "      \"norm.weight\",\n",
      "      \"norm.bias\",\n",
      "      \"head.bias\"\n",
      "    ],\n",
      "    \"lr_scale\": 1.0\n",
      "  }\n",
      "}\n",
      "Use Cosine LR scheduler\n",
      "Set warmup steps = 700\n",
      "Set warmup steps = 0\n",
      "Max WD = 0.0500000, Min WD = 0.0500000\n",
      "criterion = SoftTargetCrossEntropy()\n",
      "Auto resume checkpoint: \n",
      "Eval only mode\n",
      "Test:  [0/6]  eta: 0:03:12  loss: 0.1994 (0.1994)  acc1: 94.7917 (94.7917)  acc5: 100.0000 (100.0000)  time: 32.0435  data: 28.4644  max mem: 1917\n",
      "Test:  [5/6]  eta: 0:00:05  loss: 0.0838 (0.1651)  acc1: 94.7917 (96.6071)  acc5: 100.0000 (100.0000)  time: 5.6035  data: 4.7442  max mem: 1917\n",
      "Test: Total time: 0:00:34 (5.7040 s / it)\n",
      "* Acc@1 96.607 Acc@5 100.000 loss 0.165\n",
      "[[135   2   0   3]\n",
      " [ 11 126   1   2]\n",
      " [  0   0 140   0]\n",
      " [  0   0   0 140]]\n",
      "(4, 4)\n",
      "Accuracy of the network on 560 test images: 96.60714%\n"
     ]
    }
   ],
   "source": [
    "!python main.py --eval true \\\n",
    "--model  my_model \\\n",
    "--nb_classes 4 \\\n",
    "--input_size 224 --drop_path 0.2 \\\n",
    "--data_path C:/Users/qiezh/Desktop/FYP/FYPConvNext/ChestXRays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9d462bf1",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'metrics' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [2]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mmetrics\u001b[49m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mconfusion_matrix\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "\u001b[1;31mNameError\u001b[0m: name 'metrics' is not defined"
     ]
    }
   ],
   "source": [
    "print(metrics['confusion_matrix'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e1ae96c6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function matplotlib.pyplot.show(close=None, block=None)>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAUYAAAE+CAYAAADxprlcAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAABDXklEQVR4nO3dd3gU1dfA8e/JJkiRIkW6AoKgIEVDU1RQab4CiggixUZTsNDEDijKTwU70gRFQBSVLgiIBVGRDqErRQhdQHpJOe8fMwmbzSZsQkJ24/n47JOdmXtnzq7h5N47M3dEVTHGGHNOWFYHYIwxwcYSozHG+LDEaIwxPiwxGmOMD0uMxhjjwxKjMcb4sMRojAkJItJERDaJyF8i8qyf7e1EZI37+k1Eqnlt2y4iUSKySkSWnfdYdh2jMSbYiYgH2Aw0BKKBpUBbVV3vVeZGYIOqHhaRpsAAVa3tbtsORKrqP4Ecz1qMxphQUAv4S1W3qupZ4AughXcBVf1NVQ+7i4uBUuk9mCVGY0woKAns9FqOdtel5FFgjteyAvNEZLmIdDnfwcLTFaJJk7Nbl4TceEXea+/N6hDSLC4+PqtDSJMIT+j98zt16m8JtGzMP1sD/r3PUeSqroB3whqlqqO8lv0d1+/+RaQBTmKs57X6JlXdLSKXA/NFZKOqLkwpntD7P2OMCQ3xcQEXdZPgqFSKRAOlvZZLAbt9C4lIVeBjoKmqHvTa/273534RmYrTNU8xMVpX2hiTOTQ+8Nf5LQUqiEhZEckB3A/M8C4gIlcAU4AOqrrZa30eEcmb8B5oBKxN7WDWYjTGZI4MHNpQ1VgR6QHMBTzAWFVdJyLd3O0jgJeBQsBHIgIQq6qRQFFgqrsuHPhcVb9L7Xh2uc5FYGOMF4eNMWa+tIwxno2OCnyMsdR1Ae/3Ygi9/zPGmNAQWBc5KFliNMZkjjScfAk2lhiNMZnDWozGGOMjxMZ8vVliNMZkCo2LzeoQ0s0SozEmc1hX2hhjfNjJF2OM8WEtRmOM8WEnX4wxxoe1GI0xJimNi8nqENLNEqMxJnNYi9EYY3zYGKMxxviwFqMxxviw6xiNMcaH3RJojDE+Qrgrne2f+SIixUTkCxHZIiLrRWS2iFydxn1Eisj7KWzbLiKF07K/vQcO8ki/12nepR93d32WCdPmJtn+6dffcl3TDhw+csxv/ZfeHs2t9z/OPd2eTbJ+7i9/cHfXZ6l6Z0fWbd6auH7lus20fOx57n/yZXbs3gfA0eMn6PrCm6R3BvdGDesTteYn1q/7hT59Hk+2vdldjVi2dB5L/viO3379lhtvrJm4LX/+fEz6fARrVv/I6lU/ULv29QC8Nug5li2dx5gx7ySWfeCBlvTo/ki6YvTVuFF91q1dyMb1i3imb3e/Zd55+xU2rl/EiuXzqVG9ynnrDn79eVYsn88nY99LXNeu3b080ePRC463YcNbWb36B9au/Zk+fR5Ltv3mm+uwd28UixfPZvHi2Tz33JNJtoeFhfH777P55puxiesGDXqWJUu+4+OP305c17btPXTv/vAFx5tMfHzgryCTrROjOA95mAr8pKpXqeq1wPM4z4AImKouU9Unz18yMB6Phz6dH2DGqDeY+E5/vpj1PVv+3gU4SfP3lesofnmhFOu3aHgzwwc9k2x9hStL8c5LT3FDlYpJ1o+bMod3XnySJx+6jy+/XQDAyEnT6dSmGe5zMNIkLCyM994bRPMWHalW/TbatG5BpUoVkpT54cdFRNZsRK3aTejStTcjhr+ZuG3o0AHMm/8TVas1ILJmYzZu/It8+fJSp24kkTUb4fF4qFy5Ejlz5qRjh/sYMfKzNMfoL+b333uNu5q157pqDWjT5m6uuSZpzE2b3EaF8mWpdG09HnusH8M+HJxq3Xz58lK3TiTX39AQjyeMKlWcmB/s0JrhI8ZdcLzvvvsqLVo8SI0ad3Dffc2TfccAv/66lDp17qROnTsZPDjp3+4ePR5h06a/Epfz5ctLnTo3UKtWE/c7rkjOnJfQocN9jBw5/oLi9csSY9BqAMS4D8oBQFVXAYtE5C0RWSsiUSLSBkBEvhSROxPKisinInKviNQXkVnuukIiMk9EVorISPw/7zZVRQoW4NryZQDIkzsXZUuXYN/BQwC8OXIivR5tg6Sy28jrKpE/b55k68tdUZKypYonWx8e7uH02bOcPnOWcI+Hnbv3sf+fQ9Ssek1aQwegZs3qbNmynW3bdhATE8Pkr2bQrFmjJGVOnDiZ+D5PntyJLdO8eS/l5nq1+eSTLwCIiYnhyJGjxMfHkyMiAoBcOXMSGxNDr15dGTbsE2JjL3ysqlbNGkljnjyd5s0aJynTrFljxk/8GoA/lqwgf4H8FCt2eYp14+PjyZHDjTlXTmJiYujTuxsfDBtzwTEnfMfbt+8kJiaGr76ayV13NQy4fsmSxWjS5LbE7xnwE28sPXt25aOPMuY79qUaF/Ar2GT3xFgFWO5nfUugOlANuAN4S0SKA18ACUkyB3A7MNunbn9gkarWwHl84xUXEuCufQfYuOVvqlYsz4+LV3B54cuoWO7KC9llMp1aN+OV98YyYdpc2jZryPvjvqJHx1bp3l+JEsXYGX3ukb67du2hZIliyco1b96ENat/ZNrUcXTp2geAsmWv4MCBQ4we/TZ/LJ7D8OFvkjt3Lo4fP8G0abNZ8sd3bN++kyNHjxF5QzVmzpqX7jiTxFwyaczRu/ZQwifmkiWKEb3T63NFO58rpbrHj59gytTZLFs6j+3bdnLkyDEiI6szc+aFx1yiRDGio/eci2XXHkqWTP4d1659PX/8MYdp08YlaQG/9VZ/XnjhdeK9WmPOdzyHxYtns337To4ePcYNN1Rj1qz5FxyvX9ZiDDn1gEmqGqeq+4CfgZrAHOA2EbkEaAosVNVTPnVvASYAqOq3wOH0BnHy1Gl6Dnqffl3b4fGEMfqL6XTvkPFP56t01ZVMfHcAY994nui9+ylS6DJUlT6DP+TZN4fzz+Ejadqfv+63v7HKGTO+o2q1BtzXuhMD+juJMTw8nBo1qjBq1GfUrtOUkydO0tcdsxv69ghq1W5Cv2dfpX//Pgx8ZSgPP3w/Eyd8xLPPXthIRiAxp1QmtbpDhg4nsmYj+vZ7hYED+jJg4Fs88nBbJn0+guefe+oC4k2+zjfeVavWUrHijdSu3ZThwz9l8uTRADRtehv79x9k5crkj05+++2R1KlzJ88+O4iXX+7Nq6++zUMP3c+ECcPo1++JdMfrV1xs4K8gk90T4zrgBj/r/fZTVfU08BPQGKfl+IW/csB5z1iISBcRWSYiyz6eNDXZ9pjYWHoOep//a3Ajd9xUk5179rNr7wFaPf4CjR/syb5/DtH6iZf459C/5ztUwFSVUZOm07Xt3QyfOJXH27fkrttu4vPpaWvh7Nq1h9KlSiQulyxZnN179qVYftGiPyhX7koKFbqMXbv2EL1rD0uXrgJgytTZSU5yAFSrVhmAP//cSrt2rWjX/nEqX1uR8leVSVOcSWKOThpzqZLF2eMTc/SuPZQq7fW5SjmfK5C61as7MW/evJUO7VvR9oFuVK5ckfLly6Yv3l17KeU1LFKyZHF27056zGPHjicOWcyd+yMREeEUKnQZdetGctddd7Bx4yI+++wD6te/kbFj301SN+l33JL27btTufLVXHUB33EyGh/4K8hk98T4A3CJiHROWCEiNXFaeW1ExCMiRXBagUvcIl8ADwM34zzc29dCoJ27r6bAZf4OrKqjVDVSVSM7tb3Hdxv93/2YcqVL8GDLpgBcXbY0P3/xEXPHvcPcce9QtHBBJn/wKoULFkj3h/c1/ftfuKVWdfLnzcPpM2cJEyFMhFNnzqRpP8uWraZ8+TKUKVOaiIgIWt/XPFl37KpyZRLfV69ehYiIHBw8eJh9+w4QHb2HqyuUA6BBg5vYsOHPJHUH9O/DK68MJSIiAo/H+RWN13hy5c6Vjk/tWLpsFeXLlz0Xc+sWybrps2bNo0M7Z4ihdq3rOXrkKHv37g+o7sD+zzBg4BA3Zo8Tc3w8udMZs/Mdl+XKK51j3ndfM779Nul3XLRokcT3kZHVCAsL4+DBw7z88puUL1+HSpXq0bHjE/z002888sjTSeo6rcWhPvFquuP1K4S70tn6OkZVVRG5B3hXRJ4FTgPbgaeBS4HVOK2/Z1R1r1ttHvAZMENVz/rZ7UBgkoiswOmC70hrXCvXbWbmgl+pUKY0rbq/AMCTD97HLbWq+y2//+Bh+r/7McNf7QvAM/8bxtI1G/j36HFub/8k3Tu0pGXj+iz4dRmvD/+Mw0eO8Xj/oVQqdyUjX3POXp86fYYZ3y9KXO7Ysik9X3ufiPBw3uyX/HKb1MTFxfH00y8xa+YEPB4Pn477kg0bNtO5U3sARn88gbvvaUr7dvcSExPLqVOnad/h3DF69nyJTz/9gBw5Iti2bQedu/RO3Na8WWOWLV+d2CL7Y/EKli+bT9TaDURFbUhTnL4xP/X0i8z+9nM8YWF8Ou5L1q/fTJfOHQAYNXo8s+csoEmT29i04VdOnjpFp069Uq2bGHPzxixbviox5sWLl7NyxfdERW1gzZr16Y63Z8+XmTnzMzweD+PGTWbDhj/p1KkdAB9/PJF77rmTzp3bExsby+nTp+nYMbCucLNmjVi+fDV79uwH4I8/VrB06VzWrt14Qd9xMkHYEgyUpPc6NhO4s1uXhNyXnPfajB/rzGxxQdjySE2EJ/TaJadO/R3wVRin5rwf8O99rqZPpv26sUwUev9njDGhIcT+UHmzxGiMyRxBeLY5UJYYjTGZI4THGC0xGmMyh3WljTHGh7UYjTHGh7UYjTHGR1zwTQ4RKEuMxpjMYS1GY4zxEcKJMbvfK22MySoZPImEiDQRkU0i8pd7i6/v9nYissZ9/SYi1QKt68tajMaYzJGBLUYR8QDDgIZANLBURGaoqvfN6NuAW1X1sDvByyigdoB1k7AWozEmc6gG/jq/WsBfqrrVndzlC6BF0sPpb6qaMD/qYqBUoHV9WYvRGJM5MvZxCSWBnV7L0UDtVMo/ijPxdHrqWmI0xmSSNFzgLSJdgC5eq0ap6ijvIv6OkMK+GuAkxnpprZvAEqMxJlNofOCz7blJcFQqRaKB0l7LpYDdvoVEpCrwMdBUVQ+mpa43G2M0xmSOjJ3BeylQQUTKug+qux/nYXSJROQKYArQQVU3p6WuL2sxGmMyRwbeK62qsSLSA+dxIx5grKquE5Fu7vYRwMtAIeAj9wFmse7jRfzWTe14lhiNMZkjDV3pQKjqbHweZ+zzzPhOQKdA66bGEqMxJnNk7Fnpi8oSozEmc4Tw86QsMRpjMkcI3yttidEYkzkyeIzxYrLEaIzJHDaDt0lNhZp+T5QFtSM/vpnVIaRZ3lv7ZHUIaRIfwokjEBprE9UaY0xS1pU2xhgfIdwitsRojMkc1mI0xhgfdrmOMcb4sBajMcb4sMenGmNMUmpdaWOM8WFdaWOM8WGJ0RhjfNh1jMYY48NajMYYk5TGWovRGGOSsrPSxhjjw7rSxhjjwxKjMcYkpfbMF2OM8WEnX4wxJim1rrQxxviwxGiMMT5CtydtidEYkzmsK22MMb5CODGGZXUAF0JEVESGei33EZEBFzmGn0Qk8kL28db7A1m+8SfmLZrid3u+/HkZ+dk7fLfwa6bPn8jVlcqf25YvL8M/GcqCxdNZ8Ps0ro+sCsCz/Z/mu4Vf8/ZHryWWvaf1XTzcpV26Ytx78AiP/u9T7n7uQ+55fhgT5y0G4O0v5tHi2Q9o9eJHPP3+Fxw9ccpv/aa93+HeFz+i9UvDaTtgZOL6I8dP0vWtz2jW7326vvVZYv2Vf+6g1Ysf8cDAUezYdxCAoydO0W3I+HRfBtKoUX3Wrl3IhvWL6Nu3e7LtFStexS8LZ3D82FZ69uyaZNtTT3Zm1aofWLlyAePHD+OSSy4B4PXXn2fF8vl8Mva9xLLt2t3LEz0eTVeMSeJtWJ+oNT+xft0v9OnzeLLtze5qxLKl81jyx3f89uu33HhjzcRt+fPnY9LnI1iz+kdWr/qB2rWvB+C1Qc+xbOk8xox5J7HsAw+0pEf3Ry44Xl8aqwG/gk1IJ0bgDNBSRAqnp7KIBEWL+atJM3iw9WMpbu/RszProzbR5JZW9Hr8BQYM7pe4rf/gfvy84Fdur9OCJre04q/N28ib91JuqFmdJre0whMWRsVrKnBJzku4r20Lxo/9Ml0xejxh9Lm/EdMG92DCS534YsEStuzaT50q5fjmtcf5etDjXFmsEGO+XZTiPj7u9yCTX32MSQPOJZ2x3y6i1jVlmfnGk9S6pmxi/c+++42hPdrwxL23M/mHZQCMmrGQTnfdjIikOf6wsDDef+81mjVrT9VqDbi/zd1cc02FJGUOHfqXnj1f4u13RiZZX6JEMbp3f4Q6de6kRo3b8Xg8tGndgnz58lK3TiTX39AQjyeMKlUqkTNnTjp2aM3wEePSHKNvvO+9N4jmLTpSrfpttGndgkqVksb7w4+LiKzZiFq1m9Cla29GDD/3LPChQwcwb/5PVK3WgMiajdm48S/y5ctLnbqRRNZshMfjoXLlhHjvY8TIzy4oXr/i0/AKMqGeGGOBUUBP3w0icqWILBCRNe7PK9z1n4rI2yLyI/CGuzxcRH4Uka0icquIjBWRDSLyqdf+hovIMhFZJyIDM/JDLPl9Of8ePpLi9goVy/Hrwj8A2PLndkqVLkHhIgW5NG8eate9gS8mOC3NmJhYjh49RrzGE5EjAoCcuS4hNjaGrj0e4pNRE4mNjU1XjEUK5OWaMiUAyJPrEsqVKML+w8e4sUp5wj0eAKpeVYr9h46mab8/rtxE83rVAWherzo/rtgIQLjHw5mYGE6fjSHcE8bO/YfYf/gokZXKpCv+WjVrsGXLdrZt20FMTAxfTp5Os2aNk5Q5cOAgy5avJiYmJln98PBwcuXKicfjIXeuXOzes5f4+HhyJH7POYmJiaF37258OGxMur/nBDVrVk8S7+SvZtCsWaMkZU6cOJn4Pk+e3Ikt6bx5L+XmerX55JMvAIiJieHIkaNOvBFOvLly5iQ2JoZevboybNgnFxyvPxqvAb+CTagnRoBhQDsRye+z/kPgM1WtCkwE3vfadjVwh6r2dpcvA27DSbAzgXeAysB1IlLdLfOCqkYCVYFbRaRqZnwYf9av20zTu24HoNr1VShZujjFShTliitLcfDgIYZ8+Cqzf/ySN94dQK7cuThx/CRzZn7P7J8ms/PvXRw7epxqNaowf85PGRLPrgOH2fj3Hq67qmSS9dMWruSmquX9VxKh25Dx3N9/JF//tCxx9aEjxylSIC/gJN9DR08A8Oj/1eOVT2YyYd5i2t5Riw++XkD3lrelO+YSJYsRHb373GfYtYeSJYoFVHf37r28884Itm5Zws4dKzl69Cjff7+Q48dPMGXqbJYtncf2bTs5cuQYkZHVmTlzXrrjTIy3RDF2BhBv8+ZNWLP6R6ZNHUeXrn0AKFv2Cg4cOMTo0W/zx+I5DB/+Jrlz5+L48RNMmzabJX98x/btOzly9BiRN1Rj5qwLj9ev7NhiFJFjInLUfR3zWj4mImlrFmQiVT0KfAY86bOpLvC5+348UM9r21eq6v2knpnq/LmNAvapapSqxgPrgDJumdYisgJYiZM0r83QD5KK4e+NIV+BfMz+aTIPdW7LuqiNxMXG4Qn3UKXqNUz4ZDJ3NmjDyZOnePwpZ6xo5AefcGf91gx6eSi9n+vB2/8bxv3tWzJszFs80btzumM5efoMvT+cTN8HmnBprpyJ60fPWIjHE8b/1fX/92LcC4/w5cBuDOvdji8XLGX5pu2pHqfSlcWZ8HJnxjz7ENEHDlPksrwoSt+PvuK5kd9w8MjxNMXtr/sd6FhlgQL5adasMRWursMVV15P7jy5eeCBlgAMHTqcyJqNeKbfKwwc0JeBA9/ikYfb8vnnI3juuafSFGN64p0x4zuqVmvAfa07MaC/kxjDw8OpUaMKo0Z9Ru06TTl54mTimOrQt0dQq3YT+j37Kv3792HgK0N5+OH7mTjhI5591vef0IXR+MBfwSbFxKiqeVU1n/vK67WcV1XzXcwgA/Au8CiQJ5Uy3r9VJ3y2nXF/xnu9T1gOF5GyQB/gdrcF+i2Qk1SISBe3673s+OlD5/8EqTh+7AR9n3iZO+u3pudjL1Cw0GXs3LGLvbv3sWf3PlYtjwJg9oz5VKl6TZK6la+rBMDWLX/Tsk0zuj/al6srladMuSvSHEdMbBy9PpzMnXWv447Ic38XZixaxcLVmxnctWWK43+XX+b8yhTKdym3XV+JtVt3AVAw/6Uc+PcYAAf+PUbBfEn/F6oqo2YspGvzWxk57Wcev7s+d9Wtyufz/0hT7Lui91CqVInE5ZIli7N7z76A6t5++81s376Df/45RGxsLNOmzaFunaTn26pXrwzA5s1bad++FQ880I3KlStSvnzZNMWZGO+uPZROQ7yLFv1BuXJXUqjQZezatYfoXXtYunQVAFOmzqZG9SpJyler5sT7559badeuFe3aP07laytS/qoy6YrXH40N/BVsAupKi0g9EXnYfV/YTRRBQ1UPAZNxkmOC34D73fftgJTPCpxfPpxkekREigJNA4hplKpGqmrkpTkLXsChnTPPERHOeaL7O9zLkt9XcPzYCQ7sP8ieXfsoV74MADfdUps/N21NUrf3c90Z+r9hRISH4/E4/7s1XsmVK9W87u/zMGDsdMoVL0zHJjcmrv91zZ98MnsR7z3VllyX5PBb9+SZs5w4dSbx/e/rtlC+5OUA1K9ekRmLVgFOgm1Qo2KSujMWreKWaleTL08uTp2NQcIECRNOn00+DpiapctWUb58WcqUKU1ERARtWrdgVoBdyJ07dlGr9vWJ39ltDeqxceOfScoM6P8MAwYOISIiAo875hofH0/u3LnSFGeCZctWU758mcR4W9/XnFmz5icpc1W5Monvq1evQkREDg4ePMy+fQeIjt7D1RXKAdCgwU1s2OAbbx9eeWWoG6/zexGv8eRKZ7x+ZXBXWkSaiMgmEflLRJ71s72SiPwuImdEpI/Ptu0iEiUiq0RkmW9dX+c9Kysi/YFIoCLwCZADmADcFNjHuWiGAj28lp8ExopIX+AA8HB6d6yqq0VkJU7Xeivw64UE6uv9UW9Q96ZILitUgMVR83nnfx8R7ibCiZ9+Rfmry/L2R68RFx/PX5u20PfJ/ol1+z87mPdGDiYiIoIdf0fTp8dLidsa3dmA1SvXsX/vAQBWLF3D3F++YeO6zWxYtzlNMa78cwezfltDhVKX0/ql4QA80ep23pg4h7OxcXR7yzmred1VpXjpoWbsP3yUgZ/MYFiv9hw6cpyeHzhnw2Pj4rmzznXcVNU5w/rIXfXoO+wrpv2ykmIF8zOk+32Jxzx15iwzfl3NiD4dAOjYuC69P5xMhMfD/x67N03xx8XF8dTTL/Ltt5/jCQvj03Ffsn79Zrp0dvY9avR4ihYtwuLf55Av36XEx8fz5BOdqVqtPkuWrmTKlG9ZsmQusbGxrF61jtEfT0zcd/PmjVm2fBV73Bbd4sXLWbnie6KiNrBmzfo0xekd79NPv8SsmRPweDx8Ou5LNmzYTOdO7QEY/fEE7r6nKe3b3UtMTCynTp2mfYdzl/T07PkSn376ATlyRLBt2w46d+mduK15s8YsW746Md4/Fq9g+bL5RK3dQFTUhnTF609GdpFFxINzPqEhEA0sFZEZqur9BR/C+Xd/dwq7aaCq/wR0vPONs4jIKqAGsEJVa7jr1rhdShOAKwtVDb7TbuexadZzWR1CmuW9tc/5CwWRsLDQO/d55vTOgK+V2n/7rQH/3l++4OdU9ysidYEBqtrYXX4OQFUH+yk7ADiuqkO81m0HIgNNjIH8nznrnphQ9wCpjeMZYwyQ4SdfSgI7vZaj3XUBhwPME5HlItLlfIUDucB5soiMBAqISGfgEWB0GgIyxvwXaeAX4rvJyjthjVLVUd5F/B0hDdHcpKq7ReRyYL6IbFTVhSkVPm9iVNUhItIQOIpz/d/Lqjr/PNWMMf9x8bGBJ0Y3CY5KpUg0UNpruRSwO4Wy/va/2/25X0SmArWA9CdGVxSQCydDRwUajDHmvyuDr09cClRwr4jZhXPFyQOBVHSH/8JU9Zj7vhHwSmp1Ajkr3Ql4GfgBpzn7gYi8oqpjAwnKGPPfpGnoSp9/XxorIj2AuYAHGKuq60Skm7t9hIgUA5bhXF4XLyJP49yIURiY6l5jGw58rqrfpXa8QFqMfYEaqnoQQEQK4VwjaInRGJOijL6jRVVnA7N91o3wer8Xp4vt6yhQLS3HCiQxRgPHvJaPkfTskDHGJKPxGddivNhSTIwi0st9uwv4Q0Sm44wxtgCWXITYjDEhLISfnppqizGv+3OL+0owPfPCMcZkF/GxoXcBe4IUE6OqZuicg8aY/5bs2mIEQESKAM/gTLWVOPOAqqZ/cjxjTLYXymOMgbR1JwIbgbLAQGA7zjVFxhiTIlUJ+BVsAkmMhVR1DBCjqj+r6iNAnUyOyxgT4kJ5otpALtdJmPhuj4j8H85tOP6uFTLGmERx8dnw5IuXQe7zVHoDH+BcVZ7s4VPGGOMtlMcYA5lEYpb79gjQIHPDMcZkF9nyrLSIfEAq0/qoasY+OccYk61k1xbjeZ+LYIwxKYkPwrPNgUrtAu9xFzMQY0z2EoyX4QQq0PkYjTEmTeKyaVfaGGPSzVqMxhjjw85KG2OMj2x58gU7K51hdh07mNUhpNmlIfaMZoBTu3/J6hDSJFeJm7M6hEyVLbvSdlbaGHMhsmuLEUicdqwfzkNlbNoxY0xA4kI4MQY67dgGbNoxY0wa2LRjxhjjIz4Nr2Bj044ZYzKFEnwtwUDZtGPGmEwRnx2vY0xg044ZY9IjLqCRuuAUyFnpT/Bzobc71miMMX4F49hhoALpSs/yep8TuAdnnNEYY1KUrccYVfUb72URmQR8n2kRGWOyhezeYvRVAbgiowMxxmQv2Toxisgxko4x7sW5E8YYY1KU3bvSeS9GIMaY7CVWQjcxnvd8uogsCGSdMcZ40zS8gk1q8zHmBHIDhUXkMkhsF+cDSlyE2IwxISy7jjF2BZ7GSYLLOZcYjwLDMjcsY0yoiw/hrnRq8zG+B7wnIk+o6gcXMSZjTDYQjF3kQAVyz068iBRIWBCRy0Tk8cwLyRiTHWT07Doi0kRENonIXyLyrJ/tlUTkdxE5IyJ90lLXVyCJsbOq/puwoKqHgc4B1DPG/IfFigT8Oh8R8eAM4TXFmTS7rYhc61PsEPAkMCQddZMIJDGGiZyL3D1IjgDqGWP+wzL4rHQt4C9V3aqqZ4EvgBZJjqe6X1WXcm6qxIDr+gokMc4FJovI7SJyGzAJ+C6wz2KM+a+Kl8BfASgJ7PRajnbXZUrdQBJjP2AB8BjQ3X3fN8CAkhGROBFZJSJrReQrEcmd3n1dTCISKSLvZ9b+Gzeqz7q1C9m4fhHP9O3ut8w7b7/CxvWLWLF8PjWqVzlv3cGvP8+K5fP5ZOx7ievatbuXJ3o8+p+Id8++Azzcox/NHuhCi3ZdGT95GgDDxkzgthbtuffB7tz7YHcW/rbEb/1Fi5dx1/2daNr6ET4ePzlx/ZGjx+j01PPc2eZROj31PEeOHgNgxZp13NPxMdo8+iQ7op15Vo4eO06Xni+g6XjIcih8x6lJyxijiHQRkWVery4+u/OXPgP9UtNc97yJUVXjVXWEqrZS1XuBdTgT1qbXKVWtrqpVgLNAtwvY10Wjqssy61naYWFhvP/ea9zVrD3XVWtAmzZ3c801FZKUadrkNiqUL0ula+vx2GP9GPbh4FTr5suXl7p1Irn+hoZ4PGFUqVKJnDlz8mCH1gwfcWEPgAyVeMM9Hvo+0ZmZn4/i81Hv8MWUWWzZ9jcAHdrczTfjhvHNuGHccmOtZHXj4uIYNHQYw4e+yoyJI5n9/U+JdT8eP5k6kdWZ/eUY6kRWZ8wEJ2mOmzSFd197kae6PsSXU78FYOSnk+jcsQ2SxktXQuU7Tk1autKqOkpVI71eo3x2Fw2U9louReCzfKW5bkAzSYpIdRF5Q0S2A68CGwMM6Hx+AcqLSH0R+UlEvhaRjSIyMWFcU0RuEJGfRWS5iMwVkeLu+p9EJNJ9X9iNDRF5SESmichMEdkmIj1EpJeIrBSRxSJS0OszLRaRNSIy1b2IPWG/b4jIEhHZLCI3u+vri8gs930tEfnN3edvIlLxQr6EWjVrsGXLdrZt20FMTAyTJ0+nebPGSco0a9aY8RO/BuCPJSvIXyA/xYpdnmLd+Ph4cuSIACBXrpzExMTQp3c3Phg2htjY2AsJN2TiLVK4INdWLA9Anjy5KXdlafYdCOwZ31EbNnNFqRKULlmciIgImt5+Kz/8shiAH3/5nRZN7wCgRdM7+GHh7wCEh4dz+sxZTp85Q3i4hx3Ru9l34B9q1qia5thD5TtOTawE/grAUqCCiJQVkRzA/cCMAENJc90UE6OIXC0iL4vIBuBDnKwrqtogI65rFJFwnLNEUe6qGjgXlF8LlANuEpEInNZpK1W9ARgLvBbA7qsAD+AMur4GnFTVGsDvQEe3zGdAP1Wt6sbQ36t+uKrWcuPxXp9gI3CLu8+XgdcDiClFJUoWY2f0uT9g0bv2UKJEsSRlSpYoRvTOc2V2Re+hZIliKdY9fvwEU6bOZtnSeWzftpMjR44RGVmdmTPnXUioIRkvwK49+9jw5xaqVnb+hk36Zib3dHyMF19/O7Er7G3/gX8odnmRxOWilxdmv5tUDx7+lyKFCwJO8j307xEAOndozcA33mP8l9Noe28z3h81jic6d0y270CE4nfsKyMv11HVWKAHzjmPDcBkVV0nIt1EpBuAiBQTkWigF/CiiESLSL6U6qZ2vNTufNmI06Jrpqp/uQfOiGe95BKRVe77X4AxwI3AElWNdo+zCigD/IuT5Oa7DUgPsCeAY/yoqseAYyJyBJjpro8CqrrPsCmgqj+768cBX3nVn+L+XO7G4Ss/ME5EKuD0BCICiClF/rpZvmNSKZVJre6QocMZMnQ4ACNHvMWAgW/xyMNtadjwVqKiNvD64PeS1c2O8Z48eYqeLwyi35NduTRPHtrc8390e6gtIsIHoz/jrQ9HM+j5Xj4xJd/P+XrDla6+is9HvwvAslVRXF64EKpK75cGEx7udOsLF7wsoJhD7Tv2J6Ofiqqqs4HZPutGeL3fSwoP6vNXNzWpdaXvxZli7EcRGS0it+N/EDOtEsYYq6vqE+7pc4AzXmXicJK2AOu8yl+nqo3cMrFe8ef0OYb3vuK9luMJbA7KhPIJcfh6FSf5VgGa+Tl+ksHk+PgTqR5sV/QeSpc6d/t5qZLF2bNnX5Iy0bv2UKr0uTIlSxVn9559AdWtXr0yAJs3b6VD+1a0faAblStXpHz5sqnGlR3ijYmN5ekXBvF/jRrQsP5NABQueBkej4ewsDBaNW/K2vWbk9Urenlh9u4/kLi8b/8/FClcCIBClxXgwD+HADjwzyEKFsifpK6qMvLTSXR9qC3Dx06ke6f2NGt8GxO/mh5w3KH0HacklB+fmmJiVNWpqtoGqAT8hPNkwKIiMlxEGqVUL4NtAoqISF0AEYkQkcrutu3ADe77VmnZqaoeAQ4njB8CHYCfU6niKz+wy33/UArHSBxMDgvLk+rOli5bRfnyZSlTpjQRERG0bt2CmbOSdm9mzZpHh3bOx6xd63qOHjnK3r37A6o7sP8zDBg4hIiICDweDwDx8fHkzp0rDR859OJVVV4e/C7lrizNg/e3TFyfkNQAFvz8G+XLXZmsbpVKV7MjejfRu/cSExPDnAU/06Ce8zj1+vXqMH2OM4n99Dnf0+DmuknqTp/9PbfcWIv8+fJy6swZwkQQEU6fPpPsOCkJle84NaGcGAOZj/EEMBGY6J64uA94FsicgYmkxz4rIq2A993ubzjwLs6Z8SE411d2AH5Ix+4fBEa4lwttBR5OQ903cbrSvdJ57CTi4uJ46ukXmf3t53jCwvh03JesX7+ZLp07ADBq9Hhmz1lAkya3sWnDr5w8dYpOnXqlWjdB8+aNWbZ8VWKLYfHi5axc8T1RURtYs2Z9to535Zp1zPxuARWuKsO9DzqXrDzV9UFmf/8zm/7cCgIlixWl/zPOxQb7Dxyk///eZfjQVwkP9/B8z8fo2utF4uLiuOeuRokJtFOH1vR+6XWmzJpL8aJFeHvQC4nHPHX6NNPnfM+od52h8AfbtKTnC68RERHOmwMCn985VL7j1ITyvdKSnuurTNqE5yhpX/JFcGr3L1kdQprkKnHz+QsFmdizuwIeTnvnivYB/9733DEhqKbiSc8zX4wx5ryCsYscKEuMxphMEcrdJEuMxphMEeA90EHJEqMxJlNYV9oYY3xYV9oYY3zEhnBqtMRojMkUoZsWLTEaYzKJjTEaY4wPOyttjDE+4kO4M22J0RiTKeKyOoALYInRGJMprMVojDE+QjctWmI0xmQSOyttjDE+rCttjDE+QjctWmI0xmSSuBBOjZYYjTGZwsYYjTHGh40xGmOMj9BNi5YYjTGZxFqMxhjjw06+GGOMDzv5YkwQCLXnNIfac7DTSq3FaIwxSVmL0RhjfMSrtRiNMSaJ0E2LlhiNMZkkLoQ705YYjTGZInTToiVGY0wmCeULvMOyOgBjTPakafgvECLSREQ2ichfIvKsn+0iIu+729eIyPVe27aLSJSIrBKRZec7lrUYjTGZIiO70iLiAYYBDYFoYKmIzFDV9V7FmgIV3FdtYLj7M0EDVf0nkONZi9EYkylUNeBXAGoBf6nqVlU9C3wBtPAp0wL4TB2LgQIiUjw9sVtiNMZkilg04FcASgI7vZaj3XWBllFgnogsF5Eu5zuYdaWNMZkiLbcEusnKO2GNUtVR3kX8HsJnN6mUuUlVd4vI5cB8EdmoqgtTiscSozEmU6TlrLSbBEelUiQaKO21XArYHWgZVU34uV9EpuJ0zVNMjNaVNsZkigweY1wKVBCRsiKSA7gfmOFTZgbQ0T07XQc4oqp7RCSPiOQFEJE8QCNgbWoHsxajMSZTZORZaVWNFZEewFzAA4xV1XUi0s3dPgKYDdwJ/AWcBB52qxcFpooIODnvc1X9LrXjWWI0xmSKjL4lUFVn4yQ/73UjvN4r0N1Pva1AtbQcyxKjMSZTBNhFDkqWGI0xmSKUbwm0xGiMyRQ2g7cxxviwiWqNMcZH6KZFS4zGmEwSG8IzMmbKBd4iUsid3meViOwVkV1eyzl8ytYXkVmZEUcq8R1PZ73ZIlIgg8MBoHGj+qxbu5CN6xfxTN9kVxwA8M7br7Bx/SJWLJ9PjepVzlt38OvPs2L5fD4Z+17iunbt7uWJHo/+5+INhZj37DvAwz360eyBLrRo15Xxk6cBMGzMBG5r0Z57H+zOvQ92Z+FvS/zWX7R4GXfd34mmrR/h4/GTE9cfOXqMTk89z51tHqXTU89z5OgxAFasWcc9HR+jzaNPsiPauYnk6LHjdOn5QoacUc7gC7wvqkxJjKp6UFWrq2p1YATwTsKyOzNGhnGnI7ooVPVOVf03o/cbFhbG+++9xl3N2nNdtQa0aXM311xTIUmZpk1uo0L5slS6th6PPdaPYR8OTrVuvnx5qVsnkutvaIjHE0aVKpXImTMnD3ZozfAR4/5T8YZKzOEeD32f6MzMz0fx+ah3+GLKLLZs+xuADm3u5ptxw/hm3DBuubFWsrpxcXEMGjqM4UNfZcbEkcz+/qfEuh+Pn0ydyOrM/nIMdSKrM2aCkzTHTZrCu6+9yFNdH+LLqd8CMPLTSXTu2Ab3YugLEo8G/Ao2F+2WQBH5VERaeS17t9ryichUEVkvIiNEJMwt00hEfheRFSLylYhc6q7fLiIvi8gi4D53AssVIrJaRBa4ZQaISB+v460VkTI+MYmIvOVuixKRNu764iKy0G3hrhWRm72OW9i9xehb93hrE+qlV62aNdiyZTvbtu0gJiaGyZOn07xZ4yRlmjVrzPiJXwPwx5IV5C+Qn2LFLk+xbnx8PDlyRACQK1dOYmJi6NO7Gx8MG0NsbOyFhBty8YZKzEUKF+TaiuUByJMnN+WuLM2+AwcDqhu1YTNXlCpB6ZLFiYiIoOntt/LDL4sB+PGX32nR9A4AWjS9gx8W/g5AeHg4p8+c5fSZM4SHe9gRvZt9B/6hZo2qaY7dn4yeqPZiCpZ7pWsBvYHrgKuAliJSGHgRuENVrweWAb286pxW1XrAAmA0cK+qVgPuS8NxWwLVca6KvwN4y52/7QFgrtvirQas8qnXBNitqtVUtQqQ6u1F51OiZDF2Rp+7Hz561x5KlCiWpEzJEsWI3nmuzK7oPZQsUSzFusePn2DK1NksWzqP7dt2cuTIMSIjqzNz5rwLCTUk4w3FmHft2ceGP7dQtXJFACZ9M5N7Oj7Gi6+/ndgV9rb/wD8Uu7xI4nLRywuz302qBw//S5HCBQEn+R769wgAnTu0ZuAb7zH+y2m0vbcZ748axxOdO15w7AlCuSsdLCdflri37SAik4B6wGngWuBXt1mfA/jdq86X7s86wEJV3QagqofScNx6wCRVjQP2icjPQE2cG9bHikgEME1VV/nUiwKGiMgbwCxV/SUNx0zGX7fF95clpTKp1R0ydDhDhg4HYOSItxgw8C0eebgtDRveSlTUBl4f/F6yutkx3lCL+eTJU/R8YRD9nuzKpXny0Oae/6PbQ20RET4Y/RlvfTiaQc/3SlLHX245X2+40tVX8fnodwFYtiqKywsXQlXp/dJgwsOdbn3hgpelOf4EwdhFDtTFbDHGJhxPnN8075Mwvt+g4sytNt9rbPJaVfUe0T7h/hQ/9ZMcz5XTTxm/vzruPG23ALuA8SLS0Wf7ZuAGnAQ5WEReTrZjkS4iskxElsXHn/DdnMSu6D2ULlUicblUyeLs2bMvSZnoXXsoVfpcmZKlirN7z76A6lavXhmAzZu30qF9K9o+0I3KlStSvnzZVOPKLvGGUswxsbE8/cIg/q9RAxrWvwmAwgUvw+PxEBYWRqvmTVm7fnOyekUvL8ze/QcSl/ft/4cihQsBUOiyAhz4x2kvHPjnEAUL5E9SV1UZ+ekkuj7UluFjJ9K9U3uaNb6NiV9NT1PsvuI0PuBXsLmYiXE7TjIBZwryCK9ttdzphMKANsAiYDFwk4iUBxCR3CJytZ/9/g7cKiJl3XIFvY53vbvuesDfb+hCoI2IeESkCE4yXCIiVwL7VXU0MCZhPwlEpARwUlUnAEN8t4Mzv5yqRqpqZFhYnlS+Fli6bBXly5elTJnSRERE0Lp1C2bOStodmzVrHh3aOUO0tWtdz9EjR9m7d39AdQf2f4YBA4cQERGBx+Ocq4qPjyd37lypxpVd4g2VmFWVlwe/S7krS/Pg/S0T1yckNYAFP/9G+XJXJqtbpdLV7IjeTfTuvcTExDBnwc80qFcHgPr16jB9zvcATJ/zPQ1urpuk7vTZ33PLjbXIny8vp86cIUwEEeH06TMBx+7384TwGOPF7EqPBqaLyBKccUHvZtTvwP9wxhgXAlNVNV5EHgImicglbrkXgSR/LlX1gDv77xQ3se7HeWDONzhzs63C6Ron/zMLU4G6wGqcVuczqrpXRB4E+opIDHAc8B14uQ5nPDIeiAEeS+uX4S0uLo6nnn6R2d9+jicsjE/Hfcn69Zvp0rkDAKNGj2f2nAU0aXIbmzb8yslTp+jUqVeqdRM0b96YZctXJbZwFi9ezsoV3xMVtYE1a9YnDyYbxhsqMa9cs46Z3y2gwlVluPdB55Kgp7o+yOzvf2bTn1tBoGSxovR/5kkA9h84SP//vcvwoa8SHu7h+Z6P0bXXi8TFxXHPXY0SE2inDq3p/dLrTJk1l+JFi/D2oBcSj3nq9Gmmz/meUe++BsCDbVrS84XXiIgI580B/dL7dQOhfeeLBOPAZ3YTnqOkfckmmVO7L2hoOktEFC4X8HU8lYvWDvj3ft2+Py78+qAMFCwnX4wx2UwotxgtMRpjMkUwnlQJlCVGY0ymCMaTKoGyxGiMyRTWlTbGGB/WYjTGGB9qY4zGGJNUKN8SaInRGJMp7Ky0Mcb4COWbRywxGmMyhZ2VNsYYH3ZW2hhjfFhX2hhjfNhZaWOM8REXb2eljTEmCetKG2OMD+tKG2OMD2sxGmOMD7uO0RhjfNgtgcYY4yOUu9IX8/Gpxpj/kIx+fKqINBGRTSLyl4g862e7iMj77vY17mOTA6rryxKjMSZTqGrAr/MREQ8wDGgKXAu0FZFrfYo1BSq4ry7A8DTUTcISozEmU2RkYgRqAX+p6lZVPQt8AbTwKdMC+Ewdi4ECIlI8wLpJWGI0xmQKTcMrACWBnV7L0e66QMoEUjcJO/lyEcSe3ZVpDxMXkS6qOiqz9p/RQi1esJjTKy2/9yLSBaf7m2CUT/z+9uWbU1MqE0jdJKzFGPq6nL9IUAm1eMFiznSqOkpVI71evkk9GijttVwK2B1gmUDqJmGJ0RgTCpYCFUSkrIjkAO4HZviUmQF0dM9O1wGOqOqeAOsmYV1pY0zQU9VYEekBzAU8wFhVXSci3dztI4DZwJ3AX8BJ4OHU6qZ2PAnlizBNcIwlpUWoxQsW83+RJUZjjPFhY4zGGOPDEqMxxviwxGhMNiAi94lIXvf9iyIyxfteYZM2NsYYIkSkYGrbVfXQxYolUOf7h6mqKy5WLGklIhWAwTj31uZMWK+q5bIsqFSIyBpVrSoi9XDiHgI8r6q1szi0kGSX64SO5Zy7iv8K4LD7vgCwAyibZZGlbGgq2xS47WIFkg6fAP2Bd4AGOJd+ZNodTBkgzv35f8BwVZ0uIgOyMJ6QZi3GECMiI4AZqjrbXW4K3KGqvbM2suxFRJar6g0iEqWq17nrflHVm7M6Nn9EZBawC7gDuAE4BSxR1WpZGliIssQYYhL+wfqsW6aqkVkVUyBEpArJu6WfZV1EqRORX4Gbga+BH3CSzv9UtWKWBpYCEckNNAGiVPVPd1aZ61R1XhaHFpIsMYYYEZkL/AJMwOmOtgduUdXGWRpYKkSkP1AfJzHOxpkXb5GqtsrKuFIjIjWBDThDFa8C+YE33emsgoaI5FPVoymNQQfj2HMosMQYYtx/AP2BW9xVC4GBwfwPQESigGrASlWtJiJFgY9VtVkWhxbyRGSWqt4lIttIPpOMBuvJomBnidFkOhFZoqq1RGQ5zomMY8BaVa2cxaElIyLvqurTIjITP1NTqWrzLAjLXGR2VjpEhPg/2GUiUgAYjXN2/TiwJEsjStl49+eQLI0ijUTkJmCVqp4QkfbA9cC7qroji0MLSdZiDBEicoOqLheRW/1tV9WfL3ZM6SEiZYB8qromq2PJTkRkDc5wRVWc5D4GaKmqfn9fTOqsxRgiVHW5+7YgMFtVz2RlPGklIlWBMri/cyJSXlWnZGlQqXBbYAOAK3FiFoJ7zC5WVVVEWgDvqeoYEXkwq4MKVZYYQ09z4F0RWYjzUJ+5qhqbxTGlSkTG4rRk1gEJT2FXIGgTI06LqydO1z/uPGWDwTEReQ7oANzsPhkvIotjClnWlQ5BIhKBc8lLG6AeMF9VO2VtVCkTkfWqmurjKoONiPwRSrfTiUgx4AFgqar+IiJXAPWD+VrRYGaJMUS5ybEJzq1qN6tqkSwOKUUiMgYYqqrrszqWQInI/3Bme54CJA5bBPn93UWBmu7iElXdn5XxhDJLjCFGRJrgPLOiAfAT8CUwL5i70yJyCzAT2IuTZBLG66pmaWCpEJEf/axWVQ3K+7tFpDXwFs7vhODctdNXVb/OyrhClSXGECMiX+CMLc4JlRMwIvIX0AuI4twYI6r6d5YFlc2IyGqgYUIrUUSKAN/bvdLpYydfQoyq3u92mRqKCIRGl2mHqqb6VLZgIyL5SXqH0c/AK6p6JOuiSlWYz+/BQWy+1XSzxBhiROQ+nIuPf8LpMn0gIsHeZdooIp/jdKe9x+uC+az0WGAt0Npd7oAzFVnLLIsodd+599FPcpfb4NyXbtLButIhJhS7TCLyiZ/VqqqPXPRgAiQiq1S1+vnWBRMRuRe4CecP5kJVnZrFIYUsazGGnpDqMrnX0/2jqn2zOpY0OiUi9VR1ESRe8H0qi2NKlap+A3yT1XFkB5YYQ09IdZlUNS5Enz3yGDDOHWsU4BDwUJZG5IeIHOPcrDre3b+EM//5siSwEGdd6RAhIuWBoqr6q4i0xLmwW3AecTBRVbdkaYCpEJGhQAXgK+BEwvogH2MEnPkOAVT1aFbHYi4eS4whwp26/nnfyRdEJBLoH8xzG4boGGMBoCNe93cDqOqTWRRSqtw7XZKx2XXSxxJjiBCRtapaJYVtic8lMRlDRH4DFpP82stxWRZUKtzJgBPkxHk42qZgnPMyFNgYY+jImcq2XBctinQQkVLABzhnTBVYBDylqtFZGljqcqpqr6wOIlC+fxjdcd2uWRROyAvas5kmmaUi0tl3pYg8ijMDTDD7BJgBlABK4lzP6K97HUzGi0hnESkuIgUTXlkdVKDce7prnreg8cu60iHCvdtlKnCWc4kwEsgB3KOqe7MqtvMJ0WsCuwOvAf9y7mxv0M7HKCLerdswnBm8CwXzQ9KCmXWlQ4Sq7gNuFJEGQMJY47eq+kMWhhWof9zp9hMuMWqLc/1lMOsFlFfVf7I6kADl9XofC3yLXdOYbtZiNJnOPWP6IVAXp/X1G84YY9BOIiEiM4D7VfVkVsdiLj5LjMb4ISJTgcrAjyS9vztYL9eZD9ynqv+6y5cBX1hXOn2sK20yjYi8nMpmVdVXL1owaTfNfYWKIglJEUBVD4vI5VkYT0izxGgy0wk/6/IAjwKFgKBNjMF6vWIq4kTkioQLukXkSvw8ZtcExrrS5qIQkbzAUzhJcTLOow6Cdh5JEdmG/+d3B+tZ6cY4z+1OeIzuLUAXVZ2bdVGFLmsxmkzlXvvXC2gHjAOuV9XDWRtVQCK93ucE7sN5dG3QEZEwID/OJTp1cO6h7xlCZ9SDjrUYTaYRkbdwJnYdBQxT1eNZHNIFEZFFqlovq+PwR0QWquot5y9pAmGJ0WQaEYnHOaMbS4hNieUzVVoYTgvysWCdEFhEXsKZL/JLks5gdCjLggphlhiN8cPnKYGxwHZgiKpuypqIUueOifoK2jt1gp0lRmOM8WGTSBjjh4gUFZExIjLHXb7WnbAjKIlIbhF5UURGucsVROSurI4rVFliNMa/T4G5ODMCAWwGns6qYALwCc4EIze6y9HAoKwLJ7RZYjTGv8KqOhl3klpVjQXisjakVF2lqm8CMQCqegrnJJdJB0uMxvh3QkQK4Z5NF5E6wJGsDSlVZ0UkF+fivQqve7xN2tgF3sb41wtnct2rRORXoAjQKmtDSlV/4DugtIhMxJkt/aEsjSiE2VlpY1IgIuFARZwu6SZVjcnikFLltnAT7nxZbHe+pJ+1GI1JWS3OPSXwehFBVT/L2pBSdSvOY3UViMCZ8d2kg7UYjfFDRMYDVwGrOHfSRYN4PsaPgPKcmyW9DbBFVbtnXVShyxKjMX6IyAbgWg2RfyAisg6okhCvO7FElD0+NX3srLQx/q0FimV1EGmwCbjCa7k0sCaLYgl5NsZojH+FgfUisoSkjzZonnUhJSciM3HGFPMDG9x4FaiN82wdkw6WGI3xb0BWBxCgIVkdQHZkY4zGeBGRnEA3nBMZUcAY964X8x9iidEYLyLyJc5tdb8ATYG/VfWprI3q/ETkGOfmvMyBc7nOiWCe8zKYWVfamKSuVdXrAERkDLAki+MJiKrm9V4WkbtxrsM06WBnpY1JKvHullDoQrt35ySjqtOA2y5uNNmHtRiNSaqaiBx13wuQy10O1scxLMG5K6el17qERzHYOFk6WWI0xouqerI6hnRqxrlEmPAohqC6tCiU2MkXY0KYiEQDb5N87kUFUNW3L3pQ2YC1GI0JbR7gUmxS2gxlLUZjQpiIrFDV689f0qSFnZU2JrRZSzETWIvRmBAmIgVV9VBWx5HdWGI0xhgf1pU2xhgflhiNMcaHJUaTbiISJyKrRGStiHwlIrkvYF+fikgr9/3HInJtKmXri8iNKW1Ppd52ESkc6HqfMsfTeKwBItInrTGa4GCJ0VyIU6paXVWrAGdxputKJCLpuotEVTup6vpUitQH0pwYjQmUJUaTUX4ByrutuR9F5HMgSkQ8IvKWiCwVkTUi0hVAHB+KyHoR+Ra4PGFHIvKTiES675uIyAoRWS0iC0SkDE4C7um2Vm8WkSIi8o17jKUicpNbt5CIzBORlSIykgAubRGRaSKyXETWiUgXn21D3VgWiEgRd91VIvKdW+cXEamUId+myVJ254u5YO4ML01xHvgOznRXVVR1m5tcjqhqTRG5BPhVROYBNXCe2XwdUBRYD4z12W8RYDRwi7uvgqp6SERGAMdVdYhb7nPgHVVdJCJXAHOBa3AeQr9IVV8Rkf8DkiS6FDziHiMXsFREvlHVg0AeYIWq9haRl9199wBGAd1U9U8RqQ18hM1qE/IsMZoLkUtEVrnvfwHG4HRxl6jqNnd9I6BqwvghzrNJKgC3AJNUNQ7YLSI/+Nl/HWBhwr5SuV7vDuBakcQGYT4Ryeseo6Vb91sRORzAZ3pSRO5x35d2Yz0IxANfuusnAFNE5FL3837ldexLAjiGCXKWGM2FOKWq1b1XuAnihPcq4AlVnetT7k7OPy2WBFAGnCGhuqp6yk8sAV+oKyL1cZJsXVU9KSI/ATlTKK7ucf/1/Q5M6LMxRpPZ5gKPiUgEgIhcLSJ5gIXA/e4YZHGggZ+6vwO3ikhZt25Bd/0xwHvG6nk43VrcctXdtwuBdu66psBl54k1P3DYTYqVcFqsCcKAhFbvAzhd9KPANhG5zz2GiEi18xzDhABLjCazfYwzfrhCRNYCI3F6KlOBP3EeODUc+Nm3oqoewBkXnCIiqznXlZ0J3JNw8gV4Eoh0T+6s59zZ8YHALSKyAqdLv+M8sX4HhIvIGuBVYLHXthNAZRFZjjOG+Iq7vh3wqBvfOqBFAN+JCXJ2S6AxxviwFqMxxviwxGiMMT4sMRpjjA9LjMYY48MSozHG+LDEaIwxPiwxGmOMD0uMxhjj4/8BdPORLpOu4dsAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 288x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "cf_matrix  = [[135,   2,   0,   3],\n",
    "          [ 11, 126,   1,   2],\n",
    "          [  0,   0, 140,   0],\n",
    "          [  0,   0,   0, 140]]\n",
    "classes = ('Covid', 'Normal', 'Pneumonia', 'Tuberculosis')\n",
    "df_cm = pd.DataFrame(cf_matrix/np.sum(cf_matrix), index = [i for i in classes],columns = [i for i in classes])\n",
    "plt.figure(figsize = (4,4))\n",
    "s = sn.heatmap(df_cm, annot=True,fmt='.2%')\n",
    "s.set(xlabel='Predicted label', ylabel='Actual label')\n",
    "plt.show\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d18c7ab",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
